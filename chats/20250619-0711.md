wedosoft: 현재 브랜치를 원격과 동기화 해주세요 원격 기준입니다.

GitHub Copilot: 현재 브랜치를 원격 기준으로 동기화하겠습니다. 먼저 현재 Git 상태를 확인하고 원격 저장소에서 최신 변경사항을 가져와서 동기화하겠습니다. 현재 상황을 확인했습니다. `dev` 브랜치에서 로컬과 원격이 diverged 상태입니다 (로컬에 32개, 원격에 6개의 서로 다른 커밋이 있습니다). 원격 기준으로 동기화한다고 하셨으니, 원격의 최신 상태를 가져와서 강제로 동기화하겠습니다.

먼저 원격의 최신 정보를 가져오겠습니다: 이제 원격 기준으로 동기화하겠습니다. 로컬 변경사항은 잃게 되지만 원격과 완전히 일치하게 됩니다: 동기화가 완료되었습니다. 확인해보겠습니다: 완료되었습니다! 현재 상태를 요약하면:

## ✅ 브랜치 동기화 완료

- **현재 브랜치**: `dev`
- **동기화 상태**: 원격 `origin/dev`와 완전히 일치
- **최신 커밋**: `23b26b5 - feat: Implement unified vector search module with LangChain-Qdrant integration`
- **작업 트리**: 깨끗한 상태 (변경사항 없음)

로컬 브랜치가 원격 `origin/dev` 기준으로 완전히 동기화되었습니다. 이전에 로컬에 있던 32개의 커밋은 제거되고, 원격의 최신 상태로 업데이트되었습니다.

wedosoft: 현재 프로젝트에 문제점이 많고 여러가지 제고할 사항들이 있어서 이에 대한 논의를 하고 싶습니다. 현재 문서를 읽어주세요

GitHub Copilot: 네, 문서를 모두 읽었습니다. 현재 프로젝트의 문제점과 제고할 사항들에 대해 논의하실 준비가 되었습니다. 어떤 부분부터 논의를 시작할지 말씀해 주세요.

wedosoft: 먼저 데이터 수집 로직부터 논의해봅시다.

GitHub Copilot: 네, 데이터 수집 로직부터 논의하겠습니다.

현재 문서에 따르면 데이터 수집 로직은 다음과 같은 흐름으로 구성되어 있습니다:

### 📌 데이터 수집 로직 요약

1. **데이터 수집 및 병합**

   - 티켓, 컨버세이션, 첨부파일을 별도로 수집
   - 티켓 본문과 컨버세이션을 병합하여 하나의 문서로 구성
   - JSON 형태로 로컬 저장 및 해시값으로 중복/변경 감지

2. **LLM 요약 및 벡터 저장**
   - Claude/OpenAI 등 LLM을 사용하여 이슈 및 솔루션 요약
   - 요약된 결과만 VectorDB에 저장하고 원본 텍스트는 메타데이터로만 저장
   - 유사도 검색 시 요약 텍스트 기준으로 유사도 계산

현재 이 데이터 수집 로직에서 어떤 문제점이나 개선이 필요한 부분이 있는지 구체적으로 말씀해 주시면 논의를 진행하겠습니다.

wedosoft: 현재는 티켓원본 세부정보 대화 첨부파일 지식베이스 등을 각각 별도로 수집하고 있습니다. 이 문서의 방향대로 나아가려면 최초 데이터 수집시 원본 티켓과 세부정보, 대화내역까지 하나의 문서로 병합하여 데이터 수집을 해야합니다. 지식베이스는 그대로 하면 되겠습니다. 이에 현재 로직에서 어떻게 개선하면 좋을지 제안주세요

GitHub Copilot: 현재 문서의 지침과 프로젝트의 요구사항을 고려하여, 데이터 수집 로직을 다음과 같이 개선할 것을 제안합니다.

---

## 📌 현재 로직의 문제점

현재 로직은 티켓, 컨버세이션, 첨부파일을 별도로 수집하고 있습니다. 그러나 문서의 지침에 따르면, 티켓 본문과 컨버세이션을 병합하여 하나의 문서로 구성한 후 JSON 형태로 저장하고, 이를 기반으로 요약 및 벡터화를 수행해야 합니다.

---

## 🚧 개선이 필요한 부분

- **티켓과 컨버세이션의 병합 로직**이 명확히 구현되어 있지 않거나, 별도의 문서로 구성되지 않은 경우
- **중복 및 변경 감지 로직**이 해시값을 기준으로 명확히 구현되지 않은 경우
- **JSON 형태로 로컬 저장**하는 로직이 없거나 불충분한 경우
- **벡터 DB 저장 시 메타데이터**에 원본 텍스트가 아닌 요약 결과만 저장하는 로직이 명확하지 않은 경우

---

## ✅ 개선 제안

다음과 같은 방식으로 데이터 수집 로직을 개선할 것을 제안합니다.

### 1️⃣ 티켓과 컨버세이션 병합 로직 명확화

- 티켓 본문과 컨버세이션을 하나의 문서로 병합하는 명확한 함수 구현
- JSON 형태로 저장하며, 해시값을 통해 중복 및 변경 감지

**예시 코드**:

```python
# backend/data/ingest.py

import hashlib
import json
from typing import List, Dict, Any

def merge_ticket_and_conversations(ticket: Dict[str, Any], conversations: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    티켓 본문과 컨버세이션을 병합하여 하나의 문서로 구성합니다.

    Args:
        ticket: Freshdesk 티켓 원본 데이터
        conversations: 티켓에 연결된 컨버세이션 목록

    Returns:
        병합된 티켓 문서 (JSON 형태)
    """
    merged_content = {
        "original_id": str(ticket["id"]),
        "doc_type": "ticket",
        "subject": ticket.get("subject", ""),
        "content": ticket.get("description", "") + "\n\n" + "\n\n".join(
            [conv.get("body", "") for conv in conversations]
        ),
        "conversations": conversations,  # 메타데이터로 저장
    }
    return merged_document
```

---

### 2️⃣ JSON 형태로 로컬 저장 및 해시값으로 중복/변경 감지

- JSON 형태로 저장하고, 해시값을 이용하여 중복 및 변경 여부를 감지합니다.

```python
import hashlib
import json
from pathlib import Path

def save_ticket_document(ticket_document: Dict[str, Any], storage_path: Path) -> None:
    """
    병합된 티켓 문서를 JSON 형태로 저장하고, 해시값으로 중복/변경을 감지합니다.

    Args:
        ticket_document: 병합된 티켓 문서 데이터
        storage_path: 저장할 경로
    """
    # 해시값 생성 (중복/변경 감지용)
    document_hash = hash(json.dumps(ticket_document, sort_keys=True))

    file_path = storage_path / f"{ticket_document['original_id']}.json"

    # 기존 파일이 존재하면 해시값 비교 후 저장 여부 결정
    if file_exists_and_same_hash(file_path=file_path, new_hash=hash(ticket_document)):
        return  # 변경사항 없음

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(ticket_document, f, ensure_ascii=False, indent=2)

def file_exists_and_same_hash(file_path: Path, new_hash: int) -> bool:
    """
    기존 파일의 해시값과 새 해시값을 비교하여 동일 여부를 판단합니다.

    Args:
        file_path: 기존 파일 경로
        new_hash: 새로 생성된 문서의 해시값

    Returns:
        해시값이 동일하면 True, 다르면 False
    """
    if not file_path.exists():
        return False

    with open(file_path, "r", encoding="utf-8") as f:
        existing_data = json.load(f)
        existing_hash = hash(existing_data)

    return existing_hash == new_hash
```

---

### 2️⃣ 요약 및 벡터 저장 로직 명확화

- 병합된 문서를 LLM으로 요약한 후, 요약 결과만 벡터 DB에 저장합니다.
- 원본 텍스트는 메타데이터로만 저장합니다.

```python
# backend/core/ingest.py 예시

from backend.core.llm_router import LLM_ROUTER
from backend.core.vectordb import QdrantAdapter

async def summarize_and_store(ticket_document: Dict[str, Any], llm_router: LLM_ROUTER, qdrant_adapter: QdrantAdapter, collection_name: str, company_id: str):
    """
    병합된 티켓 문서를 요약하고 벡터 DB에 저장합니다.

    Args:
        ticket_document: 병합된 티켓 문서
        llm_router: LLM 라우터 인스턴스
        qdrant_adapter: Qdrant 어댑터 인스턴스
    """
    summary_chain = llm_router.get_summary_generation_chain()
    summary_result = await summary_chain.ainvoke({"content": ticket_document["content"]})

    # 벡터 DB에 요약 결과만 저장
    qdrant_adapter.add_documents(
        collection_name=f"{company_id}_tickets",
        documents=[summary_chain.content],
        ids=[generate_uuid(ticket_document["original_id"])],
        metadatas=[{
            "original_id": ticket_document["original_id"],
            "doc_type": "ticket",
            "subject": ticket_document["subject"],
            # 원본 텍스트는 메타데이터로만 저장 (필요 시)
        }]
    )
```

---

## 📌 개선 후 기대 효과

- 티켓과 컨버세이션이 명확히 병합되어 하나의 문서로 관리되므로, 데이터 일관성 및 관리 용이성 향상
- 중복 및 변경사항 감지 로직으로 불필요한 재처리 방지
- 벡터 DB에 요약 결과만 저장하여 검색 성능 및 정확도 향상

---

위와 같은 방식으로 데이터 수집 로직을 개선하면, 프로젝트의 요구사항을 충족하면서도 유지보수성과 성능을 높일 수 있습니다. 이 방향으로 진행해도 될지 확인 부탁드립니다.

wedosoft: #codebase 점검해 봤나요?

GitHub Copilot: 네, 제공해주신 코드베이스와 관련 문서들을 모두 점검했습니다. 현재 프로젝트의 주요 작업 현황과 구조를 간략히 정리해 드리겠습니다.

---

## 📌 프로젝트 현황 요약

### 1. 주요 작업 및 상태

- **Freshdesk 데이터 수집 및 임베딩 파이프라인**:

  - Freshdesk API를 통해 티켓 및 지식베이스 데이터를 수집하고, OpenAI 임베딩 모델을 사용하여 벡터화한 후 Qdrant 벡터 DB에 저장하는 전체 파이프라인이 구현 중입니다.
  - 현재 run_collection.py에서 빠른 테스트(100개 티켓 수집 및 저장)를 수행하는 로직이 구현되어 있으며, 임베딩 및 Qdrant 저장 단계에서의 오류 처리 및 로깅 강화가 필요합니다.

- **Qdrant 벡터 DB 연동**:

  - vectordb.py 또는 `data/qdrant_handler.py`에서 Qdrant 포인트 업서트 로직 구현이 예정되어 있습니다.
  - `company_id` 기반 멀티테넌트 데이터 분리 및 메타데이터 필터링을 통한 데이터 격리가 중요한 요구사항으로 명시되어 있습니다.

- **API 엔드포인트 설계 및 구현**:

  - `/init`, `/query`, `/generate_reply`, `/ingest`, `/health`, `/metrics`, `/query/stream`, `/generate_reply/stream`, `/attachments/*` 등 주요 엔드포인트가 정의되어 있으며, FastAPI 기반으로 구현 중입니다.
  - 특히 `/init` 및 `/query` 엔드포인트는 티켓 요약, 유사 티켓, 추천 솔루션 등 초기 데이터를 제공하고, 자연어 기반 검색을 지원하는 핵심 기능입니다.

- **인증 및 권한 부여 로직**:

  - Freshdesk Signed Request 또는 토큰 기반 인증 로직이 구현 예정이며, `company_id` 기반 접근 제어가 필수적으로 요구됩니다.
  - API 요청 시 헤더에서 Freshdesk 도메인과 API 키를 동적으로 추출하여 고객사별 데이터 격리를 보장하는 로직이 필요합니다.

- **테스트 전략 및 품질 관리**:
  - 단위 테스트 및 통합 테스트 작성이 예정되어 있으며, pytest 및 mocking 라이브러리를 활용하여 외부 의존성(Freshdesk API, Qdrant, OpenAI API)을 모킹하여 테스트 환경의 독립성을 확보할 계획입니다.

---

## 📂 주요 파일 및 디렉토리 구조

```
project-a/
├── backend/
│   ├── api/
│   │   ├── main.py (FastAPI 엔드포인트 정의)
│   │   └── ingest.py (데이터 수집 및 임베딩 파이프라인)
│   ├── core/
│   │   ├── vectordb.py (Qdrant 연동 로직)
│   │   ├── retriever.py (벡터 검색 로직)
│   │   ├── llm_router.py (LLM 호출 및 응답 생성 로직)
│   │   ├── schemas.py (Pydantic 모델 정의)
│   │   └── settings.py (환경 설정)
│   └── freshdesk/
│       └── run_collection.py (Freshdesk 데이터 수집 및 저장 테스트)
├── docs/
│   └── PROJECT_RULES.md (프로젝트 규칙 및 가이드라인)
├── tasks/
│   ├── task_005.txt (임베딩 및 Qdrant 저장 파이프라인 관련 작업)
│   ├── task_020.txt (인증 및 권한 부여 관련 작업)
│   └── task_022.txt (단위/통합 테스트 작성 작업)
└── scripts/
    └── prd.txt (제품 요구사항 정의서)
```

---

## 🚩 주요 개선 필요 영역

### 1. Qdrant 저장 검증 자동화

- 현재 run_collection.py에서 데이터 수집 후 Qdrant 저장까지 자동화되어 있지만, 저장 성공 여부를 자동으로 검증하는 로직이 부족합니다.
- 워크플로우 마지막에 Qdrant 포인트 수를 자동으로 출력하거나, 별도의 검증 스크립트를 추가하여 저장 성공 여부를 명확히 확인할 필요가 있습니다.

### 2. ID 체계 표준화

- `original_id`는 Freshdesk 원본 숫자 ID를 문자열 형태로 저장하고, Qdrant 포인트 ID는 UUID 형식으로 별도 관리하는 명확한 ID 체계가 필요합니다.
- API 엔드포인트 및 내부 함수 호출 시 ID 타입 일관성을 유지하고, Qdrant payload에 `original_id`와 `doc_type`을 명확히 저장하도록 수정이 필요합니다.

### 3. 동적 Freshdesk 설정 및 멀티테넌트 지원

- 모든 API 요청에서 헤더 기반으로 Freshdesk 도메인과 API 키를 동적으로 추출하여 고객사별 데이터 격리를 보장하는 로직이 필요합니다.
- 벡터 DB 검색 시 `company_id` 필터링을 명확히 적용하여 데이터 격리를 철저히 유지해야 합니다.

### 4. Langchain 아키텍처 개선

- 현재 LLM 호출이 순차적으로 이루어지고 있어 성능 개선이 필요합니다.
- `asyncio.gather` 또는 Langchain의 `RunnableParallel`을 활용하여 병렬 처리를 구현하고, Langchain-Qdrant 라이브러리를 도입하여 벡터 DB 연동을 표준화할 필요가 있습니다.

### 5. 프론트엔드 연동 및 타입 안전성

- Freshdesk FDK 환경에서 프론트엔드와 백엔드 간 데이터 타입 불일치를 방지하기 위한 런타임 타입 검증 및 에러 처리 강화가 필요합니다.
- 프론트엔드에서 API 응답 데이터를 명확히 검증하고, 백엔드 API 호출 시 동적 헤더 구성을 철저히 구현해야 합니다.

---

## 🚧 다음 단계 제안

다음과 같은 작업을 우선적으로 진행하는 것이 좋겠습니다.

1. **Qdrant 저장 검증 자동화**

   - run_collection.py 또는 별도 스크립트에 Qdrant 포인트 수 자동 출력 로직 추가

2. **ID 체계 표준화**

   - ingest.py, vectordb.py, main.py, schemas.py 파일에서 ID 처리 로직 수정 및 검토

3. **동적 Freshdesk 설정 및 멀티테넌트 지원**

   - 모든 API 엔드포인트에서 헤더 기반 Freshdesk 설정 추출 및 `company_id` 필터링 적용

4. **Langchain 아키텍처 개선**

   - `/init` 엔드포인트의 LLM 호출을 병렬 처리로 변경하고, Langchain-Qdrant 도입을 위한 리팩토링 진행

5. **단위 및 통합 테스트 작성**
   - pytest 및 mocking 라이브러리를 활용하여 핵심 기능에 대한 테스트 케이스 작성

---

위 내용을 바탕으로 다음 작업을 진행하고자 합니다.  
진행해도 될까요? 아니면 특정 부분에 대해 추가적인 확인이나 수정이 필요하신가요?

wedosoft: 지침에 따르면 최초 데이터 수집시 티켓 원본과 디테일, 대화, 첨부파일까지 함께 묶어서 저장할 것을 논의하는데 이에 대해서는 어떤가요

GitHub Copilot: 네, 지침에 따르면 최초 데이터 수집 시 티켓 원본, 세부정보, 대화 내역, 첨부파일까지 하나의 문서로 병합하여 저장하는 것이 권장됩니다. 이에 대한 논의 사항을 정리하여 제안 드립니다.

---

## 📌 현재 상황 및 문제점

현재는 티켓 원본, 세부 정보, 대화 내역, 첨부파일을 각각 별도의 데이터로 수집하고 있습니다.  
이 방식은 다음과 같은 문제를 야기할 수 있습니다:

- 데이터가 여러 곳에 분산되어 있어 관리가 어렵고, 데이터 일관성 유지가 어려움
- 벡터화 및 요약 시 데이터 병합 과정에서 추가적인 처리 비용 발생
- 중복 데이터 처리 및 변경 감지가 복잡해짐

---

## 🚧 개선 방향

지침에 따라 최초 데이터 수집 시 다음과 같은 방식으로 데이터를 병합하여 저장하는 방식을 제안합니다.

### ✅ 개선된 데이터 수집 흐름

1. **Freshdesk API에서 데이터 수집**

   - 티켓 원본 (`ticket`)
   - 티켓 세부 정보 (`details`)
   - 대화 내역 (`conversations`)
   - 첨부파일 정보 (`attachments`)

2. **하나의 문서로 병합**

   - 티켓 본문, 세부 정보, 대화 내역, 첨부파일 메타데이터를 하나의 JSON 문서로 병합
   - 첨부파일은 메타데이터로만 저장하고, 실제 파일은 별도 스토리지에 저장하거나 링크로 관리

3. **JSON 형태로 로컬 저장**
   - 병합된 데이터를 JSON 형태로 저장
   - 해시값을 이용하여 중복 및 변경 감지

---

## 🛠️ 구현 예시 코드

다음은 개선된 데이터 수집 로직의 예시 코드입니다.

### 1️⃣ 데이터 병합 함수 구현

```python
# backend/data/ingest.py

from typing import Dict, Any, List

def merge_ticket_data(ticket: dict, details: dict, conversations: list, attachments: list) -> dict:
    """
    티켓 원본, 세부 정보, 대화 내역, 첨부파일 메타데이터를 하나의 문서로 병합합니다.

    Args:
        ticket: 티켓 원본 데이터
        details: 티켓 세부 정보
        conversations: 티켓 관련 대화 내역 리스트
        attachments: 첨부파일 메타데이터 리스트

    Returns:
        병합된 티켓 문서 (JSON 형태)
    """
    merged_document = {
        "original_id": str(ticket["id"]),
        "doc_type": "ticket",
        "subject": ticket.get("subject", ""),
        "description": ticket.get("description", ""),
        "details": details,
        "conversations": conversations,
        "attachments": [
            {
                "attachment_id": str(att["id"]),
                "file_name": att["name"],
                "content_type": att["content_type"],
                "url": att["attachment_url"]
            } for att in attachments
        ],
    }
    return merged_document
```

### ✅ 중복 및 변경 감지 로직

병합된 문서의 해시값을 생성하여 중복 및 변경 여부를 감지합니다.

```python
import hashlib
import json

def generate_document_hash(document: dict) -> str:
    """
    병합된 문서의 해시값을 생성합니다.

    Args:
        document: 병합된 티켓 문서

    Returns:
        문서의 해시값 (SHA256)
    """
    document_str = json.dumps(document, sort_keys=True, ensure_ascii=False)
    return hashlib.sha256(document_str.encode('utf-8')).hexdigest()

def is_document_changed(existing_hash: str, new_document: dict) -> bool:
    """
    기존 문서의 해시값과 새 문서의 해시값을 비교하여 변경 여부를 판단합니다.

    Args:
        existing_hash: 기존 문서의 해시값
        new_document: 새로 생성된 문서

    Returns:
        변경되었으면 True, 아니면 False
    """
    new_hash = generate_document_hash(new_document)
    return existing_hash != new_hash
```

---

## 📌 기대 효과

- 데이터가 하나의 문서로 병합되어 관리가 용이해지고, 데이터 일관성 확보
- 중복 및 변경 감지 로직으로 불필요한 재처리 방지
- 이후 요약 및 벡터화 작업의 효율성 향상

---

위와 같은 방식으로 데이터 수집 로직을 개선하면 프로젝트의 요구사항을 충족하면서도 유지보수성과 성능을 높일 수 있습니다. 이 방향으로 진행해도 될까요? 추가적으로 논의가 필요한 부분이 있다면 말씀해 주세요.

wedosoft: 지금처럼 하면 백엔드를 클라우드에 배포했을 때 서버 로컬에 json으로 저장되는 거로 판단됩니다. 만약 saas 확장 및 멀티 테넌트 구조에서는 로컬 데이터를 어떻게 처리하ㅏㄴ요?

GitHub Copilot: 네, 정확히 지적하셨습니다. 현재 방식처럼 JSON 파일을 서버 로컬에 저장하는 방식은 SaaS 확장 및 멀티테넌트 환경에서는 적합하지 않습니다. 클라우드 환경에서는 다음과 같은 방식으로 데이터를 처리하는 것이 일반적입니다.

---

## 🚧 현재 방식의 문제점

- 서버 로컬에 JSON 파일 저장 시, 서버가 확장되거나 컨테이너가 재시작될 때 데이터가 유실될 수 있습니다.
- 멀티테넌트 환경에서 고객사별 데이터 격리 및 보안 관리가 어렵습니다.
- 확장성 및 고가용성 확보가 어렵습니다.

---

## ✅ SaaS 확장 및 멀티테넌트 환경에서의 권장 데이터 처리 방식

다음과 같은 클라우드 기반의 데이터 저장 방식을 권장합니다.

### 1️⃣ 클라우드 객체 스토리지 (Object Storage)

- AWS S3, Azure Blob Storage, Google Cloud Storage 등 클라우드 객체 스토리지 사용
- JSON 파일을 객체 스토리지에 저장하고, URL을 통해 접근
- 고객사별로 별도의 폴더 또는 버킷을 생성하여 데이터 격리

**예시 구조**:

```
s3://your-bucket/company_id/tickets/12345.json
```

### 2️⃣ 관리형 NoSQL 데이터베이스 (예: MongoDB Atlas, DynamoDB)

- JSON 데이터를 NoSQL 데이터베이스에 저장
- 고객사별로 컬렉션 또는 파티션 키를 사용하여 데이터 격리
- 빠른 조회 및 변경 감지 가능

**예시 구조**:

```json
{
  "_id": "ticket_12345",
  "company_id": "company_a",
  "ticket_data": { ... },
  "hash": "sha256_hash_value",
  "updated_at": "2025-06-18T17:30:00Z"
}
```

### 3️⃣ 관리형 관계형 데이터베이스 (예: PostgreSQL, MySQL)

- JSON 데이터를 JSONB 필드에 저장하여 효율적인 조회 및 인덱싱 가능
- 고객사별로 테이블 또는 스키마를 분리하여 데이터 격리

**예시 구조 (PostgreSQL)**:

```sql
CREATE TABLE tickets (
  id SERIAL PRIMARY KEY,
  company_id VARCHAR(255) NOT NULL,
  original_id VARCHAR(255) NOT NULL,
  ticket_data JSONB NOT NULL,
  hash VARCHAR(64) NOT NULL,
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);
```

---

## 📌 추천하는 방식

일반적으로 SaaS 환경에서는 다음과 같은 조합을 추천합니다.

- **JSON 원본 데이터**: 클라우드 객체 스토리지 (AWS S3, Azure Blob Storage 등)
- **메타데이터 및 해시값 관리**: 관리형 데이터베이스 (MongoDB Atlas, PostgreSQL 등)
- **벡터 데이터**: Qdrant Cloud와 같은 관리형 벡터 DB

이렇게 하면 다음과 같은 장점이 있습니다.

- 데이터 유실 방지 및 고가용성 확보
- 고객사별 데이터 격리 및 보안 관리 용이
- 확장성 및 성능 최적화 가능

---

이러한 방식으로 변경하는 것이 좋겠습니다. 이 방향으로 진행해도 될까요? 추가적으로 논의가 필요한 부분이 있다면 말씀해 주세요.

wedosoft: 좋습니댜ㅏㅣ 그럼 한발 더 나아가서, saas 확장과 더불어 freshdesk 고객 뿐만이 아닌 다른 제품도 고려하고 있다면 (예: 젠데스크 등) 처음부터 어떤 설계로 가는게 좋을까요

GitHub Copilot: 네, Freshdesk뿐 아니라 Zendesk 등 다양한 고객지원 플랫폼을 지원하는 SaaS 확장성을 고려한다면, 처음부터 다음과 같은 설계를 추천합니다.

---

## 📌 멀티 플랫폼 지원을 위한 아키텍처 설계 원칙

### 1️⃣ 추상화 계층 도입 (Adapter 패턴)

- 플랫폼별 API 연동 로직을 추상화하여 공통 인터페이스를 정의하고, 각 플랫폼별로 Adapter를 구현합니다.
- Adapter는 플랫폼별 데이터를 공통 데이터 모델로 변환하여 시스템 내부에서 일관된 처리를 가능하게 합니다.

**예시 구조**:

```
backend/
├── adapters/
│   ├── freshdesk_adapter.py
│   ├── zendesk_adapter.py
│   └── base_adapter.py (공통 인터페이스 정의)
```

**예시 코드**:

```python
# backend/adapters/base_adapter.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any

class BaseAdapter(ABC):
    @abstractmethod
    async def fetch_ticket(self, ticket_id: str) -> Dict[str, Any]:
        """티켓 상세 정보를 가져옵니다."""
        pass

    @abstractmethod
    async def fetch_conversations(self, ticket_id: str) -> List[Dict[str, Any]]:
        """티켓의 대화 내역을 가져옵니다."""
        pass

    @abstractmethod
    async def fetch_attachments(self, ticket_id: str) -> List[Dict[str, Any]]:
        """티켓의 첨부파일 정보를 가져옵니다."""
        pass
```

```python
# backend/adapters/freshdesk_adapter.py
from .base_adapter import BaseAdapter

class FreshdeskAdapter(BaseAdapter):
    async def fetch_ticket(self, ticket_id: str) -> Dict[str, Any]:
        # Freshdesk API 호출 로직
        pass

    async def fetch_conversations(self, ticket_id: str) -> List[Dict[str, Any]]:
        # Freshdesk API 호출 로직
        pass

    async def fetch_attachments(self, ticket_id: str) -> List[Dict[str, Any]]:
        # Freshdesk API 호출 로직
        pass
```

```python
# backend/adapters/zendesk_adapter.py
from .base_adapter import BaseAdapter

class ZendeskAdapter(BaseAdapter):
    async def fetch_ticket(self, ticket_id: str) -> Dict[str, Any]:
        # Zendesk API 호출 로직
        pass

    async def fetch_conversations(self, ticket_id: str) -> List[Dict[str, Any]]:
        # Zendesk API 호출 로직
        pass

    async def fetch_attachments(self, ticket_id: str) -> List[Dict[str, Any]]:
        # Zendesk API 호출 로직
        pass
```

---

### 2️⃣ 공통 데이터 모델 정의 (Pydantic 모델)

- 플랫폼마다 데이터 구조가 다르므로, 내부적으로 사용하는 공통 데이터 모델을 정의하여 일관된 처리를 가능하게 합니다.

```python
# backend/core/schemas.py
from pydantic import BaseModel
from typing import List, Optional

class Attachment(BaseModel):
    attachment_id: str
    file_name: str
    content_type: str
    url: str

class Conversation(BaseModel):
    conversation_id: str
    author: str
    body: str
    created_at: str

class Ticket(BaseModel):
    original_id: str
    subject: str
    description: str
    conversations: List[Conversation]
    attachments: List[Attachment]
```

---

### 3️⃣ 플랫폼 라우팅 로직 (Factory 패턴)

- 요청 헤더 또는 설정에서 플랫폼 정보를 추출하여 적절한 Adapter를 선택하는 Factory 클래스를 구현합니다.

```python
# backend/core/adapter_factory.py
from adapters.freshdesk_adapter import FreshdeskAdapter
from adapters.zendesk_adapter import ZendeskAdapter
from adapters.base_adapter import BaseAdapter

def get_adapter(platform: str) -> BaseAdapter:
    if platform == "freshdesk":
        return FreshdeskAdapter()
    elif platform == "zendesk":
        return ZendeskAdapter()
    else:
        raise ValueError(f"지원하지 않는 플랫폼입니다: {platform}")
```

---

### 4️⃣ 멀티테넌트 및 플랫폼별 데이터 격리

- 벡터 DB 저장 시 플랫폼과 고객사 정보를 메타데이터로 저장하여 데이터 격리를 명확히 합니다.

```json
{
  "original_id": "12345",
  "platform": "freshdesk",
  "company_id": "company_a",
  "doc_type": "ticket"
}
```

---

### 5️⃣ 환경변수 및 설정 관리

- 플랫폼별 API 키 및 설정을 환경변수로 관리하여 보안성을 높이고, 플랫폼 추가 시 설정 확장성을 확보합니다.

```bash
# Freshdesk
FRESHDESK_DOMAIN=your-domain.freshdesk.com
FRESHDESK_API_KEY=your-api-key

# Zendesk
ZENDESK_DOMAIN=your-domain.zendesk.com
ZENDESK_API_KEY=your-api-key
```

---

### 6️⃣ API 엔드포인트 설계

- API 엔드포인트는 플랫폼에 독립적으로 설계하고, 플랫폼 정보는 헤더 또는 요청 본문에서 전달받습니다.

```python
# backend/api/main.py
from fastapi import FastAPI, Header, Depends
from core.adapter_factory import get_adapter
from core.schemas import Ticket

app = FastAPI()

@app.get("/init/{ticket_id}", response_model=Ticket)
async def init_ticket(
    ticket_id: str,
    x_platform: str = Header(...),
):
    adapter = get_adapter(x_platform)
    ticket_data = await adapter.fetch_ticket(ticket_id)
    conversations = await adapter.fetch_conversations(ticket_id)
    attachments = await adapter.fetch_attachments(ticket_id)

    return Ticket(
        original_id=ticket_data["id"],
        subject=ticket_data["subject"],
        description=ticket_data["description"],
        conversations=conversations,
        attachments=attachments
    )
```

---

## 📌 기대 효과 및 장점

- **확장성**: 새로운 플랫폼 추가 시 Adapter만 구현하면 쉽게 확장 가능
- **유지보수성**: 플랫폼별 로직이 명확히 분리되어 유지보수 용이
- **데이터 일관성**: 공통 데이터 모델을 통해 내부 처리 로직의 일관성 확보
- **데이터 격리 및 보안**: 플랫폼 및 고객사별 데이터 격리 명확화

---

위와 같은 설계를 처음부터 적용하면, 향후 다양한 고객지원 플랫폼을 지원하는 SaaS 서비스로의 확장이 용이해집니다. 이 방향으로 진행해도 될까요? 추가적으로 논의가 필요한 부분이 있다면 말씀해 주세요.

wedosoft: 지금은 mvp 단계인데 사실 프레시데스크도 구현하기 버거운 상황입니다. 그래도 장기적인 로드맵으로 본다면 당장 구현하지 않더라도 그 기반은 만들어 놓는게 낫겠죠?

GitHub Copilot: 네, 맞습니다. 당장 여러 플랫폼을 지원하는 구조를 완벽히 구현하는 것은 MVP 단계에서는 부담이 될 수 있습니다. 하지만 장기적인 로드맵을 고려하면, 최소한의 기반 설계는 미리 갖춰두는 것이 좋습니다.

### 📌 MVP 단계에서 최소한으로 준비할 수 있는 기반 설계

1. **추상화 계층 (Adapter 패턴) 최소 구현**

   - 현재 Freshdesk만 지원하더라도, Adapter 인터페이스를 정의하고 Freshdesk Adapter를 구현해 두면 나중에 Zendesk 등 다른 플랫폼 추가 시 쉽게 확장할 수 있습니다.

2. **공통 데이터 모델 정의**

   - 티켓, 대화, 첨부파일 등 핵심 데이터 구조를 공통 모델로 정의해 두면, 향후 다른 플랫폼 데이터를 쉽게 통합할 수 있습니다.

3. **환경 설정 및 멀티테넌트 구조**
   - 환경변수 기반의 설정 관리 및 고객사별 데이터 격리 구조를 미리 설계해 두면, 나중에 SaaS 확장 시 큰 변경 없이 확장 가능합니다.

### 🚧 MVP 단계에서의 권장 접근법

- **최소한의 추상화**만 구현하고, 현재 필요한 Freshdesk Adapter만 실제로 구현합니다.
- **공통 데이터 모델**은 Freshdesk 데이터 구조를 기준으로 최소한의 필드만 정의합니다.
- **환경 설정 및 멀티테넌트 구조**는 처음부터 명확히 설계하여, 향후 확장 시 큰 리팩토링을 방지합니다.

이렇게 하면 MVP 단계에서 부담을 최소화하면서도, 장기적으로 확장 가능한 기반을 확보할 수 있습니다. 이 방향으로 진행해도 될까요? 추가적으로 논의가 필요한 부분이 있다면 말씀해 주세요.

wedosoft: 멀티 테넌트 구조에서 환경변수 특히 고객의 도메인과 api key 등은 보통 각 고객마다 어떻게 처리하나요 현장 기준으로

GitHub Copilot: 멀티 테넌트 SaaS 환경에서 고객별로 민감한 정보(도메인, API 키 등)를 처리하는 현장 기준의 일반적인 방법은 다음과 같습니다.

---

## 📌 현장 기준 멀티 테넌트 환경변수 처리 방식

### 1️⃣ 고객별 설정을 데이터베이스에 저장 (가장 일반적)

- 고객별로 별도의 설정 테이블을 만들어 관리합니다.
- 고객이 가입하거나 설정을 변경할 때, DB에 저장된 값을 사용하여 동적으로 처리합니다.

**예시 구조 (관계형 DB)**:

```sql
CREATE TABLE customer_settings (
    company_id VARCHAR(255) PRIMARY KEY,
    freshdesk_domain VARCHAR(255) NOT NULL,
    freshdesk_api_key VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

### 2️⃣ 암호화된 저장소 사용 (Secrets Manager)

- AWS Secrets Manager, Azure Key Vault, Google Secret Manager 등 클라우드 제공자의 보안 저장소를 활용합니다.
- 고객별로 별도의 Secret을 생성하여 안전하게 관리합니다.

**예시 (AWS Secrets Manager)**:

```
Secret Name: customer/{company_id}/freshdesk
Secret Value (JSON):
{
  "domain": "customer-domain.freshdesk.com",
  "api_key": "customer-api-key"
}
```

### 3️⃣ 환경변수는 공통 설정만 관리

- 환경변수는 공통적인 설정(예: DB 연결 정보, 서비스 URL 등)만 관리합니다.
- 고객별 민감한 정보는 환경변수에 저장하지 않고, 위의 DB 또는 Secrets Manager를 통해 관리합니다.

---

## 📌 실제 현장 구현 예시 (추천 방식)

### ✅ 고객별 설정을 DB에 저장하고, API 요청 시 동적으로 로드

1. **고객별 설정 테이블 생성**

```sql
CREATE TABLE customer_settings (
    company_id VARCHAR(255) PRIMARY KEY,
    freshdesk_domain VARCHAR(255) NOT NULL,
    freshdesk_api_key VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

2. **API 요청 시 헤더에서 고객 식별자(company_id) 추출**

```python
from fastapi import Header, HTTPException

async def get_customer_config(
    x_company_id: str = Header(...)
):
    # DB에서 고객 설정 조회
    customer_config = await db.fetch_customer_settings(x_company_id)
    if not customer_config:
        raise HTTPException(status_code=404, detail="고객 설정을 찾을 수 없습니다.")
    return customer_config
```

3. **고객 설정을 사용하여 Freshdesk API 클라이언트 동적 생성**

```python
from freshdesk.api import API as FreshdeskAPI

async def get_freshdesk_client(customer_config):
    return FreshdeskAPI(
        domain=customer_config["freshdesk_domain"],
        api_key=customer_config["freshdesk_api_key"]
    )
```

---

## 📌 현장에서 이 방식을 사용하는 이유

- **보안성**: 민감한 정보가 코드나 환경변수에 노출되지 않고, DB 또는 Secrets Manager에 안전하게 저장됩니다.
- **확장성**: 고객이 늘어나도 설정을 쉽게 추가하고 관리할 수 있습니다.
- **유지보수성**: 고객별 설정 변경 시 코드나 환경변수를 수정하지 않고 DB에서만 변경하면 됩니다.

---

위와 같은 방식이 현장에서 가장 일반적으로 사용되는 멀티 테넌트 환경변수 처리 방식입니다. 이 방식을 적용하는 것이 좋겠습니다. 추가적으로 궁금한 사항이 있으시면 말씀해 주세요.

wedosoft: 자 그럼 지금 데이터베이스가 임베딩용 벡터 디비, 데이터 수집용 rdb, 민감한 정보 저장용 디비 이렇게 각각 필요한건가요?

GitHub Copilot: 네, 정확히 이해하셨습니다. SaaS 환경에서 확장성과 보안성을 고려하면, 일반적으로 다음과 같은 데이터베이스 구성을 권장합니다.

---

## 📌 권장 데이터베이스 구성

| 용도                    | 데이터베이스 유형                              | 예시                                                  | 주요 역할                                                                 |
| ----------------------- | ---------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------------------- |
| **임베딩 및 검색**      | 벡터 DB                                        | Qdrant, Pinecone, Weaviate                            | 임베딩 벡터 저장 및 유사도 검색                                           |
| **데이터 수집 및 관리** | 관계형 DB (RDB) 또는 NoSQL                     | PostgreSQL, MySQL, MongoDB                            | 티켓 원본, 대화 내역, 첨부파일 메타데이터 등 구조화된 데이터 저장 및 관리 |
| **민감한 정보 저장**    | 보안 저장소 (Secrets Manager) 또는 암호화된 DB | AWS Secrets Manager, Azure Key Vault, HashiCorp Vault | 고객사별 API 키, 도메인 등 민감한 정보 안전하게 저장                      |

---

## 🛠️ 각 데이터베이스의 역할과 필요성

### 1️⃣ 임베딩용 벡터 DB (Qdrant 등)

- **역할**: 임베딩 벡터를 저장하고, 빠른 유사도 검색을 수행합니다.
- **필요성**: 일반적인 DB로는 벡터 검색 성능이 떨어지므로, 전용 벡터 DB가 필수입니다.

### 2️⃣ 데이터 수집용 RDB 또는 NoSQL (PostgreSQL, MongoDB 등)

- **역할**: 티켓 원본, 세부 정보, 대화 내역, 첨부파일 메타데이터 등 구조화된 데이터를 저장하고 관리합니다.
- **필요성**: JSON 형태의 데이터를 효율적으로 저장하고, 중복 및 변경 감지, 고객사별 데이터 격리 및 관리가 용이합니다.

### 3️⃣ 민감한 정보 저장용 DB (Secrets Manager 등)

- **역할**: 고객사별 API 키, 도메인 등 민감한 정보를 안전하게 저장하고 관리합니다.
- **필요성**: 민감한 정보가 코드나 일반 DB에 노출되지 않도록 보안성을 높이고, 접근 권한을 엄격히 관리할 수 있습니다.

---

## ✅ 결론 및 권장 사항

말씀하신 대로, 위 3가지 데이터베이스를 각각 별도로 구성하는 것이 SaaS 환경에서 가장 이상적이고 일반적인 방식입니다. 이렇게 구성하면 다음과 같은 장점이 있습니다.

- **성능 최적화**: 각 데이터베이스가 자신의 역할에 최적화되어 있어 성능이 뛰어납니다.
- **보안 강화**: 민감한 정보가 별도의 보안 저장소에 저장되어 보안성이 높습니다.
- **확장성 및 유지보수성**: 데이터가 명확히 분리되어 있어 확장 및 유지보수가 용이합니다.

이러한 방식으로 데이터베이스를 구성하는 것이 좋겠습니다. 추가적으로 궁금한 사항이 있으시면 말씀해 주세요.

wedosoft: 각 3개의 디비는 모든 고객 대비 한개씩만 있으면 되나요?

GitHub Copilot: 아니요, 멀티테넌트 SaaS 환경에서는 **고객사 규모와 요구사항에 따라 다른 접근 방식**을 사용합니다. 정확한 답변을 드리자면:

## 📌 데이터베이스 구성 전략

### 1️⃣ 벡터 DB (Qdrant 등)

- **일반적 접근**: 모든 고객이 하나의 벡터 DB를 공유하되, **메타데이터 필터링**으로 격리
- **구현 방식**:
  ```python
  # 모든 벡터에 company_id를 메타데이터로 포함
  {
    "vector": [0.1, 0.2, ...],
    "payload": {
      "company_id": "customer_a",
      "original_id": "12345",
      "doc_type": "ticket"
    }
  }
  ```
- **대규모 고객사**: 별도의 컬렉션 또는 네임스페이스 사용 가능

### 2️⃣ 데이터 수집용 DB (PostgreSQL/MongoDB)

- **옵션 1: 공유 DB + 스키마 분리** (PostgreSQL)

  ```sql
  -- 각 고객사별 스키마
  CREATE SCHEMA customer_a;
  CREATE SCHEMA customer_b;

  -- 스키마별 테이블
  customer_a.tickets
  customer_b.tickets
  ```

- **옵션 2: 공유 테이블 + Row-level 격리**

  ```sql
  -- 모든 데이터에 company_id 포함
  CREATE TABLE tickets (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(255) NOT NULL,
    ticket_data JSONB,
    INDEX idx_company (company_id)
  );
  ```

- **옵션 3: 고객사별 별도 DB** (대규모/엔터프라이즈)
  - 완전한 데이터 격리가 필요한 경우

### 3️⃣ 민감한 정보 저장 (Secrets Manager)

- **일반적 접근**: 하나의 Secrets Manager에서 계층적 관리
  ```
  /customers/customer_a/freshdesk_api_key
  /customers/customer_b/freshdesk_api_key
  ```
- **접근 제어**: IAM 정책으로 각 고객사의 시크릿에만 접근 가능하도록 설정

## 📊 현장에서 실제로 사용하는 구성

### 스타트업/중소규모 SaaS (고객사 ~1000개)

```
- 벡터 DB: 1개 (메타데이터 필터링)
- RDB: 1개 (Row-level 격리)
- Secrets: 1개 시스템 (계층적 관리)
```

### 중대규모 SaaS (고객사 1000~10000개)

```
- 벡터 DB: 1~3개 (지역별/성능별 분산)
- RDB: 샤딩 또는 읽기 전용 복제본 추가
- Secrets: 1개 시스템 (엄격한 접근 제어)
```

### 엔터프라이즈 SaaS (대규모 고객 요구사항)

```
- 벡터 DB: 고객사별 전용 인스턴스 옵션 제공
- RDB: 고객사별 별도 DB 또는 전용 클러스터
- Secrets: 고객사 전용 키 관리 시스템
```

## ✅ MVP 단계 권장사항

MVP 단계에서는 다음과 같은 구성을 추천합니다:

```yaml
# 데이터베이스 구성
vector_db:
  type: "Qdrant Cloud"
  instances: 1
  isolation: "metadata_filtering" # company_id 기반

application_db:
  type: "PostgreSQL"
  instances: 1
  isolation: "row_level" # company_id 컬럼

secrets_management:
  type: "AWS Secrets Manager" # 또는 환경변수
  instances: 1
  isolation: "path_based" # /company_id/secret_name
```

이렇게 하면:

- **비용 효율적**: 인프라 비용 최소화
- **확장 가능**: 고객이 늘어도 같은 구조로 확장 가능
- **보안**: 데이터 격리가 코드 레벨에서 보장됨
- **유지보수 용이**: 단일 시스템으로 관리 간편

나중에 특정 고객사가 전용 인스턴스를 요구하거나 규모가 커지면, 그때 별도 DB로 분리하는 전략을 사용하시면 됩니다.

wedosoft: 그러니까 1000개만 넘지 않으면 각각 하나의 디비로 충분하다는 거죠?

GitHub Copilot: 네, 맞습니다! 고객사가 1000개 미만이라면 각 용도별로 하나의 DB로 충분합니다.

## 📊 스타트업/중소규모 SaaS 기준 (고객사 ~1000개)

### ✅ 권장 구성

```yaml
# 단일 인스턴스로 충분한 구성
vector_db:
  type: "Qdrant Cloud"
  instances: 1 # 단일 인스턴스
  isolation: "metadata_filtering" # company_id로 데이터 격리

application_db:
  type: "PostgreSQL" # 또는 MongoDB
  instances: 1 # 단일 인스턴스
  isolation: "row_level" # company_id 컬럼으로 격리

secrets_management:
  type: "AWS Secrets Manager" # 또는 DB 암호화 저장
  instances: 1 # 단일 시스템
  isolation: "path_based" # /company_id/secret_name 구조
```

### 💡 이 구성의 장점

- **비용 효율적**: 인프라 비용 최소화 (월 수백 달러 수준)
- **관리 용이**: 단일 시스템으로 운영 복잡도 낮음
- **충분한 성능**: 1000개 고객사 기준 문제없이 처리 가능
- **확장 가능**: 나중에 고객이 늘면 쉽게 확장 가능

### 🔍 실제 처리 방식

```python
# 모든 고객사가 하나의 DB를 공유하되, company_id로 격리
def get_customer_data(company_id: str):
    # 벡터 DB 검색
    vector_results = qdrant.search(
        filter={"company_id": company_id}  # 이 필터만으로 격리
    )

    # 일반 DB 조회
    tickets = db.query(
        "SELECT * FROM tickets WHERE company_id = ?",
        company_id
    )

    # Secrets 조회
    api_key = secrets.get(f"/customers/{company_id}/api_key")
```

이렇게 하면 MVP부터 중규모까지는 충분히 커버 가능합니다!

wedosoft: 그럼 mvp 단계에서 미리 3개의 디비를 준비하고 작업하는게 좋을까요? 지금은 환경변수나 비밀키는 .env 로컬에 저장하고 로컬에서 개발하고 있는데 어떤 절차가 권장되나요

GitHub Copilot: MVP 단계에서의 데이터베이스 구성과 개발 절차에 대해 권장사항을 말씀드리겠습니다.

## 📌 MVP 단계 데이터베이스 구성 권장사항

### 1️⃣ 단계별 접근법 권장

MVP 단계에서는 **점진적 확장 방식**을 추천합니다:

```yaml
# MVP 초기 (현재)
development:
  vector_db: Qdrant Cloud (무료 티어)
  application_db: SQLite (로컬) → PostgreSQL (Docker)
  secrets: .env 파일 (로컬)

# MVP 중반 (고객 테스트)
staging:
  vector_db: Qdrant Cloud (무료/스타터 플랜)
  application_db: PostgreSQL (Docker 또는 Supabase 무료)
  secrets: .env + 환경변수 분리

# MVP 완성 (프로덕션 준비)
production:
  vector_db: Qdrant Cloud (유료 플랜)
  application_db: PostgreSQL (관리형 DB)
  secrets: AWS Secrets Manager 또는 환경변수
```

### 2️⃣ 현재 단계에서 권장하는 구성

```bash
# 로컬 개발 환경 (.env)
# 벡터 DB (Qdrant Cloud 무료 티어 사용)
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=your-qdrant-api-key

# 애플리케이션 DB (로컬 PostgreSQL)
DATABASE_URL=postgresql://user:password@localhost:5432/project_a_dev

# Freshdesk API (테스트 계정)
FRESHDESK_TEST_DOMAIN=test-account.freshdesk.com
FRESHDESK_TEST_API_KEY=test-api-key

# LLM API Keys
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
```

## 🛠️ MVP 개발 절차 권장사항

### 1️⃣ 로컬 개발 환경 설정

```bash
# 1. Docker Compose로 로컬 DB 환경 구성
# docker-compose.yml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: project_a_dev
      POSTGRES_USER: developer
      POSTGRES_PASSWORD: localpass
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

### 2️⃣ 민감한 정보 관리 전략

```python
# backend/core/config.py
from pydantic_settings import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    # 환경별 설정
    environment: str = "development"

    # 데이터베이스 설정
    database_url: str
    qdrant_url: str
    qdrant_api_key: str

    # 멀티테넌트를 위한 기본 설정
    # 실제 값은 API 요청 시 헤더에서 동적으로 받음
    default_freshdesk_domain: str = ""
    default_freshdesk_api_key: str = ""

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

@lru_cache()
def get_settings():
    return Settings()
```

### 3️⃣ 고객별 설정 관리 (MVP용 간단한 방식)

```python
# backend/data/customer_config.py
import json
from pathlib import Path
from cryptography.fernet import Fernet

class CustomerConfigManager:
    """MVP 단계용 간단한 고객 설정 관리"""

    def __init__(self, config_file: Path = Path("configs/customers.json")):
        self.config_file = config_file
        self.encryption_key = Fernet.generate_key()  # 실제로는 환경변수에서
        self.cipher = Fernet(self.encryption_key)

    def save_customer_config(self, company_id: str, config: dict):
        """고객 설정을 암호화하여 저장"""
        # API 키 암호화
        if 'api_key' in config:
            config['api_key'] = self.cipher.encrypt(
                config['api_key'].encode()
            ).decode()

        # 기존 설정 로드
        configs = self._load_configs()
        configs[company_id] = config

        # 저장
        with open(self.config_file, 'w') as f:
            json.dump(configs, f, indent=2)

    def get_customer_config(self, company_id: str) -> dict:
        """고객 설정을 복호화하여 반환"""
        configs = self._load_configs()
        config = configs.get(company_id, {})

        # API 키 복호화
        if 'api_key' in config:
            config['api_key'] = self.cipher.decrypt(
                config['api_key'].encode()
            ).decode()

        return config
```

## 📊 MVP 단계별 진행 계획

### Phase 1: 로컬 개발 (현재)

```yaml
기간: 2-4주
환경:
  - 벡터 DB: Qdrant Cloud 무료 티어
  - 앱 DB: Docker PostgreSQL (로컬)
  - 비밀: .env 파일
작업:
  - 핵심 기능 구현
  - 단일 테스트 고객사로 개발
```

### Phase 2: 스테이징 환경 구축

```yaml
기간: 1-2주
환경:
  - 벡터 DB: Qdrant Cloud (동일)
  - 앱 DB: Supabase 또는 Railway (무료 티어)
  - 비밀: 환경변수 + 간단한 암호화
작업:
  - 2-3개 테스트 고객사 추가
  - 멀티테넌트 로직 검증
```

### Phase 3: 프로덕션 준비

```yaml
기간: 2-3주
환경:
  - 벡터 DB: Qdrant Cloud 유료 플랜
  - 앱 DB: AWS RDS 또는 GCP Cloud SQL
  - 비밀: AWS Secrets Manager
작업:
  - 보안 강화
  - 모니터링 구축
  - 백업 전략 수립
```

## ✅ 즉시 시작할 수 있는 작업

1. **Qdrant Cloud 무료 계정 생성**

   - https://cloud.qdrant.io 에서 가입
   - 1GB 스토리지, 0.5GB RAM 무료 제공

2. **Docker Compose 파일 생성**

   ```bash
   # PostgreSQL만 먼저 시작
   docker-compose up -d postgres
   ```

3. **환경변수 구조화**

   ```bash
   # .env.example 생성 (Git에 커밋)
   cp .env .env.example
   # 실제 값은 제거하고 구조만 남김
   ```

4. **간단한 멀티테넌트 테스트**
   ```python
   # 헤더 기반 고객사 식별 로직만 먼저 구현
   # 실제 DB 분리는 나중에
   ```

이렇게 점진적으로 진행하면서 필요에 따라 확장하는 것이 MVP 단계에서 가장 효율적입니다. 어떤 부분부터 시작하시겠습니까?

wedosoft: 프로덕션 준비 단계에서 postgresql을 사용안하고 aws gcp를 사용하는 이유가 있나요? 프로적션에 적합해서인가요

Workspace: 작업 영역 정보 수집AWS나 GCP 같은 클라우드 서비스를 프로덕션에서 선호하는 이유와 PostgreSQL을 직접 사용하지 않는 이유를 설명드리겠습니다.

## 🚀 클라우드 서비스(AWS/GCP) 선호 이유

### 1. **관리형 서비스의 이점**

- **자동 백업**: 일일 백업, 포인트 인 타임 복구
- **자동 패치**: 보안 업데이트 자동 적용
- **고가용성**: Multi-AZ 배포로 장애 자동 복구
- **모니터링**: CloudWatch/Stackdriver 통합 모니터링

### 2. **확장성**

```yaml
# 예: AWS RDS 자동 확장
자동 스케일링:
  - CPU 사용률 기반 자동 확장
  - 스토리지 자동 증가
  - Read Replica 추가로 읽기 성능 향상
```

### 3. **보안**

- VPC 격리
- IAM 기반 접근 제어
- 암호화 (전송 중/저장 시)
- 보안 그룹/방화벽 규칙

## 🔍 PostgreSQL 직접 관리 vs 관리형 서비스

### PostgreSQL 직접 설치 시 부담

```bash
# 직접 관리해야 할 것들
- 서버 프로비저닝
- PostgreSQL 설치/설정
- 백업 스크립트 작성/관리
- 복제 설정
- 모니터링 시스템 구축
- 보안 패치 적용
- 성능 튜닝
```

### 관리형 PostgreSQL 서비스

- **AWS RDS PostgreSQL**
- **GCP Cloud SQL PostgreSQL**
- **Azure Database for PostgreSQL**

## 💰 비용 효율성

### 소규모 프로젝트 (현재 상황)

```yaml
AWS RDS (db.t3.micro):
  - 월 $15-20
  - 자동 백업 포함
  - 고가용성 옵션

직접 EC2에 PostgreSQL:
  - EC2 인스턴스: 월 $10-15
  - 추가 관리 시간: 월 10-20시간
  - 백업 스토리지: 추가 비용
```

## 🎯 현재 프로젝트에 적합한 이유

### 1. **Qdrant Cloud 사용 중**

- 이미 클라우드 기반 벡터 DB 사용
- 클라우드 네이티브 아키텍처 일관성

### 2. **멀티테넌트 요구사항**

- 고객사별 데이터 격리
- 확장 가능한 아키텍처 필요

### 3. **운영 리소스 절약**

- 소규모 팀에서 DB 관리 부담 최소화
- 개발에 집중 가능

## 🏗️ 단계별 접근 방법

### Phase 1: MVP (현재)

```python
# 간단한 파일 기반 저장
progress_data = {
    "last_processed": datetime.now(),
    "status": "completed"
}
json.dump(progress_data, open("progress.json", "w"))
```

### Phase 2: 초기 프로덕션

```yaml
# AWS RDS PostgreSQL 도입
- 작은 인스턴스로 시작
- 자동 백업 설정
- 모니터링 대시보드 구성
```

### Phase 3: 확장 단계

```yaml
# 필요에 따라 확장
- Read Replica 추가
- 더 큰 인스턴스로 업그레이드
- 멀티 리전 배포
```

## 🔧 PostgreSQL이 필요한 경우

### 언제 도입이 필요한가?

1. **복잡한 쿼리 필요**

   - 진행 상황 상세 추적
   - 사용자별 통계
   - 복잡한 필터링

2. **트랜잭션 관리**

   - 동시 작업 처리
   - 데이터 일관성 보장

3. **관계형 데이터**
   - 사용자-회사-티켓 관계
   - 권한 관리

## 💡 권장사항

### 현재 단계 (MVP)

```python
# 간단한 JSON 파일 사용
# backend/data/progress_tracker.py
class SimpleProgressTracker:
    def __init__(self):
        self.file_path = "progress.json"

    def save_progress(self, data):
        with open(self.file_path, 'w') as f:
            json.dump(data, f)
```

### 프로덕션 준비 시

```python
# AWS RDS PostgreSQL 사용
# backend/core/database.py
from sqlalchemy import create_engine

DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://user:pass@rds-endpoint.amazonaws.com/dbname"
)

engine = create_engine(DATABASE_URL)
```

## 📊 결론

**PostgreSQL을 사용하지 않는 것이 아니라, 관리형 PostgreSQL 서비스를 사용하는 것입니다.**

- ✅ **PostgreSQL 엔진 사용**: 동일한 SQL, 동일한 기능
- ✅ **관리 부담 제거**: 백업, 패치, 모니터링 자동화
- ✅ **확장성 확보**: 필요 시 쉽게 스케일업
- ✅ **비용 효율적**: 초기 투자 최소화

프로덕션 환경에서는 안정성과 관리 효율성이 중요하므로, 클라우드 관리형 서비스가 더 적합합니다.

wedosoft: PostgreSQL 에 대해서 더 설명해 주세요. ㅏ그러니까 로컬에 PostgreSQL을 설치하는게 아니고 aws 기반의 PostgreSQL을 사용한다는 건가요?

Workspace: 작업 영역 정보 수집네, 정확히 이해하셨습니다! 로컬에 PostgreSQL을 설치하는 것이 아니라 **AWS가 제공하는 관리형 PostgreSQL 서비스**를 사용한다는 의미입니다.

## 📊 PostgreSQL 사용 방식 비교

### 1. **로컬 PostgreSQL 설치 (전통적 방식)**

```bash
# Mac에서 PostgreSQL 설치
brew install postgresql

# 서버 시작
brew services start postgresql

# 데이터베이스 생성
createdb myapp_db
```

**단점:**

- 백업 스크립트 직접 작성/관리
- 보안 패치 수동 적용
- 서버 장애 시 수동 복구
- 성능 튜닝 직접 수행

### 2. **AWS RDS PostgreSQL (권장 방식)**

```python
# 연결 방식은 동일
import psycopg2

# AWS RDS 엔드포인트로 연결
conn = psycopg2.connect(
    host="mydb.c1234567.us-east-1.rds.amazonaws.com",  # AWS가 제공하는 주소
    database="myapp_db",
    user="postgres",
    password="your_password"
)
```

## 🔍 AWS RDS PostgreSQL 상세 설명

### **RDS란?**

- **Relational Database Service**의 약자
- AWS가 PostgreSQL을 대신 관리해주는 서비스
- PostgreSQL 엔진은 동일, 관리만 AWS가 대행

### **주요 특징**

```yaml
자동 관리 기능:
  - 하드웨어 프로비저닝
  - 데이터베이스 설정
  - 패치 적용
  - 백업 (일일/시점 복구)
  - 모니터링
  - 장애 복구
```

## 💡 실제 사용 예시

### 1. **AWS 콘솔에서 RDS 생성**

```yaml
설정 예시:
  엔진: PostgreSQL 15.4
  인스턴스: db.t3.micro (프리티어)
  스토리지: 20GB SSD
  백업: 7일 보관
  Multi-AZ: 개발-No / 프로덕션-Yes
```

### 2. **프로젝트에서 연결**

```python
# backend/core/database.py
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# AWS RDS PostgreSQL URL
DATABASE_URL = os.getenv(
    "DATABASE_URL",
    "postgresql://username:password@mydb.c1234567.us-east-1.rds.amazonaws.com:5432/project_a"
)

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(bind=engine)
```

### 3. **환경변수 설정**

```bash
# .env.production
DATABASE_URL=postgresql://project_a_user:SecurePass123!@project-a-db.c1234567.us-east-1.rds.amazonaws.com:5432/project_a_db
```

## 🎯 프로젝트 A에서의 활용

### **현재 상황**

```python
# 단순 진행 상황 추적
progress_data = {
    "last_ticket_id": 12345,
    "processed_count": 1000,
    "status": "in_progress"
}
# JSON 파일로 저장 중
```

### **PostgreSQL 도입 시**

```sql
-- 진행 상황 테이블
CREATE TABLE ingest_progress (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(100),
    task_type VARCHAR(50),
    status VARCHAR(20),
    last_processed_id BIGINT,
    processed_count INTEGER,
    error_count INTEGER,
    started_at TIMESTAMP,
    updated_at TIMESTAMP,
    metadata JSONB
);

-- 사용자 활동 로그
CREATE TABLE user_activities (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(100),
    action_type VARCHAR(50),
    ticket_id BIGINT,
    query_text TEXT,
    response_time_ms INTEGER,
    created_at TIMESTAMP
);
```

## 🚀 단계별 도입 전략

### **Phase 1: 개발 단계 (현재)**

```python
# 로컬 개발은 Docker PostgreSQL
docker run -d \
  --name postgres-dev \
  -e POSTGRES_PASSWORD=devpass \
  -p 5432:5432 \
  postgres:15
```

### **Phase 2: MVP 배포**

```yaml
# AWS RDS 최소 사양으로 시작
- 인스턴스: db.t3.micro
- 스토리지: 20GB
- 백업: 일일 1회
- 비용: 월 $15-20
```

### **Phase 3: 프로덕션 확장**

```yaml
# 필요에 따라 업그레이드
- 인스턴스: db.t3.small → db.m5.large
- Read Replica 추가
- Multi-AZ 활성화
- 백업: 지속적 백업 (PITR)
```

## 💰 비용 비교

### **자체 서버에 PostgreSQL**

```yaml
EC2 인스턴스: $10-15/월
관리 시간: 10-20시간/월
백업 스토리지: 추가 비용
모니터링 도구: 추가 구축 필요
```

### **AWS RDS PostgreSQL**

```yaml
db.t3.micro: $15-20/월
자동 백업: 포함
모니터링: CloudWatch 포함
관리 시간: 거의 없음
```

## 🔧 실제 구현 예시

### **진행 상황 추적 개선**

```python
# backend/core/progress_tracker.py
from sqlalchemy import Column, Integer, String, DateTime, JSON
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

class IngestProgress(Base):
    __tablename__ = "ingest_progress"

    id = Column(Integer, primary_key=True)
    company_id = Column(String(100), nullable=False)
    task_type = Column(String(50), nullable=False)
    status = Column(String(20), default="pending")
    last_processed_id = Column(Integer)
    processed_count = Column(Integer, default=0)
    error_count = Column(Integer, default=0)
    started_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, onupdate=datetime.utcnow)
    metadata = Column(JSON)

class ProgressTracker:
    def __init__(self, db_session):
        self.session = db_session

    async def update_progress(self, company_id: str, last_id: int, count: int):
        """진행 상황 업데이트"""
        progress = self.session.query(IngestProgress).filter_by(
            company_id=company_id,
            status="in_progress"
        ).first()

        if progress:
            progress.last_processed_id = last_id
            progress.processed_count += count
            progress.updated_at = datetime.utcnow()
            self.session.commit()
```

## 📌 핵심 정리

**AWS RDS PostgreSQL = PostgreSQL 엔진 + AWS의 관리 서비스**

- ✅ **동일한 PostgreSQL**: SQL, 기능, 성능 모두 동일
- ✅ **관리 부담 제거**: 백업, 패치, 모니터링 자동화
- ✅ **확장성**: 클릭 몇 번으로 성능 업그레이드
- ✅ **안정성**: 자동 장애 복구, Multi-AZ 옵션
- ✅ **비용 효율적**: 관리 인력 불필요

로컬에 PostgreSQL을 설치하고 직접 관리하는 것보다, AWS RDS를 사용하는 것이 프로덕션 환경에서는 훨씬 실용적입니다.

wedosoft: 그럼 현재 상황은 백엔드 프론트 모두 로컬에 있고 벡터디비만 클라우드인 상태입니다. 지금 PostgreSQL을 생성하는게 맞나요? 백엔드 배포는 ec2를 생각하고 있습니다. 어떻게 구성되는 건가요

Workspace: 작업 영역 정보 수집현재 상황을 정리하고 PostgreSQL 도입 시점과 전체 아키텍처를 설명드리겠습니다.

## 🏗️ 현재 상황 및 아키텍처 분석

### 현재 상황

- **백엔드**: 로컬 개발 (Docker)
- **프론트엔드**: 로컬 개발 (FDK)
- **벡터 DB**: Qdrant Cloud ✅
- **파일 저장소**: 로컬 파일 시스템
- **진행 상황 추적**: JSON 파일

### 🤔 PostgreSQL 도입 시점 판단

**지금 당장 필요하지 않습니다.** 이유:

1. **현재 단계 (개발/MVP)**

   - JSON 파일로 충분히 관리 가능
   - 복잡도를 낮게 유지하는 것이 중요
   - 빠른 개발과 테스트에 집중

2. **PostgreSQL이 필요한 시점**
   - EC2 배포 직전 또는 직후
   - 다음 기능들이 필요할 때:
     - 동시 사용자 처리
     - 트랜잭션 관리
     - 복잡한 쿼리 및 리포팅
     - 사용자별 권한 관리

## 🚀 EC2 배포 시 전체 아키텍처

### 1. **개발 환경 (현재)**

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│   로컬 FDK      │────▶│  로컬 FastAPI   │────▶│  Qdrant Cloud   │
│  (프론트엔드)   │     │   (백엔드)      │     │   (벡터 DB)     │
└─────────────────┘     └─────────────────┘     └─────────────────┘
                               │
                               ▼
                        ┌─────────────────┐
                        │  로컬 파일시스템 │
                        │  (JSON 파일)     │
                        └─────────────────┘
```

### 2. **초기 프로덕션 배포 (EC2)**

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  Freshdesk      │────▶│    EC2 인스턴스  │────▶│  Qdrant Cloud   │
│  Custom App     │     │   - FastAPI     │     │   (벡터 DB)     │
└─────────────────┘     │   - Docker      │     └─────────────────┘
                        └─────────────────┘
                               │
                               ▼
                        ┌─────────────────┐
                        │    AWS RDS      │
                        │  (PostgreSQL)   │
                        └─────────────────┘
```

### 3. **확장된 프로덕션 아키텍처**

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────────┐
│  Freshdesk      │────▶│  Load Balancer  │────▶│  Qdrant Cloud   │
│  Custom Apps    │     └─────────────────┘     └─────────────────┘
└─────────────────┘            │
                               ▼
                    ┌─────────────────────┐
                    │   EC2 Auto Scaling  │
                    │  ┌────────────────┐ │
                    │  │ EC2 Instance 1 │ │
                    │  ├────────────────┤ │
                    │  │ EC2 Instance 2 │ │
                    │  └────────────────┘ │
                    └─────────────────────┘
                               │
                    ┌──────────┴──────────┐
                    ▼                     ▼
            ┌─────────────────┐   ┌─────────────────┐
            │    AWS RDS      │   │     AWS S3      │
            │  (PostgreSQL)   │   │  (파일 저장소)  │
            └─────────────────┘   └─────────────────┘
```

## 📋 단계별 구축 가이드

### **Phase 1: 현재 ~ MVP 완성** (PostgreSQL 없음)

```python
# backend/data/simple_tracker.py
class SimpleProgressTracker:
    def __init__(self):
        self.file_path = "progress.json"

    def save_progress(self, data):
        with open(self.file_path, 'w') as f:
            json.dump(data, f)

    def load_progress(self):
        if os.path.exists(self.file_path):
            with open(self.file_path, 'r') as f:
                return json.load(f)
        return {}
```

### **Phase 2: EC2 배포 준비** (PostgreSQL 도입)

#### 1. RDS PostgreSQL 생성

```bash
# AWS CLI로 RDS 생성
aws rds create-db-instance \
  --db-instance-identifier project-a-db \
  --db-instance-class db.t3.micro \
  --engine postgres \
  --engine-version 15.4 \
  --master-username postgres \
  --master-user-password YourSecurePassword \
  --allocated-storage 20 \
  --vpc-security-group-ids sg-xxxxxx
```

#### 2. 데이터베이스 스키마 설계

```sql
-- 진행 상황 추적
CREATE TABLE ingest_progress (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(100) NOT NULL,
    task_type VARCHAR(50) NOT NULL,
    status VARCHAR(20) DEFAULT 'pending',
    total_items INTEGER,
    processed_items INTEGER DEFAULT 0,
    error_count INTEGER DEFAULT 0,
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP,
    metadata JSONB
);

-- 사용자 활동 로그
CREATE TABLE user_activities (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(100) NOT NULL,
    user_email VARCHAR(255),
    action_type VARCHAR(50),
    ticket_id BIGINT,
    query_text TEXT,
    response_time_ms INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- API 사용량 추적
CREATE TABLE api_usage (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(100) NOT NULL,
    endpoint VARCHAR(100),
    method VARCHAR(10),
    status_code INTEGER,
    response_time_ms INTEGER,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

#### 3. SQLAlchemy 모델 정의

```python
# backend/core/models.py
from sqlalchemy import Column, Integer, String, DateTime, JSON
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

class IngestProgress(Base):
    __tablename__ = "ingest_progress"

    id = Column(Integer, primary_key=True)
    company_id = Column(String(100), nullable=False)
    task_type = Column(String(50), nullable=False)
    status = Column(String(20), default="pending")
    total_items = Column(Integer)
    processed_items = Column(Integer, default=0)
    error_count = Column(Integer, default=0)
    started_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, onupdate=datetime.utcnow)
    completed_at = Column(DateTime)
    metadata = Column(JSON)
```

### **Phase 3: EC2 배포**

#### 1. EC2 환경 설정

```bash
# EC2 인스턴스에서
sudo apt-get update
sudo apt-get install docker.io docker-compose

# 환경변수 설정
cat > .env.production << EOF
# Qdrant Cloud (이미 사용 중)
QDRANT_URL=https://your-cluster.cloud.qdrant.io
QDRANT_API_KEY=your-api-key

# AWS RDS PostgreSQL (새로 추가)
DATABASE_URL=postgresql://postgres:password@project-a-db.xxxxx.us-east-1.rds.amazonaws.com:5432/project_a

# AWS S3 (선택사항)
AWS_REGION=ap-northeast-2
S3_BUCKET_NAME=project-a-data
EOF
```

#### 2. Docker Compose 프로덕션 설정

```yaml
# docker-compose.production.yml
version: "3.8"

services:
  backend:
    image: project-a-backend:latest
    ports:
      - "80:8000"
    env_file:
      - .env.production
    volumes:
      - ./logs:/app/logs
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
```

## 🎯 권장 로드맵

### **지금 해야 할 일**

1. ✅ 현재 JSON 기반 시스템으로 MVP 완성
2. ✅ 기능 테스트 및 안정화
3. ✅ 배포 요구사항 정리

### **EC2 배포 시점에 할 일**

1. 🔄 AWS RDS PostgreSQL 생성
2. 🔄 데이터 마이그레이션 스크립트 작성
3. 🔄 EC2 인스턴스 설정 및 배포
4. 🔄 모니터링 설정

### **배포 후 최적화**

1. 🔮 Redis 캐싱 레이어 추가
2. 🔮 CloudFront CDN 설정
3. 🔮 Auto Scaling 설정
4. 🔮 백업 자동화

## 💡 핵심 조언

**지금 PostgreSQL을 도입하지 마세요.** 이유:

- 개발 속도가 느려집니다
- 로컬 환경이 복잡해집니다
- 아직 필요한 기능이 없습니다

**EC2 배포 시점에 PostgreSQL을 도입하세요.** 이유:

- 프로덕션 환경에 적합합니다
- RDS의 관리 기능을 활용할 수 있습니다
- 확장성과 안정성이 필요한 시점입니다

현재는 MVP 완성과 기능 안정화에 집중하시는 것을 추천드립니다!

라이선스 유형이 2개인 유사한 코드가 있습니다.

wedosoft: 좋습니다. 거렇다면 추후 PostgreSQL 를 사용하게 되면 그에 따른 로직 수정이 많이 필요하지 않나요? 로컬로 데이터 수집하다가 PostgreSQL로 변경함에 따른 로직 변경입니다.

Workspace: 작업 영역 정보 수집좋은 질문입니다! PostgreSQL 도입 시 로직 변경을 최소화하는 방법을 설명드리겠습니다.

## 🔄 로직 변경 최소화 전략

### 1. **추상화 레이어 도입 (현재부터 준비)**

#### 현재: 파일 기반 저장

```python
# backend/core/progress_storage.py
from abc import ABC, abstractmethod
import json
import os
from typing import Dict, Optional
from datetime import datetime

class ProgressStorageInterface(ABC):
    """진행 상황 저장소 인터페이스"""

    @abstractmethod
    async def save_progress(self, company_id: str, task_type: str, data: Dict) -> None:
        pass

    @abstractmethod
    async def get_progress(self, company_id: str, task_type: str) -> Optional[Dict]:
        pass

    @abstractmethod
    async def update_status(self, company_id: str, task_type: str, status: str) -> None:
        pass

class FileProgressStorage(ProgressStorageInterface):
    """파일 기반 진행 상황 저장소 구현"""

    def __init__(self, base_path: str = "./progress_data"):
        self.base_path = base_path
        os.makedirs(base_path, exist_ok=True)

    async def save_progress(self, company_id: str, task_type: str, data: Dict) -> None:
        file_path = os.path.join(self.base_path, f"{company_id}_{task_type}.json")
        data['updated_at'] = datetime.utcnow().isoformat()

        with open(file_path, 'w') as f:
            json.dump(data, f, indent=2)

    async def get_progress(self, company_id: str, task_type: str) -> Optional[Dict]:
        file_path = os.path.join(self.base_path, f"{company_id}_{task_type}.json")

        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                return json.load(f)
        return None

    async def update_status(self, company_id: str, task_type: str, status: str) -> None:
        data = await self.get_progress(company_id, task_type) or {}
        data['status'] = status
        await self.save_progress(company_id, task_type, data)
```

#### 미래: PostgreSQL 저장소 (나중에 추가)

```python
# backend/core/progress_storage.py (추가 구현)
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update

class PostgreSQLProgressStorage(ProgressStorageInterface):
    """PostgreSQL 기반 진행 상황 저장소 구현"""

    def __init__(self, session_factory):
        self.session_factory = session_factory

    async def save_progress(self, company_id: str, task_type: str, data: Dict) -> None:
        async with self.session_factory() as session:
            # IngestProgress 모델 사용
            progress = IngestProgress(
                company_id=company_id,
                task_type=task_type,
                status=data.get('status', 'pending'),
                total_items=data.get('total_items'),
                processed_items=data.get('processed_items', 0),
                metadata=data
            )
            session.add(progress)
            await session.commit()

    async def get_progress(self, company_id: str, task_type: str) -> Optional[Dict]:
        async with self.session_factory() as session:
            result = await session.execute(
                select(IngestProgress).where(
                    IngestProgress.company_id == company_id,
                    IngestProgress.task_type == task_type
                )
            )
            progress = result.scalar_one_or_none()

            if progress:
                return {
                    'status': progress.status,
                    'total_items': progress.total_items,
                    'processed_items': progress.processed_items,
                    'metadata': progress.metadata
                }
            return None
```

### 2. **팩토리 패턴으로 쉬운 전환**

```python
# backend/core/dependencies.py
from enum import Enum
from .progress_storage import FileProgressStorage, PostgreSQLProgressStorage

class StorageType(Enum):
    FILE = "file"
    POSTGRESQL = "postgresql"

class StorageFactory:
    """저장소 구현체를 생성하는 팩토리"""

    @staticmethod
    def create_progress_storage(
        storage_type: StorageType = StorageType.FILE,
        **kwargs
    ) -> ProgressStorageInterface:

        if storage_type == StorageType.FILE:
            return FileProgressStorage(**kwargs)
        elif storage_type == StorageType.POSTGRESQL:
            return PostgreSQLProgressStorage(**kwargs)
        else:
            raise ValueError(f"Unsupported storage type: {storage_type}")

# 의존성 주입
def get_progress_storage() -> ProgressStorageInterface:
    """현재는 파일, 나중에는 PostgreSQL로 쉽게 전환"""
    storage_type = StorageType(os.getenv("STORAGE_TYPE", "file"))

    if storage_type == StorageType.FILE:
        return StorageFactory.create_progress_storage(storage_type)
    else:
        # PostgreSQL 설정
        session_factory = get_db_session_factory()
        return StorageFactory.create_progress_storage(
            storage_type,
            session_factory=session_factory
        )
```

### 3. **비즈니스 로직은 변경 없음**

```python
# backend/api/ingest.py
from fastapi import Depends
from ..core.dependencies import get_progress_storage
from ..core.progress_storage import ProgressStorageInterface

async def ingest(
    # ... 기존 파라미터들 ...
    progress_storage: ProgressStorageInterface = Depends(get_progress_storage)
) -> None:
    """
    데이터 수집 함수 - 저장소 구현체와 무관하게 동작
    """
    # 진행 상황 저장 - 인터페이스만 사용
    await progress_storage.save_progress(
        company_id=DEFAULT_COMPANY_ID,
        task_type="ingest",
        data={
            "status": "in_progress",
            "total_items": total_count,
            "processed_items": 0
        }
    )

    # 처리 중...
    for batch in batches:
        # 배치 처리
        processed_count += len(batch)

        # 진행 상황 업데이트 - 동일한 인터페이스
        await progress_storage.update_status(
            company_id=DEFAULT_COMPANY_ID,
            task_type="ingest",
            status=f"processed_{processed_count}"
        )
```

## 🚀 단계별 전환 계획

### **Phase 1: 현재 (파일 기반)**

```bash
# .env
STORAGE_TYPE=file
```

### **Phase 2: PostgreSQL 도입 시**

```bash
# .env.production
STORAGE_TYPE=postgresql
DATABASE_URL=postgresql://user:pass@rds.amazonaws.com/db
```

**필요한 작업:**

1. PostgreSQLProgressStorage 클래스 구현 (이미 준비된 인터페이스 사용)
2. 데이터베이스 모델 정의 (SQLAlchemy)
3. 환경변수만 변경

## 📊 변경 영향도 분석

### **변경 필요 없음** ✅

- API 엔드포인트 로직
- 비즈니스 로직
- 벡터 DB 연동
- 프론트엔드

### **최소 변경 필요** 🔄

- 의존성 주입 설정
- 환경변수 추가
- 데이터베이스 모델 정의

### **신규 추가** 🆕

- PostgreSQL 저장소 구현체
- 마이그레이션 스크립트 (기존 파일 → DB)

## 💡 실제 구현 예시

### 현재 사용할 간단한 추상화

```python
# backend/core/simple_storage.py
class SimpleStorage:
    """단순한 추상화 레이어"""

    def __init__(self, use_db: bool = False):
        self.use_db = use_db
        self.data_dir = "./progress_data"

    async def save(self, key: str, data: Dict) -> None:
        if self.use_db:
            # 미래: DB 저장
            # await db.save(key, data)
            pass
        else:
            # 현재: 파일 저장
            os.makedirs(self.data_dir, exist_ok=True)
            with open(f"{self.data_dir}/{key}.json", 'w') as f:
                json.dump(data, f)

    async def load(self, key: str) -> Optional[Dict]:
        if self.use_db:
            # 미래: DB 조회
            # return await db.get(key)
            pass
        else:
            # 현재: 파일 읽기
            file_path = f"{self.data_dir}/{key}.json"
            if os.path.exists(file_path):
                with open(file_path, 'r') as f:
                    return json.load(f)
            return None
```

## 🎯 핵심 권장사항

1. **지금부터 추상화 사용**

   - 파일 직접 접근 대신 추상화 레이어 통해 접근
   - 나중에 구현체만 교체하면 됨

2. **환경변수로 전환 제어**

   - `STORAGE_TYPE=file` (현재)
   - `STORAGE_TYPE=postgresql` (미래)

3. **점진적 마이그레이션**
   - 새로운 데이터는 PostgreSQL로
   - 기존 데이터는 마이그레이션 스크립트로 이전

이렇게 준비하면 PostgreSQL 도입 시 **비즈니스 로직 변경 없이** 저장소 구현체만 추가하면 됩니다!

wedosoft: 추상화 레이어란게 어떤건가요?

GitHub Copilot: 추상화 레이어(Abstraction Layer)는 **복잡한 구현 세부사항을 숨기고 단순한 인터페이스를 제공하는 프로그래밍 패턴**입니다.

## 🎯 추상화 레이어의 핵심 개념

### 1. **기본 개념**

- 복잡한 로직을 간단한 인터페이스 뒤에 숨김
- 구현 세부사항의 변경이 사용하는 코드에 영향을 주지 않도록 함
- "무엇을 하는가"와 "어떻게 하는가"를 분리

### 2. **현재 프로젝트에서의 예시**

#### ❌ 추상화 없는 코드 (현재 상황)

```python
# 데이터 수집 시 직접 파일 시스템 접근
import json
import os

def save_progress(company_id: str, data: dict):
    # 파일 시스템에 직접 접근
    file_path = f"./progress_data/{company_id}.json"
    with open(file_path, 'w') as f:
        json.dump(data, f)

def load_progress(company_id: str):
    # 파일 시스템에 직접 접근
    file_path = f"./progress_data/{company_id}.json"
    if os.path.exists(file_path):
        with open(file_path, 'r') as f:
            return json.load(f)
    return None
```

#### ✅ 추상화 레이어를 적용한 코드

```python
# 추상화 인터페이스 정의
from abc import ABC, abstractmethod

class ProgressStorageInterface(ABC):
    """진행 상황 저장소의 추상 인터페이스"""

    @abstractmethod
    async def save(self, company_id: str, data: dict) -> None:
        """데이터를 저장합니다"""
        pass

    @abstractmethod
    async def load(self, company_id: str) -> dict:
        """데이터를 불러옵니다"""
        pass

# 파일 시스템 구현
class FileProgressStorage(ProgressStorageInterface):
    async def save(self, company_id: str, data: dict) -> None:
        file_path = f"./progress_data/{company_id}.json"
        with open(file_path, 'w') as f:
            json.dump(data, f)

    async def load(self, company_id: str) -> dict:
        file_path = f"./progress_data/{company_id}.json"
        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                return json.load(f)
        return None

# PostgreSQL 구현 (나중에 추가)
class PostgreSQLProgressStorage(ProgressStorageInterface):
    async def save(self, company_id: str, data: dict) -> None:
        # PostgreSQL에 저장하는 로직
        await self.db.execute(
            "INSERT INTO progress ..."
        )

    async def load(self, company_id: str) -> dict:
        # PostgreSQL에서 불러오는 로직
        result = await self.db.fetch(
            "SELECT * FROM progress WHERE company_id = $1",
            company_id
        )
        return result
```

### 3. **사용하는 코드는 변경 없음**

```python
# 비즈니스 로직에서 사용
async def ingest_data(
    company_id: str,
    storage: ProgressStorageInterface  # 추상 인터페이스만 알면 됨
):
    # 저장소가 파일이든 DB든 상관없이 동일한 방식으로 사용
    progress_data = {
        "status": "in_progress",
        "processed": 0,
        "total": 1000
    }

    # 구현체가 무엇인지 몰라도 됨
    await storage.save(company_id, progress_data)

    # 나중에 불러올 때도 동일
    saved_data = await storage.load(company_id)
```

## 📊 추상화 레이어의 장점

### 1. **유연성**

- 파일 저장에서 DB 저장으로 쉽게 전환 가능
- 비즈니스 로직 코드 수정 불필요

### 2. **테스트 용이성**

```python
# 테스트용 메모리 저장소
class MemoryProgressStorage(ProgressStorageInterface):
    def __init__(self):
        self.data = {}

    async def save(self, company_id: str, data: dict):
        self.data[company_id] = data

    async def load(self, company_id: str):
        return self.data.get(company_id)

# 테스트에서 사용
async def test_ingest():
    storage = MemoryProgressStorage()  # 실제 파일/DB 없이 테스트
    await ingest_data("test_company", storage)
```

### 3. **확장성**

- 나중에 Redis, MongoDB 등 다른 저장소 추가 가능
- 기존 코드 수정 없이 새로운 구현체만 추가

## 🎯 현재 프로젝트에 적용하면

```python
# 환경변수로 저장소 타입 선택
STORAGE_TYPE = os.getenv("STORAGE_TYPE", "file")

# 저장소 생성
if STORAGE_TYPE == "file":
    storage = FileProgressStorage()
elif STORAGE_TYPE == "postgresql":
    storage = PostgreSQLProgressStorage()
else:
    storage = MemoryProgressStorage()

# 모든 곳에서 동일하게 사용
await storage.save(company_id, data)
```

이렇게 하면 나중에 PostgreSQL로 전환할 때 환경변수만 바꾸면 되고, 비즈니스 로직은 전혀 수정하지 않아도 됩니다!

wedosoft: 좋습니다. 이제 데이터 자정방식에 대해서 논의합시다. 마크다운 문서에 있다시피

- 데이터 수집시 티켓+세부+대화+첨부파일을 하나의 문서로 만들어 파일로 저장 (청크 분할 포함)
- llm을 사용하여 각 티켓의 전체 텍스트를 분석하여 Issues/ Solution 으로 요약 및 파일 업데이트
- 이후 벡터디비에 티켓 원본 텍스트는 메타데이터로 저장하고 임베딩된 issue/solution을 벡터디비에 저장
  이 절차로 판단됩니다. 그런데 문제는 llm을 호출하여 티켓 요약하는 작업인데 이 부분을 로컬에서 파일 기반으로 하는 경우와 PostgreSQL에 배포하여 하는 경우에 따른 대비가 필요보입니다. 어떤 절차와 순서가 적합할지 제언주세요.

GitHub Copilot: 네, 데이터 수집 방식에 대해 LLM 요약 작업을 고려한 절차를 제안드리겠습니다.

## 📌 데이터 수집 및 LLM 요약 절차 설계

### 1. **현재 MVP 단계 (파일 기반)**

#### 📂 파일 구조

```
project-a/
├── data/
│   ├── raw/              # 원본 데이터
│   │   ├── tickets/      # 티켓+대화+첨부파일 병합 JSON
│   │   └── kb/           # 지식베이스 문서
│   ├── processed/        # LLM 요약된 데이터
│   │   ├── tickets/      # 요약 추가된 JSON
│   │   └── kb/
│   └── progress/         # 진행 상황 추적
│       └── summary_progress.json
```

#### 🔄 처리 절차

```python
# backend/data/pipeline/ticket_processor.py

class TicketProcessor:
    def __init__(self, storage: StorageInterface):
        self.storage = storage
        self.llm_client = get_llm_client()

    async def process_ticket_batch(self, batch_size: int = 10):
        """티켓 배치 처리 (수집 → 병합 → 요약 → 저장)"""

        # 1. 원본 데이터 수집 및 병합
        raw_tickets = await self.collect_and_merge_tickets(batch_size)

        # 2. 병합된 데이터를 raw 폴더에 저장
        for ticket in raw_tickets:
            await self.storage.save(
                f"raw/tickets/{ticket['id']}.json",
                ticket
            )

        # 3. LLM 요약 처리 (청크 단위)
        for ticket in raw_tickets:
            # 진행 상황 체크 (중복 처리 방지)
            if await self.is_already_processed(ticket['id']):
                continue

            # 티켓 텍스트 준비 (청크 분할 포함)
            chunks = self.split_into_chunks(ticket)

            # LLM 요약 생성
            summary = await self.generate_summary(chunks)

            # 요약 추가하여 processed 폴더에 저장
            ticket['llm_summary'] = summary
            await self.storage.save(
                f"processed/tickets/{ticket['id']}.json",
                ticket
            )

            # 진행 상황 업데이트
            await self.update_progress(ticket['id'])
```

### 2. **프로덕션 단계 (PostgreSQL 기반)**

#### 🗄️ 데이터베이스 스키마

```sql
-- 티켓 원본 및 처리 상태 관리
CREATE TABLE tickets (
    id BIGINT PRIMARY KEY,
    company_id VARCHAR(100) NOT NULL,
    raw_data JSONB NOT NULL,           -- 원본 티켓+대화+첨부파일
    llm_summary JSONB,                 -- LLM 요약 결과
    processing_status VARCHAR(50) DEFAULT 'pending',
    processed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_company_status (company_id, processing_status)
);

-- 처리 진행 상황 추적
CREATE TABLE processing_queue (
    id SERIAL PRIMARY KEY,
    ticket_id BIGINT NOT NULL,
    company_id VARCHAR(100) NOT NULL,
    status VARCHAR(50) DEFAULT 'queued',
    retry_count INTEGER DEFAULT 0,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_queue_status (status, created_at)
);
```

#### 🔄 처리 절차 (확장 가능한 구조)

```python
# backend/data/pipeline/scalable_processor.py

class ScalableTicketProcessor:
    def __init__(self, db_session, storage_type: str = "postgresql"):
        self.db = db_session
        self.llm_client = get_llm_client()
        self.storage_type = storage_type

    async def process_tickets_async(self):
        """비동기 큐 기반 티켓 처리"""

        while True:
            # 1. 처리할 티켓 가져오기 (큐에서)
            tickets = await self.fetch_pending_tickets(limit=10)

            if not tickets:
                await asyncio.sleep(30)  # 대기
                continue

            # 2. 병렬 처리
            tasks = [
                self.process_single_ticket(ticket)
                for ticket in tickets
            ]
            await asyncio.gather(*tasks, return_exceptions=True)

    async def process_single_ticket(self, ticket):
        """개별 티켓 처리"""
        try:
            # 1. 상태 업데이트 (처리 중)
            await self.update_status(ticket.id, "processing")

            # 2. LLM 요약 생성
            summary = await self.generate_summary_with_retry(
                ticket.raw_data
            )

            # 3. 결과 저장
            await self.save_summary(ticket.id, summary)

            # 4. 벡터 DB에 저장
            await self.store_to_vector_db(ticket, summary)

            # 5. 상태 업데이트 (완료)
            await self.update_status(ticket.id, "completed")

        except Exception as e:
            await self.handle_error(ticket.id, e)
```

## 🎯 단계별 마이그레이션 전략

### **Phase 1: MVP (현재)**

```python
# 간단한 파일 기반 처리
processor = TicketProcessor(FileStorage())
await processor.process_ticket_batch(100)
```

### **Phase 2: 하이브리드 (전환기)**

```python
# 파일과 DB 동시 사용
class HybridProcessor:
    def __init__(self):
        self.file_storage = FileStorage()
        self.db_storage = PostgreSQLStorage()

    async def process(self):
        # 파일에서 읽어서 DB로 마이그레이션
        raw_files = await self.file_storage.list("raw/tickets/")

        for file_path in raw_files:
            data = await self.file_storage.load(file_path)

            # DB에 저장 (중복 체크)
            if not await self.db_storage.exists(data['id']):
                await self.db_storage.save_ticket(data)
```

### **Phase 3: 프로덕션 (최종)**

```python
# 완전한 DB 기반 + 큐 시스템
processor = ScalableTicketProcessor(db_session)

# 여러 워커로 분산 처리
workers = [
    asyncio.create_task(processor.process_tickets_async())
    for _ in range(4)  # 4개 워커
]
```

## 💡 핵심 고려사항

### 1. **LLM 비용 최적화**

```python
class LLMOptimizer:
    def should_process(self, ticket):
        """처리 필요 여부 판단"""
        # 이미 처리됨
        if ticket.get('llm_summary'):
            return False

        # 너무 짧은 티켓
        if len(ticket['content']) < 100:
            return False

        # 자동 생성 티켓
        if ticket.get('is_automated'):
            return False

        return True
```

### 2. **청크 처리 전략**

```python
def split_into_chunks(self, ticket, max_tokens=2000):
    """긴 티켓을 청크로 분할"""
    content = self.extract_full_content(ticket)

    # 토큰 카운트 기반 분할
    chunks = []
    current_chunk = []
    current_tokens = 0

    for paragraph in content.split('\n\n'):
        tokens = self.count_tokens(paragraph)

        if current_tokens + tokens > max_tokens:
            chunks.append('\n\n'.join(current_chunk))
            current_chunk = [paragraph]
            current_tokens = tokens
        else:
            current_chunk.append(paragraph)
            current_tokens += tokens

    if current_chunk:
        chunks.append('\n\n'.join(current_chunk))

    return chunks
```

### 3. **진행 상황 추적**

```python
class ProgressTracker:
    async def get_summary_stats(self, company_id: str):
        """요약 처리 진행 상황"""
        return {
            "total_tickets": await self.count_total(company_id),
            "processed": await self.count_processed(company_id),
            "pending": await self.count_pending(company_id),
            "failed": await self.count_failed(company_id),
            "progress_percentage": await self.calculate_progress(company_id)
        }
```

## 📊 권장 실행 순서

### **즉시 시작 (MVP)**

1. 파일 기반 수집기 구현
2. 간단한 LLM 요약 함수 작성
3. 진행 상황 JSON 파일로 추적
4. 소규모 배치로 테스트 (10-100개)

### **다음 단계 (확장)**

1. PostgreSQL 스키마 설계
2. 비동기 큐 시스템 구현
3. 재시도 로직 추가
4. 모니터링 대시보드

### **최종 목표 (프로덕션)**

1. 분산 처리 시스템
2. 실시간 진행 상황 모니터링
3. 자동 오류 복구
4. 비용 최적화 로직

이렇게 단계별로 접근하면 MVP에서 빠르게 시작하면서도 향후 확장을 고려한 구조를 유지할 수 있습니다. 어떤 부분부터 구현을 시작하시겠습니까?

wedosoft: 좋습니다. 지금까지 논의한 내용을 마크다운 파일로 상세히 모두 반영하여 만들어주세요. 지침서로 사용하겠습니다.

GitHub Copilot: 네, 지금까지 논의한 내용을 종합하여 상세한 지침서를 작성하겠습니다.

```markdown
# 📚 Copilot RAG 시스템 최종 구현 지침서 v3

이 문서는 Freshdesk 기반 Copilot 시스템의 데이터 수집, 처리, 저장 및 추천 기능 구현을 위한 최종 지침서입니다.

---

## 📌 시스템 전체 아키텍처

### 🎯 목표

- Freshdesk 티켓 데이터를 수집하여 LLM 요약 생성
- 유사 티켓 추천 및 솔루션 제공
- 피드백 기반 추천 정확도 개선
- SaaS 확장성을 고려한 멀티테넌트 구조

### 🔄 전체 데이터 흐름
```

[Step 1] 데이터 수집 (티켓+대화+첨부파일) →
[Step 2] 하나의 문서로 병합 →
[Step 3] LLM 요약 (이슈/해결 요약) →
[Step 4] 임베딩 생성 →
[Step 5] Vector DB 저장 →
[Step 6] Copilot UI에서 추천 →
[Step 7] 피드백 수집 및 반영

```

---

## 1. 데이터 수집 및 병합 아키텍처

### 1.1 MVP 단계 (현재) - 파일 기반

#### 📂 디렉토리 구조
```

project-a/
├── data/
│ ├── raw/ # 원본 데이터
│ │ ├── tickets/ # 병합된 티켓 JSON
│ │ └── kb/ # 지식베이스 문서
│ ├── processed/ # LLM 요약된 데이터
│ │ ├── tickets/  
│ │ └── kb/
│ └── progress/ # 진행 상황 추적
│ └── progress.json

````

#### 🔧 데이터 병합 로직
```python
# backend/data/ingest.py
from typing import Dict, Any, List
import hashlib
import json
from pathlib import Path

class TicketMerger:
    """티켓 데이터 병합 클래스"""

    def merge_ticket_data(
        self,
        ticket: dict,
        conversations: list,
        attachments: list
    ) -> dict:
        """
        티켓 원본, 대화 내역, 첨부파일을 하나의 문서로 병합

        Args:
            ticket: 티켓 원본 데이터
            conversations: 대화 내역 리스트
            attachments: 첨부파일 메타데이터 리스트

        Returns:
            병합된 티켓 문서
        """
        # 대화 내용을 텍스트로 병합
        conversation_text = "\n\n".join([
            f"[{conv.get('created_at')}] {conv.get('body', '')}"
            for conv in conversations
        ])

        merged_document = {
            "original_id": str(ticket["id"]),
            "doc_type": "ticket",
            "subject": ticket.get("subject", ""),
            "description": ticket.get("description", ""),
            "merged_content": f"{ticket.get('description', '')}\n\n{conversation_text}",
            "conversations": conversations,
            "attachments": [
                {
                    "attachment_id": str(att["id"]),
                    "file_name": att["name"],
                    "content_type": att["content_type"],
                    "url": att["attachment_url"]
                } for att in attachments
            ],
            "metadata": {
                "status": ticket.get("status"),
                "priority": ticket.get("priority"),
                "created_at": ticket.get("created_at"),
                "updated_at": ticket.get("updated_at"),
                "tags": ticket.get("tags", [])
            }
        }

        return merged_document

    def generate_document_hash(self, document: dict) -> str:
        """문서의 해시값 생성 (중복/변경 감지용)"""
        doc_str = json.dumps(document, sort_keys=True, ensure_ascii=False)
        return hashlib.sha256(doc_str.encode('utf-8')).hexdigest()
````

### 1.2 프로덕션 단계 - 클라우드 기반

#### 🗄️ 데이터베이스 설계

```sql
-- PostgreSQL 스키마 설계
-- 티켓 원본 및 처리 상태 관리
CREATE TABLE tickets (
    id BIGINT PRIMARY KEY,
    company_id VARCHAR(100) NOT NULL,
    raw_data JSONB NOT NULL,           -- 원본 티켓+대화+첨부파일
    llm_summary JSONB,                 -- LLM 요약 결과
    processing_status VARCHAR(50) DEFAULT 'pending',
    processed_at TIMESTAMP,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    hash VARCHAR(64) NOT NULL,         -- 중복/변경 감지용
    INDEX idx_company_status (company_id, processing_status),
    INDEX idx_hash (hash)
);

-- LLM 처리 큐
CREATE TABLE processing_queue (
    id SERIAL PRIMARY KEY,
    ticket_id BIGINT NOT NULL,
    company_id VARCHAR(100) NOT NULL,
    status VARCHAR(50) DEFAULT 'queued',
    retry_count INTEGER DEFAULT 0,
    error_message TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_queue_status (status, created_at)
);

-- 피드백 데이터
CREATE TABLE feedback (
    id SERIAL PRIMARY KEY,
    company_id VARCHAR(100) NOT NULL,
    query_id VARCHAR(255),
    recommended_ticket_ids JSONB,
    feedback_type VARCHAR(20), -- 'positive' or 'negative'
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    INDEX idx_company_feedback (company_id, timestamp)
);
```

---

## 2. LLM 요약 처리

### 2.1 요약 생성 로직

```python
# backend/core/llm_summarizer.py
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
import asyncio
from typing import List, Dict, Any

class TicketSummarizer:
    """티켓 요약 생성 클래스"""

    def __init__(self, llm_client):
        self.llm = llm_client
        self.summary_prompt = ChatPromptTemplate.from_template("""
당신은 고객 지원 티켓을 분석하는 전문가입니다.
다음 티켓 내용을 분석하여 구조화된 요약을 생성해주세요.

티켓 내용:
{ticket_content}

다음 형식으로 요약해주세요:
1. 문제 (Problem): 고객이 겪고 있는 주요 문제
2. 원인 (Cause): 문제의 근본 원인
3. 해결방법 (Solution): 제시된 해결 방법
4. 결과 (Result): 최종 해결 여부 및 결과

JSON 형식으로 응답해주세요.
""")

    async def summarize_ticket(self, merged_document: Dict[str, Any]) -> Dict[str, Any]:
        """단일 티켓 요약 생성"""
        try:
            # 티켓 전체 텍스트 준비
            ticket_content = merged_document['merged_content']

            # 텍스트가 너무 긴 경우 청크로 분할
            if len(ticket_content) > 10000:  # 약 2500 토큰
                chunks = self.split_into_chunks(ticket_content)
                summaries = await asyncio.gather(*[
                    self._generate_chunk_summary(chunk)
                    for chunk in chunks
                ])
                # 청크 요약들을 통합
                final_summary = await self._merge_summaries(summaries)
            else:
                # 직접 요약 생성
                final_summary = await self._generate_summary(ticket_content)

            # 문서에 요약 추가
            merged_document['llm_summary'] = final_summary
            merged_document['summary_generated_at'] = datetime.utcnow().isoformat()

            return merged_document

        except Exception as e:
            print(f"요약 생성 실패: {e}")
            merged_document['llm_summary'] = {
                "problem": "요약 생성 실패",
                "cause": str(e),
                "solution": "수동 검토 필요",
                "result": "처리 실패"
            }
            return merged_document

    def split_into_chunks(self, text: str, max_chars: int = 8000) -> List[str]:
        """긴 텍스트를 청크로 분할"""
        chunks = []
        paragraphs = text.split('\n\n')
        current_chunk = []
        current_length = 0

        for paragraph in paragraphs:
            if current_length + len(paragraph) > max_chars:
                chunks.append('\n\n'.join(current_chunk))
                current_chunk = [paragraph]
                current_length = len(paragraph)
            else:
                current_chunk.append(paragraph)
                current_length += len(paragraph)

        if current_chunk:
            chunks.append('\n\n'.join(current_chunk))

        return chunks
```

### 2.2 배치 처리 및 비용 최적화

```python
# backend/data/batch_processor.py
class BatchProcessor:
    """배치 단위 LLM 처리"""

    def __init__(self, storage, llm_summarizer):
        self.storage = storage
        self.summarizer = llm_summarizer
        self.batch_size = 10
        self.max_concurrent = 5  # 동시 처리 수 제한

    async def process_pending_tickets(self, company_id: str):
        """대기 중인 티켓들을 배치로 처리"""
        while True:
            # 처리할 티켓 가져오기
            pending_tickets = await self.storage.get_pending_tickets(
                company_id=company_id,
                limit=self.batch_size
            )

            if not pending_tickets:
                break

            # 동시성 제한을 두고 병렬 처리
            semaphore = asyncio.Semaphore(self.max_concurrent)

            async def process_with_limit(ticket):
                async with semaphore:
                    return await self.process_single_ticket(ticket)

            # 배치 처리
            results = await asyncio.gather(*[
                process_with_limit(ticket)
                for ticket in pending_tickets
            ], return_exceptions=True)

            # 결과 저장
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    await self.handle_error(pending_tickets[i], result)
                else:
                    await self.storage.save_processed_ticket(result)

            # 진행 상황 업데이트
            await self.update_progress(company_id, len(results))
```

---

## 3. 벡터 저장 및 검색

### 3.1 임베딩 생성 및 저장

```python
# backend/core/embedding_manager.py
from langchain.embeddings import OpenAIEmbeddings
from qdrant_client import QdrantClient
from qdrant_client.models import PointStruct, VectorParams, Distance
import uuid

class EmbeddingManager:
    """임베딩 생성 및 벡터 DB 관리"""

    def __init__(self, qdrant_url: str, api_key: str):
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        self.qdrant = QdrantClient(url=qdrant_url, api_key=api_key)

    async def store_ticket_embeddings(self, processed_ticket: Dict[str, Any], company_id: str):
        """처리된 티켓을 벡터 DB에 저장"""

        # 요약된 텍스트로 임베딩 생성
        summary_text = json.dumps(processed_ticket['llm_summary'], ensure_ascii=False)
        embedding = await self.embeddings.aembed_query(summary_text)

        # Qdrant 포인트 생성
        point = PointStruct(
            id=str(uuid.uuid4()),
            vector=embedding,
            payload={
                "original_id": processed_ticket["original_id"],
                "doc_type": "ticket",
                "company_id": company_id,
                "subject": processed_ticket["subject"],
                "summary": processed_ticket["llm_summary"],
                "metadata": processed_ticket["metadata"],
                "created_at": processed_ticket.get("created_at"),
                "processed_at": datetime.utcnow().isoformat()
            }
        )

        # 컬렉션에 저장
        collection_name = f"tickets_{company_id}"
        await self.ensure_collection_exists(collection_name)

        self.qdrant.upsert(
            collection_name=collection_name,
            points=[point]
        )

    async def search_similar_tickets(
        self,
        query: str,
        company_id: str,
        limit: int = 5
    ) -> List[Dict[str, Any]]:
        """유사 티켓 검색"""

        # 쿼리 임베딩 생성
        query_embedding = await self.embeddings.aembed_query(query)

        # 벡터 검색
        collection_name = f"tickets_{company_id}"
        results = self.qdrant.search(
            collection_name=collection_name,
            query_vector=query_embedding,
            limit=limit,
            with_payload=True
        )

        # 결과 포맷팅
        similar_tickets = []
        for result in results:
            similar_tickets.append({
                "ticket_id": result.payload["original_id"],
                "subject": result.payload["subject"],
                "summary": result.payload["summary"],
                "similarity_score": result.score,
                "metadata": result.payload.get("metadata", {})
            })

        return similar_tickets
```

---

## 4. 추상화 레이어 설계

### 4.1 스토리지 인터페이스

```python
# backend/core/storage_interface.py
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional

class StorageInterface(ABC):
    """스토리지 추상 인터페이스"""

    @abstractmethod
    async def save_ticket(self, ticket_data: Dict[str, Any]) -> None:
        """티켓 데이터 저장"""
        pass

    @abstractmethod
    async def get_ticket(self, ticket_id: str, company_id: str) -> Optional[Dict[str, Any]]:
        """티켓 데이터 조회"""
        pass

    @abstractmethod
    async def get_pending_tickets(self, company_id: str, limit: int) -> List[Dict[str, Any]]:
        """처리 대기 중인 티켓 목록 조회"""
        pass

    @abstractmethod
    async def update_ticket_status(self, ticket_id: str, company_id: str, status: str) -> None:
        """티켓 처리 상태 업데이트"""
        pass

    @abstractmethod
    async def save_progress(self, company_id: str, progress_data: Dict[str, Any]) -> None:
        """진행 상황 저장"""
        pass
```

### 4.2 파일 기반 구현 (MVP)

```python
# backend/core/file_storage.py
import json
import os
from pathlib import Path
from typing import Dict, Any, List, Optional
from .storage_interface import StorageInterface

class FileStorage(StorageInterface):
    """파일 기반 스토리지 구현"""

    def __init__(self, base_path: str = "./data"):
        self.base_path = Path(base_path)
        self.base_path.mkdir(parents=True, exist_ok=True)

    async def save_ticket(self, ticket_data: Dict[str, Any]) -> None:
        company_id = ticket_data.get("company_id", "default")
        ticket_id = ticket_data["original_id"]

        # 디렉토리 생성
        ticket_dir = self.base_path / "raw" / "tickets" / company_id
        ticket_dir.mkdir(parents=True, exist_ok=True)

        # 파일 저장
        file_path = ticket_dir / f"{ticket_id}.json"
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(ticket_data, f, ensure_ascii=False, indent=2)

    async def get_ticket(self, ticket_id: str, company_id: str) -> Optional[Dict[str, Any]]:
        file_path = self.base_path / "raw" / "tickets" / company_id / f"{ticket_id}.json"

        if file_path.exists():
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None

    async def get_pending_tickets(self, company_id: str, limit: int) -> List[Dict[str, Any]]:
        raw_dir = self.base_path / "raw" / "tickets" / company_id
        processed_dir = self.base_path / "processed" / "tickets" / company_id

        if not raw_dir.exists():
            return []

        pending_tickets = []
        for file_path in raw_dir.glob("*.json"):
            ticket_id = file_path.stem
            processed_path = processed_dir / f"{ticket_id}.json"

            # 아직 처리되지 않은 티켓만 선택
            if not processed_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    ticket_data = json.load(f)
                    pending_tickets.append(ticket_data)

                if len(pending_tickets) >= limit:
                    break

        return pending_tickets
```

### 4.3 PostgreSQL 구현 (프로덕션)

```python
# backend/core/postgres_storage.py
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker
from sqlalchemy import select, update
from .storage_interface import StorageInterface
from .models import Ticket, ProcessingQueue

class PostgresStorage(StorageInterface):
    """PostgreSQL 기반 스토리지 구현"""

    def __init__(self, database_url: str):
        self.engine = create_async_engine(database_url)
        self.async_session = sessionmaker(
            self.engine, class_=AsyncSession, expire_on_commit=False
        )

    async def save_ticket(self, ticket_data: Dict[str, Any]) -> None:
        async with self.async_session() as session:
            # 기존 티켓 확인
            existing = await session.get(Ticket, ticket_data["original_id"])

            if existing:
                # 해시 비교하여 변경된 경우만 업데이트
                new_hash = self._generate_hash(ticket_data)
                if existing.hash != new_hash:
                    existing.raw_data = ticket_data
                    existing.hash = new_hash
                    existing.processing_status = 'pending'
                    existing.updated_at = datetime.utcnow()
            else:
                # 새 티켓 생성
                ticket = Ticket(
                    id=int(ticket_data["original_id"]),
                    company_id=ticket_data["company_id"],
                    raw_data=ticket_data,
                    hash=self._generate_hash(ticket_data),
                    processing_status='pending'
                )
                session.add(ticket)

            await session.commit()

    async def get_pending_tickets(self, company_id: str, limit: int) -> List[Dict[str, Any]]:
        async with self.async_session() as session:
            query = select(Ticket).where(
                Ticket.company_id == company_id,
                Ticket.processing_status == 'pending'
            ).limit(limit)

            result = await session.execute(query)
            tickets = result.scalars().all()

            return [ticket.raw_data for ticket in tickets]
```

---

## 5. 멀티테넌트 및 멀티플랫폼 지원

### 5.1 플랫폼 어댑터 패턴

```python
# backend/adapters/base_adapter.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional

class BasePlatformAdapter(ABC):
    """플랫폼 어댑터 기본 인터페이스"""

    @abstractmethod
    async def fetch_ticket(self, ticket_id: str) -> Dict[str, Any]:
        """티켓 상세 정보 가져오기"""
        pass

    @abstractmethod
    async def fetch_conversations(self, ticket_id: str) -> List[Dict[str, Any]]:
        """티켓 대화 내역 가져오기"""
        pass

    @abstractmethod
    async def fetch_attachments(self, ticket_id: str) -> List[Dict[str, Any]]:
        """티켓 첨부파일 정보 가져오기"""
        pass

    @abstractmethod
    async def fetch_knowledge_base(self) -> List[Dict[str, Any]]:
        """지식베이스 문서 가져오기"""
        pass
```

### 5.2 Freshdesk 어댑터

```python
# backend/adapters/freshdesk_adapter.py
from .base_adapter import BasePlatformAdapter
from freshdesk.api import API

class FreshdeskAdapter(BasePlatformAdapter):
    """Freshdesk 플랫폼 어댑터"""

    def __init__(self, domain: str, api_key: str):
        self.client = API(domain, api_key)

    async def fetch_ticket(self, ticket_id: str) -> Dict[str, Any]:
        ticket = self.client.tickets.get_ticket(int(ticket_id))
        return self._normalize_ticket(ticket)

    async def fetch_conversations(self, ticket_id: str) -> List[Dict[str, Any]]:
        conversations = self.client.conversations.list_all_conversations(int(ticket_id))
        return [self._normalize_conversation(conv) for conv in conversations]

    def _normalize_ticket(self, ticket: dict) -> dict:
        """Freshdesk 티켓을 공통 형식으로 변환"""
        return {
            "id": str(ticket["id"]),
            "subject": ticket.get("subject", ""),
            "description": ticket.get("description", ""),
            "status": ticket.get("status"),
            "priority": ticket.get("priority"),
            "created_at": ticket.get("created_at"),
            "updated_at": ticket.get("updated_at"),
            "tags": ticket.get("tags", [])
        }
```

### 5.3 고객별 설정 관리

```python
# backend/core/customer_config.py
from typing import Dict, Any, Optional
import secrets

class CustomerConfigManager:
    """고객별 설정 관리"""

    def __init__(self, storage):
        self.storage = storage
        self._cache = {}

    async def get_customer_config(self, company_id: str) -> Dict[str, Any]:
        """고객사 설정 조회 (캐시 적용)"""
        if company_id in self._cache:
            return self._cache[company_id]

        config = await self.storage.get_customer_config(company_id)
        if not config:
            raise ValueError(f"고객사 설정을 찾을 수 없습니다: {company_id}")

        # 암호화된 API 키 복호화
        config['api_key'] = self._decrypt_api_key(config['encrypted_api_key'])

        self._cache[company_id] = config
        return config

    async def save_customer_config(self, company_id: str, config: Dict[str, Any]) -> None:
        """고객사 설정 저장"""
        # API 키 암호화
        if 'api_key' in config:
            config['encrypted_api_key'] = self._encrypt_api_key(config['api_key'])
            del config['api_key']

        await self.storage.save_customer_config(company_id, config)

        # 캐시 무효화
        if company_id in self._cache:
            del self._cache[company_id]

    def _encrypt_api_key(self, api_key: str) -> str:
        """API 키 암호화 (실제 구현에서는 적절한 암호화 라이브러리 사용)"""
        # 예시: Fernet 암호화 사용
        from cryptography.fernet import Fernet
        key = self._get_encryption_key()
        f = Fernet(key)
        return f.encrypt(api_key.encode()).decode()

    def _decrypt_api_key(self, encrypted_key: str) -> str:
        """API 키 복호화"""
        from cryptography.fernet import Fernet
        key = self._get_encryption_key()
        f = Fernet(key)
        return f.decrypt(encrypted_key.encode()).decode()
```

---

## 6. 피드백 수집 및 추천 개선

### 6.1 피드백 API

```python
# backend/api/feedback.py
from fastapi import APIRouter, Depends
from ..core.schemas import FeedbackRequest, FeedbackResponse
from ..core.dependencies import get_storage

router = APIRouter()

@router.post("/feedback", response_model=FeedbackResponse)
async def submit_feedback(
    request: FeedbackRequest,
    storage = Depends(get_storage)
):
    """추천 결과에 대한 피드백 수집"""

    feedback_data = {
        "company_id": request.company_id,
        "query_id": request.query_id,
        "recommended_ticket_ids": request.recommended_tickets,
        "feedback_type": request.type,  # 'positive' or 'negative'
        "timestamp": datetime.utcnow().isoformat()
    }

    await storage.save_feedback(feedback_data)

    return FeedbackResponse(
        status="success",
        message="피드백이 저장되었습니다."
    )
```

### 6.2 추천 점수 재조정

```python
# backend/core/recommendation_optimizer.py
from typing import List, Dict, Any
import numpy as np

class RecommendationOptimizer:
    """피드백 기반 추천 최적화"""

    def __init__(self, storage):
        self.storage = storage
        self.boost_factor = 1.2
        self.penalty_factor = 0.8

    async def rerank_recommendations(
        self,
        candidates: List[Dict[str, Any]],
        company_id: str
    ) -> List[Dict[str, Any]]:
        """피드백 기반으로 추천 결과 재정렬"""

        # 최근 피드백 데이터 로드
        recent_feedback = await self.storage.get_recent_feedback(
            company_id=company_id,
            days=30
        )

        # 티켓별 피드백 점수 계산
        feedback_scores = self._calculate_feedback_scores(recent_feedback)

        # 후보 점수 조정
        for candidate in candidates:
            ticket_id = candidate['ticket_id']

            if ticket_id in feedback_scores:
                # 피드백 기반 점수 조정
                original_score = candidate['similarity_score']
                feedback_multiplier = feedback_scores[ticket_id]
                candidate['adjusted_score'] = original_score * feedback_multiplier
            else:
                # 피드백이 없는 경우 원본 점수 유지
                candidate['adjusted_score'] = candidate['similarity_score']

        # 조정된 점수로 재정렬
        return sorted(candidates, key=lambda x: x['adjusted_score'], reverse=True)

    def _calculate_feedback_scores(self, feedback_list: List[Dict]) -> Dict[str, float]:
        """티켓별 피드백 점수 계산"""
        scores = {}

        for feedback in feedback_list:
            for ticket_id in feedback['recommended_ticket_ids']:
                if ticket_id not in scores:
                    scores[ticket_id] = 1.0

                if feedback['feedback_type'] == 'positive':
                    scores[ticket_id] *= self.boost_factor
                else:
                    scores[ticket_id] *= self.penalty_factor

        return scores
```

---

## 7. API 엔드포인트 구현

### 7.1 초기화 엔드포인트

```python
# backend/api/main.py
from fastapi import FastAPI, Depends, Header
from typing import Optional

app = FastAPI()

@app.get("/init/{ticket_id}")
async def init_ticket_data(
    ticket_id: str,
    x_freshdesk_domain: Optional[str] = Header(None),
    x_freshdesk_api_key: Optional[str] = Header(None),
    storage = Depends(get_storage),
    vector_db = Depends(get_vector_db)
):
    """티켓 초기 데이터 로드"""

    # 동적 Freshdesk 설정 추출
    company_id = extract_company_id(x_freshdesk_domain)

    # 티켓 요약 생성 또는 조회
    ticket_summary = await get_or_generate_summary(
        ticket_id, company_id, storage
    )

    # 유사 티켓 검색
    similar_tickets = await vector_db.search_similar_tickets(
        query=ticket_summary['problem'],
        company_id=company_id,
        limit=5
    )

    # 관련 솔루션 검색
    related_solutions = await vector_db.search_solutions(
        query=ticket_summary['problem'],
        company_id=company_id,
        limit=5
    )

    return {
        "ticket_summary": ticket_summary,
        "similar_tickets": similar_tickets,
        "related_solutions": related_solutions
    }
```

### 7.2 자연어 쿼리 엔드포인트

```python
@app.post("/query")
async def process_natural_language_query(
    request: QueryRequest,
    x_freshdesk_domain: Optional[str] = Header(None),
    x_freshdesk_api_key: Optional[str] = Header(None),
    vector_db = Depends(get_vector_db),
    llm_client = Depends(get_llm_client)
):
    """자연어 쿼리 처리"""

    company_id = extract_company_id(x_freshdesk_domain)

    # 의도 분석
    intent = await analyze_intent(request.query, llm_client)

    results = {}

    # 선택된 콘텐츠 타입별 검색
    if "tickets" in request.type:
        results["tickets"] = await vector_db.search_similar_tickets(
            query=request.query,
            company_id=company_id,
            limit=10
        )

    if "solutions" in request.type:
        results["solutions"] = await vector_db.search_solutions(
            query=request.query,
            company_id=company_id,
            limit=10
        )

    if "attachments" in request.type:
        results["attachments"] = await search_attachments(
            query=request.query,
            company_id=company_id
        )

    # LLM 응답 생성
    llm_response = await generate_contextual_response(
        query=request.query,
        search_results=results,
        llm_client=llm_client
    )

    return {
        "intent": intent,
        "results": results,
        "llm_response": llm_response
    }
```

---

## 8. 모니터링 및 운영

### 8.1 성능 메트릭

```python
# backend/core/metrics.py
from prometheus_client import Counter, Histogram, Gauge
import time

# 메트릭 정의
ticket_processed_counter = Counter(
    'tickets_processed_total',
    'Total number of tickets processed',
    ['company_id', 'status']
)

llm_request_duration = Histogram(
    'llm_request_duration_seconds',
    'LLM API request duration',
    ['model', 'operation']
)

vector_search_duration = Histogram(
    'vector_search_duration_seconds',
    'Vector search duration',
    ['collection', 'company_id']
)

active_processing_gauge = Gauge(
    'active_processing_tasks',
    'Number of active processing tasks',
    ['company_id']
)

class MetricsCollector:
    """메트릭 수집 헬퍼"""

    @staticmethod
    def track_llm_request(model: str, operation: str):
        """LLM 요청 추적 데코레이터"""
        def decorator(func):
            async def wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = await func(*args, **kwargs)
                    return result
                finally:
                    duration = time.time() - start_time
                    llm_request_duration.labels(
                        model=model,
                        operation=operation
                    ).observe(duration)
            return wrapper
        return decorator
```

### 8.2 에러 처리 및 재시도

```python
# backend/core/error_handler.py
import asyncio
from typing import TypeVar, Callable
from functools import wraps

T = TypeVar('T')

class RetryConfig:
    """재시도 설정"""
    def __init__(self, max_attempts: int = 3, base_delay: float = 1.0):
        self.max_attempts = max_attempts
        self.base_delay = base_delay

def with_retry(config: RetryConfig = RetryConfig()):
    """재시도 데코레이터"""
    def decorator(func: Callable[..., T]) -> Callable[..., T]:
        @wraps(func)
        async def wrapper(*args, **kwargs) -> T:
            last_exception = None

            for attempt in range(config.max_attempts):
                try:
                    return await func(*args, **kwargs)
                except Exception as e:
                    last_exception = e

                    if attempt < config.max_attempts - 1:
                        # 지수 백오프
                        delay = config.base_delay * (2 ** attempt)
                        await asyncio.sleep(delay)

                    print(f"재시도 {attempt + 1}/{config.max_attempts}: {e}")

            raise last_exception

        return wrapper
    return decorator
```

---

## 9. 보안 및 규정 준수

### 9.1 데이터 보안

```python
# backend/core/security.py
from cryptography.fernet import Fernet
import hashlib
import hmac

class SecurityManager:
    """보안 관리자"""

    def __init__(self, encryption_key: bytes):
        self.cipher = Fernet(encryption_key)

    def encrypt_sensitive_data(self, data: str) -> str:
        """민감한 데이터 암호화"""
        return self.cipher.encrypt(data.encode()).decode()

    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """암호화된 데이터 복호화"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()

    def generate_api_signature(self, api_key: str, timestamp: str) -> str:
        """API 요청 서명 생성"""
        message = f"{api_key}:{timestamp}".encode()
        signature = hmac.new(
            self.signing_key,
            message,
            hashlib.sha256
        ).hexdigest()
        return signature

    def verify_api_signature(
        self,
        api_key: str,
        timestamp: str,
        signature: str
    ) -> bool:
        """API 서명 검증"""
        expected_signature = self.generate_api_signature(api_key, timestamp)
        return hmac.compare_digest(expected_signature, signature)
```

### 9.2 접근 제어

```python
# backend/core/access_control.py
from typing import List, Optional

class AccessControl:
    """접근 제어 관리"""

    def __init__(self, storage):
        self.storage = storage

    async def check_ticket_access(
        self,
        user_id: str,
        company_id: str,
        ticket_id: str
    ) -> bool:
        """티켓 접근 권한 확인"""
        # 사용자가 해당 회사에 속하는지 확인
        user = await self.storage.get_user(user_id)
        if not user or user['company_id'] != company_id:
            return False

        # 티켓이 해당 회사에 속하는지 확인
        ticket = await self.storage.get_ticket(ticket_id, company_id)
        if not ticket:
            return False

        # 역할 기반 접근 제어
        if user['role'] == 'admin':
            return True

        # 담당자인 경우만 접근 허용
        return ticket.get('assignee_id') == user_id
```

---

## 10. 배포 및 운영 가이드

### 10.1 환경별 설정

```yaml
# config/environments/production.yaml
database:
  type: postgresql
  url: ${DATABASE_URL}
  pool_size: 20

vector_db:
  type: qdrant
  url: ${QDRANT_URL}
  api_key: ${QDRANT_API_KEY}

storage:
  type: s3
  bucket: ${S3_BUCKET}
  region: ${AWS_REGION}

llm:
  provider: openai
  model: gpt-4
  temperature: 0.7
  max_tokens: 2000

security:
  encryption_key: ${ENCRYPTION_KEY}
  jwt_secret: ${JWT_SECRET}

monitoring:
  enabled: true
  prometheus_port: 9090
  log_level: INFO
```

### 10.2 Docker 구성

```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# 의존성 설치
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 애플리케이션 코드 복사
COPY . .

# 환경변수 설정
ENV PYTHONPATH=/app
ENV ENVIRONMENT=production

# 헬스체크
HEALTHCHECK --interval=30s --timeout=3s --start-period=40s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# 실행
CMD ["uvicorn", "backend.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 10.3 Kubernetes 배포

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: copilot-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: copilot-backend
  template:
    metadata:
      labels:
        app: copilot-backend
    spec:
      containers:
        - name: backend
          image: copilot-backend:latest
          ports:
            - containerPort: 8000
          env:
            - name: DATABASE_URL
              valueFrom:
                secretKeyRef:
                  name: copilot-secrets
                  key: database-url
            - name: QDRANT_URL
              valueFrom:
                secretKeyRef:
                  name: copilot-secrets
                  key: qdrant-url
          resources:
            requests:
              memory: "512Mi"
              cpu: "500m"
            limits:
              memory: "1Gi"
              cpu: "1000m"
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 10
```

---

## 📊 마이그레이션 전략

### MVP → 프로덕션 전환 체크리스트

1. **데이터 마이그레이션**

   - [ ] 파일 기반 데이터를 PostgreSQL로 이전
   - [ ] 기존 임베딩 데이터 검증 및 재생성
   - [ ] 메타데이터 정합성 확인

2. **인프라 준비**

   - [ ] PostgreSQL RDS 인스턴스 생성
   - [ ] Qdrant Cloud 프로덕션 클러스터 설정
   - [ ] S3 버킷 및 CloudFront 설정

3. **보안 설정**

   - [ ] API 키 암호화 시스템 구축
   - [ ] JWT 기반 인증 구현
   - [ ] VPC 및 보안 그룹 설정

4. **모니터링 설정**

   - [ ] Prometheus & Grafana 설정
   - [ ] 로그 수집 시스템 구축
   - [ ] 알림 규칙 설정

5. **테스트 및 검증**
   - [ ] 부하 테스트 수행
   - [ ] 장애 복구 테스트
   - [ ] 데이터 정합성 검증

---

## 🔍 디버깅 및 트러블슈팅

### 일반적인 문제 해결

1. **LLM 요약 실패**

   ```python
   # 타임아웃 설정 증가
   llm_client = ChatOpenAI(
       request_timeout=60,  # 60초로 증가
       max_retries=3
   )
   ```

2. **벡터 검색 성능 저하**

   ```python
   # 인덱스 최적화
   qdrant_client.recreate_collection(
       collection_name=collection_name,
       vectors_config=VectorParams(
           size=1536,
           distance=Distance.COSINE,
           on_disk=True  # 대용량 데이터의 경우
       )
   )
   ```

3. **메모리 부족**
   ```python
   # 배치 크기 조정
   BATCH_SIZE = 50  # 100에서 50으로 감소
   MAX_CONCURRENT = 3  # 5에서 3으로 감소
   ```

---

이 지침서는 MVP부터 프로덕션까지의 전체 구현 과정을 다룹니다. 각 단계별로 필요한 기능을 점진적으로 구현하며, 확장성과 유지보수성을 고려한 설계를 따르시기 바랍니다.

wedosoft: 상세한 정보 정말 감사합니다. 코드를 생략한 개괄적인 정리도 부탁합니다. 좀더 한눈에 파악하기 좋게 해주세요

GitHub Copilot: # 📋 Copilot RAG 시스템 구현 지침서 요약

## 🎯 프로젝트 목표

Freshdesk 기반 고객지원 상담사를 위한 AI 지원 시스템 구축

- 유사 티켓 추천
- 자동 요약 생성
- 피드백 기반 추천 개선

## 🏗️ 시스템 아키텍처

### 📊 데이터 흐름

```
데이터 수집 → 병합 → LLM 요약 → 임베딩 → Vector DB → 추천 → 피드백
```

### 🗄️ 데이터베이스 구성 (MVP: 각 1개씩)

1. **벡터 DB** (Qdrant Cloud) - 임베딩 검색
2. **애플리케이션 DB** (PostgreSQL) - 구조화 데이터
3. **비밀 저장소** (Secrets Manager) - API 키 관리

## 📁 데이터 처리 전략

### MVP 단계 (현재)

- **파일 기반** JSON 저장
- **로컬 개발** 중심
- **단순한 구조** 유지

### 프로덕션 단계

- **PostgreSQL** 도입
- **AWS RDS** 사용
- **멀티테넌트** 지원

## 🔧 핵심 구현 사항

### 1. 데이터 수집

- 티켓 + 대화 + 첨부파일 **하나로 병합**
- 해시값으로 **중복 감지**
- **청크 단위** 처리

### 2. LLM 요약

- 이슈/해결 방법 **구조화 요약**
- **비용 최적화** (필터링)
- **병렬 처리** 지원

### 3. 벡터 검색

- **요약 텍스트만** 임베딩
- 원본은 **메타데이터로만** 저장
- **company_id 기반** 격리

## 🎨 추상화 레이어 설계

### 장점

- **저장소 변경 용이** (파일 → DB)
- **비즈니스 로직 불변**
- **테스트 편의성**

### 구현 방식

```
인터페이스 정의 → 파일 구현 → PostgreSQL 구현 → 환경변수로 전환
```

## 🚀 멀티플랫폼 확장 전략

### MVP 우선

- **Freshdesk만** 집중
- **기반 구조**는 확장 고려
- **Adapter 패턴** 준비

### 향후 확장

- Zendesk 등 **다른 플랫폼**
- **공통 데이터 모델**
- **플랫폼별 Adapter**

## 📈 추천 개선 방식

### 피드백 수집

- 추천 묶음 단위 **👍/👎**
- **날짜/시간** 기록
- **API로 저장**

### 개선 전략

1. **점수 재조정** (가중치)
2. **임베딩 모델** 교체
3. **LLM reranking** 적용

## 🔐 멀티테넌트 보안

### 고객별 설정

- **DB에 저장** (암호화)
- **동적 로드**
- **캐싱 적용**

### 데이터 격리

- **company_id** 필터링
- **Row-level** 보안
- **API 키** 검증

## 📋 단계별 로드맵

### Phase 1: MVP (2-4주)

- 파일 기반 구현
- 핵심 기능 완성
- 단일 고객 테스트

### Phase 2: 스테이징 (1-2주)

- 클라우드 DB 도입
- 멀티테넌트 검증
- 성능 최적화

### Phase 3: 프로덕션 (2-3주)

- 전체 마이그레이션
- 모니터링 구축
- 자동화 완성

## ✅ 핵심 원칙

1. **MVP 우선** - 복잡도 최소화
2. **점진적 개선** - 단계별 확장
3. **추상화 적용** - 변경 용이성
4. **보안 중시** - 데이터 격리
5. **비용 효율** - 리소스 최적화
