
이제 백엔드를 aws ec2에 배포하려고 합니다. 어떻게 준비하면 될까요? 로컬 경로라던지 고려할 것이 많아 보입니다. 의견을 주세요

> Copilot: AWS EC2에 백엔드를 배포하기 위한 종합적인 가이드를 제공해드리겠습니다. 프로젝트의 특성상 고려해야 할 사항들이 많습니다.
> 
> ## 🚀 AWS EC2 배포 준비 가이드
> 
> ### 1. 로컬 경로 및 데이터 관리 전략
> 
> 현재 코드를 보면 다음과 같은 로컬 경로들이 사용되고 있습니다:
> 
> ```python
> # 현재 로컬 경로 의존성
> - self.raw_data_dir (freshdesk_full_data/)
> - self.data_dir (freshdesk_100k_data/)
> - qdrant_storage/ (벡터 DB - 이미 클라우드로 전환됨)
> - .env 파일
> - progress.json
> ```
> 
> #### 권장 해결 방안:
> 
> **1) 환경변수 기반 경로 설정**
> 
> ```python
> # core/config.py 생성 권장
> import os
> from pathlib import Path
> 
> class Config:
>     # EC2에서는 /opt/app/data 같은 절대 경로 사용
>     DATA_BASE_DIR = Path(os.getenv("DATA_BASE_DIR", "/opt/app/data"))
>     RAW_DATA_DIR = DATA_BASE_DIR / "raw_data"
>     PROCESSED_DATA_DIR = DATA_BASE_DIR / "processed_data"
>     LOGS_DIR = DATA_BASE_DIR / "logs"
>     
>     # S3 설정 (대용량 데이터용)
>     USE_S3_STORAGE = os.getenv("USE_S3_STORAGE", "false").lower() == "true"
>     S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME", "")
>     AWS_REGION = os.getenv("AWS_REGION", "ap-northeast-2")
> ```
> 
> **2) 데이터 저장소 전략**
> 
> ```yaml
> # 데이터 저장 전략
> 로컬 파일 시스템:
>   - progress.json (작은 상태 파일)
>   - 임시 캐시 파일
>   
> AWS S3:
>   - Raw 데이터 (freshdesk_full_data/)
>   - 처리된 데이터 청크
>   - 백업 파일
>   
> AWS EFS (선택사항):
>   - 여러 EC2 인스턴스 간 공유 필요 시
> ```
> 
> ### 2. EC2 인스턴스 준비
> 
> #### 권장 스펙:
> ```yaml
> 개발/테스트: t3.medium (2 vCPU, 4GB RAM)
> 프로덕션: t3.large 또는 c5.large (2 vCPU, 8GB RAM)
> 대용량 처리: c5.xlarge (4 vCPU, 8GB RAM)
> 
> 스토리지: 
>   - EBS gp3 100GB (확장 가능)
>   - 또는 S3 + 작은 EBS 조합
> ```
> 
> ### 3. 배포 준비 체크리스트
> 
> #### 3.1 코드 수정 사항
> 
> ```python
> # backend/core/storage_manager.py (신규 생성 권장)
> import boto3
> from pathlib import Path
> import json
> import os
> 
> class StorageManager:
>     """EC2와 S3를 통합 관리하는 저장소 매니저"""
>     
>     def __init__(self):
>         self.use_s3 = os.getenv("USE_S3_STORAGE", "false").lower() == "true"
>         if self.use_s3:
>             self.s3_client = boto3.client('s3')
>             self.bucket_name = os.getenv("S3_BUCKET_NAME")
>     
>     async def save_data(self, data: dict, path: str):
>         """로컬 또는 S3에 데이터 저장"""
>         if self.use_s3:
>             # S3에 저장
>             key = f"freshdesk-data/{path}"
>             self.s3_client.put_object(
>                 Bucket=self.bucket_name,
>                 Key=key,
>                 Body=json.dumps(data, ensure_ascii=False)
>             )
>         else:
>             # 로컬 파일 시스템에 저장
>             local_path = Path(os.getenv("DATA_BASE_DIR", "/opt/app/data")) / path
>             local_path.parent.mkdir(parents=True, exist_ok=True)
>             with open(local_path, 'w', encoding='utf-8') as f:
>                 json.dump(data, f, ensure_ascii=False)
> ```
> 
> #### 3.2 환경 설정 파일
> 
> ```bash
> # .env.production (EC2용)
> # API Keys
> ANTHROPIC_API_KEY=your-key
> OPENAI_API_KEY=your-key
> GOOGLE_API_KEY=your-key
> 
> # Freshdesk
> FRESHDESK_DOMAIN=wedosoft
> FRESHDESK_API_KEY=your-key
> COMPANY_ID=kyexpert
> 
> # Qdrant Cloud (이미 설정됨)
> QDRANT_URL=https://your-cluster.cloud.qdrant.io
> QDRANT_API_KEY=your-key
> 
> # Storage
> DATA_BASE_DIR=/opt/app/data
> USE_S3_STORAGE=true
> S3_BUCKET_NAME=freshdesk-rag-data
> AWS_REGION=ap-northeast-2
> 
> # Server
> PORT=8000
> HOST=0.0.0.0
> WORKERS=4
> ```
> 
> ### 4. Docker 기반 배포 구성
> 
> ```dockerfile
> # backend/Dockerfile.production
> FROM python:3.10-slim
> 
> # 시스템 패키지 설치
> RUN apt-get update && apt-get install -y \
>     gcc \
>     g++ \
>     curl \
>     && rm -rf /var/lib/apt/lists/*
> 
> # 작업 디렉토리 설정
> WORKDIR /app
> 
> # 의존성 설치
> COPY requirements.txt .
> RUN pip install --no-cache-dir -r requirements.txt
> 
> # 애플리케이션 복사
> COPY . .
> 
> # 데이터 디렉토리 생성
> RUN mkdir -p /opt/app/data/logs
> 
> # 비루트 사용자 생성
> RUN useradd -m -u 1000 appuser && \
>     chown -R appuser:appuser /app /opt/app/data
> USER appuser
> 
> # 헬스체크
> HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
>     CMD curl -f http://localhost:8000/health || exit 1
> 
> # 실행
> CMD ["python", "-m", "uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
> ```
> 
> ### 5. 배포 스크립트
> 
> ```bash
> #!/bin/bash
> # scripts/deploy_to_ec2.sh
> 
> # 1. 환경 변수 검증
> if [ ! -f .env.production ]; then
>     echo "❌ .env.production 파일이 없습니다!"
>     exit 1
> fi
> 
> # 2. Docker 이미지 빌드
> echo "🔨 Docker 이미지 빌드 중..."
> docker build -f Dockerfile.production -t freshdesk-rag-backend:latest .
> 
> # 3. ECR에 푸시 (선택사항)
> if [ "$USE_ECR" = "true" ]; then
>     aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REGISTRY
>     docker tag freshdesk-rag-backend:latest $ECR_REGISTRY/freshdesk-rag-backend:latest
>     docker push $ECR_REGISTRY/freshdesk-rag-backend:latest
> fi
> 
> # 4. EC2에 배포
> echo "🚀 EC2에 배포 중..."
> scp -i ~/.ssh/your-key.pem docker-compose.prod.yml ubuntu@$EC2_IP:/home/ubuntu/
> scp -i ~/.ssh/your-key.pem .env.production ubuntu@$EC2_IP:/home/ubuntu/.env
> 
> ssh -i ~/.ssh/your-key.pem ubuntu@$EC2_IP << 'EOF'
>     # Docker Compose로 서비스 시작
>     docker-compose -f docker-compose.prod.yml pull
>     docker-compose -f docker-compose.prod.yml up -d
>     
>     # 로그 확인
>     docker-compose -f docker-compose.prod.yml logs -f
> EOF
> ```
> 
> ### 6. 데이터 마이그레이션 전략
> 
> ```python
> # scripts/migrate_to_s3.py
> import boto3
> import os
> from pathlib import Path
> 
> def migrate_local_to_s3():
>     """로컬 데이터를 S3로 마이그레이션"""
>     s3_client = boto3.client('s3')
>     bucket_name = os.getenv("S3_BUCKET_NAME")
>     
>     local_data_dir = Path("./freshdesk_full_data")
>     
>     for file_path in local_data_dir.rglob("*.json"):
>         # S3 키 생성
>         s3_key = f"raw_data/{file_path.relative_to(local_data_dir)}"
>         
>         # S3에 업로드
>         print(f"업로드 중: {file_path} -> s3://{bucket_name}/{s3_key}")
>         s3_client.upload_file(str(file_path), bucket_name, s3_key)
> ```
> 
> ### 7. 모니터링 및 로깅
> 
> ```yaml
> # docker-compose.prod.yml
> version: '3.8'
> 
> services:
>   backend:
>     image: freshdesk-rag-backend:latest
>     ports:
>       - "8000:8000"
>     env_file:
>       - .env
>     volumes:
>       - app-logs:/opt/app/data/logs
>     restart: unless-stopped
>     logging:
>       driver: "json-file"
>       options:
>         max-size: "10m"
>         max-file: "3"
>     
>   # CloudWatch Agent (선택사항)
>   cloudwatch-agent:
>     image: amazon/cloudwatch-agent:latest
>     volumes:
>       - app-logs:/opt/app/data/logs:ro
>       - ./cloudwatch-config.json:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent.json
> 
> volumes:
>   app-logs:
> ```
> 
> ### 8. 보안 고려사항
> 
> ```bash
> # EC2 보안 그룹 설정
> - SSH (22): 특정 IP만 허용
> - HTTP (80): ALB에서만 허용
> - HTTPS (443): ALB에서만 허용
> - 애플리케이션 포트 (8000): 프라이빗 서브넷 내부만
> 
> # Secrets Manager 사용 (권장)
> aws secretsmanager create-secret \
>     --name freshdesk-rag-secrets \
>     --secret-string file://.env.production
> ```
> 
> ### 9. 배포 전 최종 체크리스트
> 
> ```yaml
> ✅ 코드 수정:
>   - [ ] 모든 하드코딩된 경로를 환경변수로 변경
>   - [ ] StorageManager 클래스 구현
>   - [ ] 에러 핸들링 강화
>   
> ✅ 인프라:
>   - [ ] EC2 인스턴스 생성
>   - [ ] S3 버킷 생성 및 권한 설정
>   - [ ] 보안 그룹 설정
>   - [ ] IAM 역할 생성 (S3 접근용)
>   
> ✅ 환경 설정:
>   - [ ] .env.production 파일 준비
>   - [ ] Docker 이미지 빌드 및 테스트
>   - [ ] 로그 수집 설정
>   
> ✅ 데이터:
>   - [ ] 기존 데이터 백업
>   - [ ] S3 마이그레이션 계획 수립
>   - [ ] 진행 상황 추적 방법 확인
> ```
> 
> ### 10. 단계별 배포 권장 순서
> 
> 1. **개발 환경에서 S3 연동 테스트**
> 2. **스테이징 EC2에서 소규모 데이터로 테스트**
> 3. **데이터 마이그레이션 (로컬 → S3)**
> 4. **프로덕션 EC2 배포**
> 5. **모니터링 설정 및 성능 튜닝**
> 
> 이 가이드를 따라 단계적으로 진행하시면 안전하게 EC2에 배포할 수 있습니다. 특히 데이터 저장소 전략과 경로 관리가 중요하므로, StorageManager 클래스 구현을 우선적으로 진행하시는 것을 권장합니다.
