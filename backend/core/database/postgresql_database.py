"""
PostgreSQL Í∏∞Î∞ò Î©ÄÌã∞ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í¥ÄÎ¶¨
Ïä§ÌÇ§Îßà Í∏∞Î∞ò ÌÖåÎÑåÌä∏ Î∂ÑÎ¶¨ Î∞è Î©ÄÌã∞ÌîåÎû´Ìèº ÏßÄÏõê
"""

import psycopg2
import psycopg2.extras
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
import os

logger = logging.getLogger(__name__)

class PostgreSQLDatabase:
    """PostgreSQL Ïä§ÌÇ§Îßà Í∏∞Î∞ò Î©ÄÌã∞ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Í¥ÄÎ¶¨"""
    
    def __init__(self, company_id: str, platform: str = "freshdesk"):
        """
        PostgreSQL Î©ÄÌã∞ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî
        
        Args:
            company_id: ÌöåÏÇ¨ ID (Ïä§ÌÇ§ÎßàÎ™ÖÏúºÎ°ú ÏÇ¨Ïö©)
            platform: ÌîåÎû´ÌèºÎ™Ö (ÌÖåÏù¥Î∏î Ï†ëÎëêÏÇ¨Î°ú ÏÇ¨Ïö©)
        """
        if not company_id:
            raise ValueError("company_idÎäî ÌïÑÏàò Îß§Í∞úÎ≥ÄÏàòÏûÖÎãàÎã§")
            
        # Ïä§ÌÇ§ÎßàÎ™Ö Ï†ïÍ∑úÌôî (PostgreSQL ÎÑ§Ïù¥Î∞ç Í∑úÏπô Ï§ÄÏàò)
        self.company_id = self._normalize_schema_name(company_id)
        self.platform = platform.lower()
        self.schema_name = f"tenant_{self.company_id}"
        
        # Ïó∞Í≤∞ Ï†ïÎ≥¥
        self.connection = None
        self._tables_created = False
        
        # PostgreSQL Ïó∞Í≤∞ ÏÑ§Ï†ï
        self.db_config = {
            'host': os.getenv('POSTGRES_HOST', 'localhost'),
            'port': os.getenv('POSTGRES_PORT', '5432'),
            'database': os.getenv('POSTGRES_DB', 'saas_platform'),
            'user': os.getenv('POSTGRES_USER', 'postgres'),
            'password': os.getenv('POSTGRES_PASSWORD', 'password')
        }
        
        logger.info(f"PostgreSQL Î©ÄÌã∞ÌÖåÎÑåÌä∏ DB Ï¥àÍ∏∞Ìôî: schema={self.schema_name}, platform={self.platform}")
    
    def _normalize_schema_name(self, company_id: str) -> str:
        """Ïä§ÌÇ§ÎßàÎ™Ö Ï†ïÍ∑úÌôî (PostgreSQL Í∑úÏπô Ï§ÄÏàò)"""
        # ÏÜåÎ¨∏Ïûê Î≥ÄÌôò, ÌäπÏàòÎ¨∏Ïûê Ï†úÍ±∞, Ïñ∏ÎçîÏä§ÏΩîÏñ¥Î°ú ÎåÄÏ≤¥
        import re
        normalized = re.sub(r'[^a-zA-Z0-9_]', '_', company_id.lower())
        # Ïà´ÏûêÎ°ú ÏãúÏûëÌïòÎ©¥ Ï†ëÎëêÏÇ¨ Ï∂îÍ∞Ä
        if normalized[0].isdigit():
            normalized = f"c_{normalized}"
        return normalized
    
    def connect(self):
        """PostgreSQL Ïó∞Í≤∞"""
        try:
            self.connection = psycopg2.connect(**self.db_config)
            self.connection.autocommit = False
            
            # Ïä§ÌÇ§Îßà ÏÉùÏÑ± (Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏùÑ Í≤ΩÏö∞)
            self._ensure_schema_exists()
            
            # Ïä§ÌÇ§ÎßàÎ•º Í∏∞Î≥∏ Í≤ÄÏÉâ Í≤ΩÎ°úÎ°ú ÏÑ§Ï†ï
            with self.connection.cursor() as cursor:
                cursor.execute(f"SET search_path TO {self.schema_name}, public")
                self.connection.commit()
            
            logger.info(f"PostgreSQL Ïó∞Í≤∞ ÏôÑÎ£å: {self.db_config['host']}:{self.db_config['port']} / {self.schema_name}")
            
            # ÌÖåÏù¥Î∏î ÏÉùÏÑ±
            if not self._tables_created:
                self.create_tables()
                
        except Exception as e:
            logger.error(f"PostgreSQL Ïó∞Í≤∞ Ïã§Ìå®: {e}")
            raise
    
    def _ensure_schema_exists(self):
        """Ïä§ÌÇ§Îßà Ï°¥Ïû¨ ÌôïÏù∏ Î∞è ÏÉùÏÑ±"""
        with self.connection.cursor() as cursor:
            # Ïä§ÌÇ§Îßà Ï°¥Ïû¨ ÌôïÏù∏
            cursor.execute("""
                SELECT schema_name FROM information_schema.schemata 
                WHERE schema_name = %s
            """, (self.schema_name,))
            
            if not cursor.fetchone():
                # Ïä§ÌÇ§Îßà ÏÉùÏÑ±
                cursor.execute(f"CREATE SCHEMA {self.schema_name}")
                self.connection.commit()
                logger.info(f"Ïä§ÌÇ§Îßà ÏÉùÏÑ± ÏôÑÎ£å: {self.schema_name}")
    
    def disconnect(self):
        """Ïó∞Í≤∞ Ìï¥Ï†ú"""
        if self.connection:
            self.connection.close()
            self.connection = None
            logger.info(f"PostgreSQL Ïó∞Í≤∞ Ìï¥Ï†ú: {self.schema_name}")
    
    def create_tables(self):
        """Î©ÄÌã∞ÌÖåÎÑåÌä∏ ÌÖåÏù¥Î∏î ÏÉùÏÑ±"""
        if not self.connection:
            self.connect()
        
        with self.connection.cursor() as cursor:
            # =====================================================
            # üè¢ SaaS Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÌÖåÏù¥Î∏î (public Ïä§ÌÇ§Îßà)
            # =====================================================
            
            # ÌÖåÎÑåÌä∏ Ï†ïÎ≥¥ ÌÖåÏù¥Î∏î (Î™®Îì† ÌÖåÎÑåÌä∏ Í≥µÌÜµ)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS public.tenants (
                    id SERIAL PRIMARY KEY,
                    company_id VARCHAR(100) UNIQUE NOT NULL,
                    schema_name VARCHAR(100) UNIQUE NOT NULL,
                    company_name VARCHAR(255) NOT NULL,
                    domain VARCHAR(255) UNIQUE NOT NULL,
                    subscription_plan_id INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    is_active BOOLEAN DEFAULT TRUE
                )
            """)
            
            # ÌîåÎû´Ìèº Ï†ïÎ≥¥ ÌÖåÏù¥Î∏î (Í≥µÌÜµ)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS public.platforms (
                    id SERIAL PRIMARY KEY,
                    platform_name VARCHAR(50) UNIQUE NOT NULL,
                    display_name VARCHAR(100) NOT NULL,
                    api_config JSONB,
                    is_active BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ÌÖåÎÑåÌä∏-ÌîåÎû´Ìèº Ïó∞Í≤∞ ÌÖåÏù¥Î∏î
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS public.tenant_platforms (
                    id SERIAL PRIMARY KEY,
                    tenant_id INTEGER REFERENCES public.tenants(id),
                    platform_id INTEGER REFERENCES public.platforms(id),
                    platform_config JSONB,
                    is_enabled BOOLEAN DEFAULT TRUE,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(tenant_id, platform_id)
                )
            """)
            
            # =====================================================
            # üìä ÌÖåÎÑåÌä∏Î≥Ñ ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ ÌÖåÏù¥Î∏î
            # =====================================================
            
            # ÌÜµÌï© Í∞ùÏ≤¥ ÌÖåÏù¥Î∏î (ÌÖåÎÑåÌä∏ Ïä§ÌÇ§Îßà ÎÇ¥)
            cursor.execute(f"""
                CREATE TABLE IF NOT EXISTS {self.schema_name}.integrated_objects (
                    id SERIAL PRIMARY KEY,
                    original_id VARCHAR(255) NOT NULL,
                    platform VARCHAR(50) NOT NULL,
                    object_type VARCHAR(50) NOT NULL,
                    original_data JSONB NOT NULL,
                    integrated_content TEXT,
                    summary TEXT,
                    metadata JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(platform, object_type, original_id)
                )
            """)
            
            # ÏßÑÌñâ Î°úÍ∑∏ ÌÖåÏù¥Î∏î
            cursor.execute(f"""
                CREATE TABLE IF NOT EXISTS {self.schema_name}.progress_logs (
                    id SERIAL PRIMARY KEY,
                    job_id VARCHAR(255) NOT NULL,
                    message TEXT NOT NULL,
                    percentage NUMERIC(5,2) NOT NULL,
                    step INTEGER NOT NULL,
                    total_steps INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(job_id, step)
                )
            """)
            
            # =====================================================
            # üìä Ïù∏Îç±Ïä§ ÏÉùÏÑ±
            # =====================================================
            
            # ÌÜµÌï© Í∞ùÏ≤¥ Ïù∏Îç±Ïä§
            cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_{self.schema_name}_integrated_platform 
                ON {self.schema_name}.integrated_objects(platform)
            """)
            
            cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_{self.schema_name}_integrated_type 
                ON {self.schema_name}.integrated_objects(object_type)
            """)
            
            cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_{self.schema_name}_integrated_created 
                ON {self.schema_name}.integrated_objects(created_at)
            """)
            
            # JSON Ïù∏Îç±Ïä§ (PostgreSQL ÌäπÌôî)
            cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_{self.schema_name}_metadata_gin 
                ON {self.schema_name}.integrated_objects USING GIN (metadata)
            """)
            
            # ÏßÑÌñâ Î°úÍ∑∏ Ïù∏Îç±Ïä§
            cursor.execute(f"""
                CREATE INDEX IF NOT EXISTS idx_{self.schema_name}_progress_job 
                ON {self.schema_name}.progress_logs(job_id)
            """)
            
            self.connection.commit()
            logger.info(f"ÌÖåÎÑåÌä∏ ÌÖåÏù¥Î∏î ÏÉùÏÑ± ÏôÑÎ£å: {self.schema_name}")
            self._tables_created = True
    
    def register_tenant(self, tenant_data: Dict[str, Any]) -> int:
        """ÌÖåÎÑåÌä∏ Îì±Î°ù (public.tenants ÌÖåÏù¥Î∏î)"""
        if not self.connection:
            self.connect()
        
        with self.connection.cursor() as cursor:
            cursor.execute("""
                INSERT INTO public.tenants (
                    company_id, schema_name, company_name, domain, subscription_plan_id
                ) VALUES (%s, %s, %s, %s, %s)
                ON CONFLICT (company_id) DO UPDATE SET
                    company_name = EXCLUDED.company_name,
                    domain = EXCLUDED.domain,
                    updated_at = CURRENT_TIMESTAMP
                RETURNING id
            """, (
                self.company_id,
                self.schema_name,
                tenant_data.get('company_name'),
                tenant_data.get('domain'),
                tenant_data.get('subscription_plan_id')
            ))
            
            tenant_id = cursor.fetchone()[0]
            self.connection.commit()
            
            logger.info(f"ÌÖåÎÑåÌä∏ Îì±Î°ù ÏôÑÎ£å: {self.company_id} (ID: {tenant_id})")
            return tenant_id
    
    def insert_integrated_object(self, integrated_data: Dict[str, Any]) -> int:
        """ÌÜµÌï© Í∞ùÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏÇΩÏûÖ"""
        if not self.connection:
            self.connect()
        
        with self.connection.cursor() as cursor:
            cursor.execute(f"""
                INSERT INTO {self.schema_name}.integrated_objects (
                    original_id, platform, object_type, original_data,
                    integrated_content, summary, metadata
                ) VALUES (%s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (platform, object_type, original_id) DO UPDATE SET
                    original_data = EXCLUDED.original_data,
                    integrated_content = EXCLUDED.integrated_content,
                    summary = EXCLUDED.summary,
                    metadata = EXCLUDED.metadata,
                    updated_at = CURRENT_TIMESTAMP
                RETURNING id
            """, (
                str(integrated_data.get('original_id')),
                self.platform,
                integrated_data.get('object_type'),
                json.dumps(integrated_data.get('original_data', {})),
                integrated_data.get('integrated_content'),
                integrated_data.get('summary'),
                json.dumps(integrated_data.get('metadata', {}))
            ))
            
            object_id = cursor.fetchone()[0]
            self.connection.commit()
            return object_id
    
    def get_integrated_objects_by_type(self, object_type: str, platform: str = None) -> List[Dict[str, Any]]:
        """ÌÉÄÏûÖÎ≥Ñ ÌÜµÌï© Í∞ùÏ≤¥ Ï°∞Ìöå"""
        if not self.connection:
            self.connect()
        
        platform = platform or self.platform
        
        with self.connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
            cursor.execute(f"""
                SELECT * FROM {self.schema_name}.integrated_objects 
                WHERE platform = %s AND object_type = %s
                ORDER BY created_at DESC
            """, (platform, object_type))
            
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def search_integrated_content(self, query: str, object_types: List[str] = None, platform: str = None) -> List[Dict[str, Any]]:
        """ÌÜµÌï© ÏΩòÌÖêÏ∏† Í≤ÄÏÉâ (PostgreSQL Ï†ÑÎ¨∏ Í≤ÄÏÉâ ÌôúÏö©)"""
        if not self.connection:
            self.connect()
        
        platform = platform or self.platform
        
        with self.connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
            base_query = f"""
                SELECT *, 
                       ts_rank(to_tsvector('english', integrated_content), plainto_tsquery('english', %s)) as rank
                FROM {self.schema_name}.integrated_objects 
                WHERE platform = %s 
                AND to_tsvector('english', integrated_content) @@ plainto_tsquery('english', %s)
            """
            
            params = [query, platform, query]
            
            if object_types:
                placeholders = ','.join(['%s'] * len(object_types))
                base_query += f" AND object_type IN ({placeholders})"
                params.extend(object_types)
            
            base_query += " ORDER BY rank DESC, updated_at DESC"
            
            cursor.execute(base_query, params)
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def clear_tenant_data(self, platform: str = None):
        """ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú"""
        if not self.connection:
            self.connect()
        
        with self.connection.cursor() as cursor:
            if platform:
                cursor.execute(f"""
                    DELETE FROM {self.schema_name}.integrated_objects WHERE platform = %s
                """, (platform,))
            else:
                cursor.execute(f"DELETE FROM {self.schema_name}.integrated_objects")
                cursor.execute(f"DELETE FROM {self.schema_name}.progress_logs")
            
            self.connection.commit()
            logger.info(f"ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú ÏôÑÎ£å: {self.schema_name}")
    
    def count_integrated_objects(self) -> int:
        """ÌÜµÌï© Í∞ùÏ≤¥ Ï¥ù Í∞úÏàò Î∞òÌôò"""
        try:
            self.connect()
            with self.connection.cursor() as cursor:
                cursor.execute(f"SELECT COUNT(*) FROM {self.schema_name}.integrated_objects")
                count = cursor.fetchone()[0]
                return count
        except Exception as e:
            logger.error(f"ÌÜµÌï© Í∞ùÏ≤¥ Í∞úÏàò Ï°∞Ìöå Ïò§Î•ò: {e}")
            return 0
        finally:
            self.disconnect()
    
    def count_integrated_objects_by_type(self, object_type: str) -> int:
        """ÌäπÏ†ï ÌÉÄÏûÖÏùò ÌÜµÌï© Í∞ùÏ≤¥ Í∞úÏàò Î∞òÌôò"""
        try:
            self.connect()
            with self.connection.cursor() as cursor:
                cursor.execute(
                    f"SELECT COUNT(*) FROM {self.schema_name}.integrated_objects WHERE object_type = %s",
                    (object_type,)
                )
                count = cursor.fetchone()[0]
                return count
        except Exception as e:
            logger.error(f"{object_type} ÌÉÄÏûÖ Í∞ùÏ≤¥ Í∞úÏàò Ï°∞Ìöå Ïò§Î•ò: {e}")
            return 0
        finally:
            self.disconnect()
    
    def get_integrated_objects_statistics(self) -> Dict[str, Any]:
        """ÌÜµÌï© Í∞ùÏ≤¥ ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Î∞òÌôò"""
        try:
            self.connect()
            with self.connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
                # Ï†ÑÏ≤¥ Í∞úÏàò
                cursor.execute(f"SELECT COUNT(*) FROM {self.schema_name}.integrated_objects")
                total_count = cursor.fetchone()[0]
                
                # ÌÉÄÏûÖÎ≥Ñ Í∞úÏàò
                cursor.execute(f"""
                    SELECT object_type, COUNT(*) as count 
                    FROM {self.schema_name}.integrated_objects 
                    GROUP BY object_type
                """)
                type_counts = {row['object_type']: row['count'] for row in cursor.fetchall()}
                
                # ÏµúÍ∑º ÏÉùÏÑ±Îêú Í∞ùÏ≤¥Îì§
                cursor.execute(f"""
                    SELECT object_type, MAX(created_at) as latest_created
                    FROM {self.schema_name}.integrated_objects 
                    GROUP BY object_type
                """)
                latest_by_type = {row['object_type']: row['latest_created'] for row in cursor.fetchall()}
                
                return {
                    'total_count': total_count,
                    'type_counts': type_counts,
                    'latest_by_type': latest_by_type,
                    'tenant_id': self.company_id,
                    'platform': self.platform,
                    'schema_name': self.schema_name
                }
                
        except Exception as e:
            logger.error(f"ÌÜµÌï© Í∞ùÏ≤¥ ÌÜµÍ≥Ñ Ï°∞Ìöå Ïò§Î•ò: {e}")
            return {
                'total_count': 0,
                'type_counts': {},
                'latest_by_type': {},
                'tenant_id': self.company_id,
                'platform': self.platform,
                'schema_name': self.schema_name
            }
        finally:
            self.disconnect()


def get_postgresql_database(company_id: str, platform: str = "freshdesk") -> PostgreSQLDatabase:
    """PostgreSQL Î©ÄÌã∞ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïù∏Ïä§ÌÑ¥Ïä§ Î∞òÌôò"""
    return PostgreSQLDatabase(company_id, platform)


# ÌÖåÎÑåÌä∏ Í¥ÄÎ¶¨ Ïú†Ìã∏Î¶¨Ìã∞
class TenantManager:
    """ÌÖåÎÑåÌä∏ Í¥ÄÎ¶¨ Ïú†Ìã∏Î¶¨Ìã∞"""
    
    @staticmethod
    def create_tenant(company_id: str, tenant_data: Dict[str, Any]) -> PostgreSQLDatabase:
        """ÏÉà ÌÖåÎÑåÌä∏ ÏÉùÏÑ±"""
        db = PostgreSQLDatabase(company_id)
        db.connect()
        db.register_tenant(tenant_data)
        return db
    
    @staticmethod
    def list_tenants() -> List[Dict[str, Any]]:
        """Ï†ÑÏ≤¥ ÌÖåÎÑåÌä∏ Î™©Î°ù Ï°∞Ìöå"""
        # ÏûÑÏãú Ïó∞Í≤∞Î°ú public.tenants Ï°∞Ìöå
        from .postgresql_database import PostgreSQLDatabase
        
        temp_db = PostgreSQLDatabase("temp")
        temp_db.connect()
        
        with temp_db.connection.cursor(cursor_factory=psycopg2.extras.RealDictCursor) as cursor:
            cursor.execute("SELECT * FROM public.tenants WHERE is_active = TRUE ORDER BY created_at")
            tenants = [dict(row) for row in cursor.fetchall()]
        
        temp_db.disconnect()
        return tenants
    
    @staticmethod
    def delete_tenant(company_id: str):
        """ÌÖåÎÑåÌä∏ ÏôÑÏ†Ñ ÏÇ≠Ï†ú (Ïä§ÌÇ§Îßà Ìè¨Ìï®)"""
        db = PostgreSQLDatabase(company_id)
        db.connect()
        
        with db.connection.cursor() as cursor:
            # Ïä§ÌÇ§Îßà ÏÇ≠Ï†ú
            cursor.execute(f"DROP SCHEMA IF EXISTS {db.schema_name} CASCADE")
            
            # public.tenantsÏóêÏÑú Ï†úÍ±∞
            cursor.execute("DELETE FROM public.tenants WHERE company_id = %s", (company_id,))
            
            db.connection.commit()
        
        db.disconnect()
        logger.info(f"ÌÖåÎÑåÌä∏ ÏôÑÏ†Ñ ÏÇ≠Ï†ú ÏôÑÎ£å: {company_id}")

# Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌïú alias
PostgreSQLDatabaseManager = PostgreSQLDatabase
