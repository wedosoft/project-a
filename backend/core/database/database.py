"""
SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Î∞è Î™®Îç∏ Ï†ïÏùò (Freshdesk Ï†ÑÏö©)

Freshdesk Î©ÄÌã∞ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞ ÏàòÏßëÏùÑ ÏúÑÌïú SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Íµ¨Ï°∞Î•º Ï†ïÏùòÌï©ÎãàÎã§.
ÌöåÏÇ¨Î≥ÑÎ°ú Î≥ÑÎèÑ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌååÏùºÏù¥ ÏÉùÏÑ±Îê©ÎãàÎã§ (Ïòà: company1_data.db, company2_data.db).
"""

import sqlite3
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path
import os

# ÌôòÍ≤ΩÎ≥ÄÏàò Î°úÎìú
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenvÍ∞Ä ÏÑ§ÏπòÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞ Î¨¥Ïãú

logger = logging.getLogger(__name__)

# Î©ÄÌã∞ÌÖåÎÑåÌä∏ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïù∏Ïä§ÌÑ¥Ïä§ Ï∫êÏãú
_database_instances = {}


class SQLiteDatabase:
    """SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Î∞è Í¥ÄÎ¶¨ ÌÅ¥ÎûòÏä§ (Î©ÄÌã∞ÌÖåÎÑåÌä∏ ÏßÄÏõê)"""
    
    def __init__(self, tenant_id: str, platform: str = "freshdesk"):
        """
        SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî (Freshdesk Ï†ÑÏö© Î©ÄÌã∞ÌÖåÎÑåÌä∏)
        
        Args:
            tenant_id: ÌÖåÎÑåÌä∏ ID (ÌïÑÏàò, Ïòà: "wedosoft", "acme")
            platform: ÌîåÎû´Ìèº Ïù¥Î¶Ñ (Í∏∞Î≥∏Í∞í: "freshdesk", ÌòÑÏû¨Îäî FreshdeskÎßå ÏßÄÏõê)
                     {tenant_id}_data.db ÌòïÏãùÏúºÎ°ú ÌöåÏÇ¨Î≥Ñ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌååÏùºÏù¥ ÏÉùÏÑ±Îê©ÎãàÎã§.
        """
        if not tenant_id:
            raise ValueError("tenant_idÎäî ÌïÑÏàò Îß§Í∞úÎ≥ÄÏàòÏûÖÎãàÎã§")
        
        # Freshdesk Ï†ÑÏö© ÌîåÎû´ÌèºÏúºÎ°ú Í≥†Ï†ï (Ï†êÏßÑÏ†Å Îã®ÏàúÌôî)
        if platform and platform != "freshdesk":
            logger.warning(f"ÌòÑÏû¨Îäî FreshdeskÎßå ÏßÄÏõêÎê©ÎãàÎã§. platform='{platform}' Î¨¥ÏãúÌïòÍ≥† 'freshdesk'Î°ú ÏÑ§Ï†ï")
        
        # Î©ÄÌã∞ÌÖåÎÑåÌä∏: ÌöåÏÇ¨Î≥Ñ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌååÏùº Î∂ÑÎ¶¨ (Freshdesk Ï†ÑÏö©)
        db_name = f"{tenant_id}_data.db"
        self.tenant_id = tenant_id
        self.platform = "freshdesk"  # Ìï≠ÏÉÅ Í≥†Ï†ï
        self.db_path = Path(__file__).parent.parent / "data" / db_name
        self.db_path.parent.mkdir(exist_ok=True)
        
        self.connection = None
        self._tables_created = False  # ÌÖåÏù¥Î∏î ÏÉùÏÑ± Ïó¨Î∂Ä Ï∂îÏ†Å
        logger.info(f"SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï¥àÍ∏∞Ìôî: {self.db_path} (ÌöåÏÇ¨: {tenant_id}, ÌîåÎû´Ìèº: Freshdesk Ï†ÑÏö©)")
    
    @property
    def tenant_id(self) -> str:
        """Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌïú tenant_id property (tenant_idÏôÄ ÎèôÏùº)"""
        return self.tenant_id
    
    def connect(self):
        """Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞"""
        self.connection = sqlite3.connect(str(self.db_path), check_same_thread=False)
        self.connection.row_factory = sqlite3.Row  # dict ÌòïÌÉúÎ°ú Í≤∞Í≥º Î∞òÌôò
        logger.info(f"Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ ÏôÑÎ£å: {self.db_path}")
        
        # ÌÖåÏù¥Î∏îÏù¥ ÏïÑÏßÅ ÏÉùÏÑ±ÎêòÏßÄ ÏïäÏïòÎã§Î©¥ ÏÉùÏÑ±
        if not self._tables_created:
            self.create_tables()
    
    def disconnect(self):
        """Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Ìï¥Ï†ú"""
        if self.connection:
            self.connection.close()
            self.connection = None
            logger.info("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïó∞Í≤∞ Ìï¥Ï†ú")
    
    def create_tables(self):
        """ÌÖåÏù¥Î∏î ÏÉùÏÑ±"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        
        # =====================================================
        # üè¢ SaaS ÎùºÏù¥ÏÑ†Ïä§ Í¥ÄÎ¶¨ ÌÖåÏù¥Î∏î (Î†àÍ±∞Ïãú ÎèÑÎ©îÏù∏ ÌÖåÏù¥Î∏î Ï†úÍ±∞Îê®)
        # =====================================================

        # =====================================================
        # üè¢ SaaS ÎùºÏù¥ÏÑ†Ïä§ Í¥ÄÎ¶¨ ÌÖåÏù¥Î∏î Ï∂îÍ∞Ä
        # =====================================================
        
        # Íµ¨ÎèÖ ÌîåÎûú Ï†ïÏùò (SQLite Î≤ÑÏ†Ñ)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS subscription_plans (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                plan_name TEXT UNIQUE NOT NULL,
                display_name TEXT NOT NULL,
                base_seats INTEGER NOT NULL,
                base_monthly_cost REAL NOT NULL,
                additional_seat_cost REAL NOT NULL,
                max_seats INTEGER,
                max_tickets_per_month INTEGER,
                max_api_calls_per_day INTEGER,
                features TEXT NOT NULL, -- JSON Î¨∏ÏûêÏó¥
                is_active BOOLEAN DEFAULT 1,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # Í≥†Í∞ùÏÇ¨ Ï†ïÎ≥¥ (SQLite Î≤ÑÏ†Ñ)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS companies (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                company_name TEXT NOT NULL,
                domain TEXT UNIQUE NOT NULL,
                contact_email TEXT NOT NULL,
                subscription_plan_id INTEGER NOT NULL,
                purchased_seats INTEGER NOT NULL,
                used_seats INTEGER DEFAULT 0,
                billing_status TEXT DEFAULT 'active',
                subscription_start TEXT NOT NULL,
                subscription_end TEXT,
                next_billing_date TEXT,
                monthly_cost REAL NOT NULL,
                current_month_tickets INTEGER DEFAULT 0,
                current_day_api_calls INTEGER DEFAULT 0,
                last_reset_month TEXT,
                last_reset_day TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                freshdesk_domain TEXT NOT NULL,
                FOREIGN KEY (subscription_plan_id) REFERENCES subscription_plans(id)
            )
        """)
        
        # ÏÉÅÎã¥Ïõê Ï†ïÎ≥¥ (SQLite Î≤ÑÏ†Ñ)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS agents (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tenant_id INTEGER NOT NULL,
                email TEXT NOT NULL,
                name TEXT NOT NULL,
                freshdesk_agent_id INTEGER,
                freshdesk_role TEXT,
                license_status TEXT DEFAULT 'inactive',
                seat_assigned BOOLEAN DEFAULT 0,
                assigned_by INTEGER,
                assigned_at TEXT,
                feature_overrides TEXT, -- JSON Î¨∏ÏûêÏó¥
                last_login_at TEXT,
                last_activity_at TEXT,
                monthly_tickets_processed INTEGER DEFAULT 0,
                monthly_ai_summaries_used INTEGER DEFAULT 0,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                is_active BOOLEAN DEFAULT 1,
                FOREIGN KEY (tenant_id) REFERENCES companies(id),
                FOREIGN KEY (assigned_by) REFERENCES agents(id),
                UNIQUE(tenant_id, email),
                UNIQUE(tenant_id, freshdesk_agent_id)
            )
        """)
        
        # ÏÇ¨Ïö©Îüâ Ï∂îÏ†Å Î°úÍ∑∏ (SQLite Î≤ÑÏ†Ñ)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS usage_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tenant_id INTEGER NOT NULL,
                agent_id INTEGER,
                usage_type TEXT NOT NULL,
                usage_count INTEGER DEFAULT 1,
                resource_id TEXT,
                metadata TEXT, -- JSON Î¨∏ÏûêÏó¥
                usage_date TEXT NOT NULL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (tenant_id) REFERENCES companies(id),
                FOREIGN KEY (agent_id) REFERENCES agents(id)
            )
        """)
        
        # Í≤∞Ï†ú Ïù¥Î†• (SQLite Î≤ÑÏ†Ñ)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS billing_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tenant_id INTEGER NOT NULL,
                billing_period_start TEXT NOT NULL,
                billing_period_end TEXT NOT NULL,
                base_amount REAL NOT NULL,
                additional_seats_count INTEGER DEFAULT 0,
                additional_seats_amount REAL DEFAULT 0,
                total_amount REAL NOT NULL,
                status TEXT DEFAULT 'pending',
                payment_method TEXT,
                transaction_id TEXT,
                plan_name TEXT NOT NULL,
                plan_features TEXT, -- JSON Î¨∏ÏûêÏó¥
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (tenant_id) REFERENCES companies(id)
            )
        """)
        
        # ÏãúÏä§ÌÖú ÏÑ§Ï†ï (SQLite Î≤ÑÏ†Ñ)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS system_settings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                setting_key TEXT UNIQUE NOT NULL,
                setting_value TEXT,
                is_encrypted BOOLEAN DEFAULT 0,
                description TEXT,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ÌöåÏÇ¨Î≥Ñ Í∞úÎ≥Ñ ÏÑ§Ï†ï (SQLite Î≤ÑÏ†Ñ) - ÌÖåÎÑåÌä∏Î≥Ñ ÏÑ§Ï†ï Í¥ÄÎ¶¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS company_settings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                tenant_id INTEGER NOT NULL,
                setting_key TEXT NOT NULL,
                setting_value TEXT,
                is_encrypted BOOLEAN DEFAULT 0,
                description TEXT,  -- ÏÑ§Ï†ï ÏÑ§Î™Ö Ïª¨Îüº Ï∂îÍ∞Ä
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (tenant_id) REFERENCES companies(id),
                UNIQUE(tenant_id, setting_key)
            )
        """)
        
        # =====================================================
        # üìä SaaS Í¥ÄÎ†® Ïù∏Îç±Ïä§ ÏÉùÏÑ±
        # =====================================================
        
        # ÌöåÏÇ¨ Í¥ÄÎ†® Ïù∏Îç±Ïä§
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_companies_domain ON companies(domain)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_companies_billing_status ON companies(billing_status)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_companies_plan_id ON companies(subscription_plan_id)")
        
        # ÏÉÅÎã¥Ïõê Í¥ÄÎ†® Ïù∏Îç±Ïä§
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_agents_tenant_id ON agents(tenant_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_agents_email ON agents(email)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_agents_seat_assigned ON agents(seat_assigned)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_agents_license_status ON agents(license_status)")
        
        # ÏÇ¨Ïö©Îüâ Í¥ÄÎ†® Ïù∏Îç±Ïä§
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_usage_logs_tenant_id ON usage_logs(tenant_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_usage_logs_agent_id ON usage_logs(agent_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_usage_logs_usage_date ON usage_logs(usage_date)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_usage_logs_usage_type ON usage_logs(usage_type)")
        
        # =====================================================
        # üìä Í∏∞Î≥∏ SaaS Îç∞Ïù¥ÌÑ∞ ÏûÖÎ†•
        # =====================================================
        
        # Í∏∞Î≥∏ ÌîåÎûú ÏÉùÏÑ± (Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏùÑ Í≤ΩÏö∞ÏóêÎßå)
        cursor.execute("SELECT COUNT(*) FROM subscription_plans")
        if cursor.fetchone()[0] == 0:
            cursor.execute("""
                INSERT INTO subscription_plans (plan_name, display_name, base_seats, base_monthly_cost, additional_seat_cost, max_seats, features) VALUES
                ('starter', 'Starter Plan', 3, 29.00, 8.00, 10, '{"ai_summary": true, "basic_analytics": true, "export_limit": 50}'),
                ('professional', 'Professional Plan', 10, 99.00, 6.00, 50, '{"ai_summary": true, "advanced_analytics": true, "custom_fields": true, "export_limit": 500}'),
                ('enterprise', 'Enterprise Plan', 25, 299.00, 5.00, null, '{"ai_summary": true, "advanced_analytics": true, "custom_fields": true, "api_access": true, "export_limit": null}')
            """)
            logger.info("Í∏∞Î≥∏ Íµ¨ÎèÖ ÌîåÎûú ÏÉùÏÑ± ÏôÑÎ£å")
        
        # Í∏∞Î≥∏ ÏãúÏä§ÌÖú ÏÑ§Ï†ï (Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏùÑ Í≤ΩÏö∞ÏóêÎßå)
        # üîê Î≥¥ÏïàÏ†ïÏ±Ö: API ÌÇ§, ÎèÑÎ©îÏù∏ Îì± ÎØºÍ∞êÌïú Ï†ïÎ≥¥Îäî Ï†àÎåÄ DB Ï†ÄÏû• Í∏àÏßÄ
        # üí° Ïù∏ÌîÑÎùº Í¥ÄÎ†® ÏÑ§Ï†ïÎßå Ï†ÄÏû• (Î≤°ÌÑ∞DB URL, LLM Î™®Îç∏Î™Ö Îì±)
        cursor.execute("SELECT COUNT(*) FROM system_settings")
        if cursor.fetchone()[0] == 0:
            cursor.execute("""
                INSERT INTO system_settings (setting_key, setting_value, is_encrypted, description) VALUES
                ('qdrant_url', 'http://localhost:6333', 0, 'Qdrant vector database URL'),
                ('qdrant_collection_name', 'saas_tickets', 0, 'Default Qdrant collection name'),
                ('default_llm_model', 'gpt-4o-mini', 0, 'Default LLM model for AI features'),
                ('openai_base_url', 'https://api.openai.com/v1', 0, 'OpenAI API base URL'),
                ('max_attachment_size_mb', '10', 0, 'Maximum attachment size in MB'),
                ('session_timeout_hours', '24', 0, 'User session timeout in hours'),
                ('max_tokens_per_request', '4000', 0, 'Maximum tokens per LLM request'),
                ('chunk_size', '1000', 0, 'Default text chunk size for vectorization'),
                ('chunk_overlap', '200', 0, 'Default chunk overlap for vectorization')
            """)
            logger.info("Í∏∞Î≥∏ ÏãúÏä§ÌÖú ÏÑ§Ï†ï ÏÉùÏÑ± ÏôÑÎ£å (Ïù∏ÌîÑÎùº ÏÑ§Ï†ïÎßå)")

        # =====================================================
        # üìä ÌÜµÌï© Îç∞Ïù¥ÌÑ∞ ÌÖåÏù¥Î∏î (UNIFIED SCHEMA)
        # =====================================================
        
        # ÌÜµÌï© Í∞ùÏ≤¥ ÌÖåÏù¥Î∏î - Î™®Îì† ÎèÑÎ©îÏù∏ Îç∞Ïù¥ÌÑ∞Î•º Ï†ÄÏû•
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS integrated_objects (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                original_id TEXT NOT NULL,
                tenant_id TEXT NOT NULL,
                platform TEXT NOT NULL,
                object_type TEXT NOT NULL, -- 'ticket', 'conversation', 'article', 'attachment'
                original_data TEXT NOT NULL, -- ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ JSON
                integrated_content TEXT, -- ÌÜµÌï©Îêú ÏΩòÌÖêÏ∏† (Í≤ÄÏÉâÏö©)
                summary TEXT, -- LLM ÏöîÏïΩ
                metadata TEXT, -- Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ JSON (parent_id, status, dates Îì±)
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                updated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(tenant_id, platform, object_type, original_id)
            )
        """)
        
        # ÏßÑÌñâÏÉÅÌô© Î°úÍ∑∏ ÌÖåÏù¥Î∏î (Ïã§ÏãúÍ∞Ñ ÏûëÏóÖ ÏßÑÌñâÏÉÅÌô© Ï∂îÏ†Å)
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS progress_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                job_id TEXT NOT NULL,
                tenant_id TEXT NOT NULL,
                message TEXT NOT NULL,
                percentage REAL NOT NULL,
                step INTEGER NOT NULL,
                total_steps INTEGER NOT NULL,
                created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(job_id, tenant_id, step)
            )
        """)
        
        # =====================================================
        # üìä ÌÜµÌï© Ïä§ÌÇ§Îßà Ïù∏Îç±Ïä§ ÏÉùÏÑ± (Î†àÍ±∞Ïãú ÌÖåÏù¥Î∏î Ïù∏Îç±Ïä§ Ï†úÍ±∞Îê®)
        # =====================================================
        
        # Integrated objects ÌÖåÏù¥Î∏î Ïù∏Îç±Ïä§ (Î™®Îì† ÎèÑÎ©îÏù∏ Îç∞Ïù¥ÌÑ∞Ïö©)
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_tenant_id ON integrated_objects(tenant_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_object_type ON integrated_objects(object_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_original_id ON integrated_objects(original_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_company_platform ON integrated_objects(tenant_id, platform)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_company_type ON integrated_objects(tenant_id, object_type)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_content_search ON integrated_objects(integrated_content)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_created_at ON integrated_objects(created_at)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_integrated_updated_at ON integrated_objects(updated_at)")
        
        # Progress logs ÌÖåÏù¥Î∏î Ïù∏Îç±Ïä§
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_progress_job_id ON progress_logs(job_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_progress_tenant_id ON progress_logs(tenant_id)")
        cursor.execute("CREATE INDEX IF NOT EXISTS idx_progress_created_at ON progress_logs(created_at)")
        
        self.connection.commit()
        logger.info("Î™®Îì† ÌÖåÏù¥Î∏î ÏÉùÏÑ± ÏôÑÎ£å")
        self._tables_created = True  # ÌÖåÏù¥Î∏î ÏÉùÏÑ± ÏôÑÎ£å ÌëúÏãú
    
    def insert_ticket(self, ticket_data: Dict[str, Any]) -> int:
        """Ìã∞Ïºì Îç∞Ïù¥ÌÑ∞ ÏÇΩÏûÖ - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©"""
        # Ìã∞Ïºì Îç∞Ïù¥ÌÑ∞Î•º ÌÜµÌï© ÌòïÌÉúÎ°ú Î≥ÄÌôò
        integrated_data = {
            'original_id': str(ticket_data.get('id')),
            'tenant_id': ticket_data.get('tenant_id'),
            'platform': ticket_data.get('platform'),
            'object_type': 'ticket',
            'original_data': ticket_data,
            'integrated_content': ticket_data.get('description_text') or ticket_data.get('description'),
            'summary': ticket_data.get('subject'),
            'metadata': {
                'status': ticket_data.get('status'),
                'priority': ticket_data.get('priority'),
                'type': ticket_data.get('type'),
                'source': ticket_data.get('source'),
                'requester_id': ticket_data.get('requester_id'),
                'responder_id': ticket_data.get('responder_id'),
                'group_id': ticket_data.get('group_id'),
                'tags': ticket_data.get('tags', []),
                'custom_fields': ticket_data.get('custom_fields', {}),
                'created_at': ticket_data.get('created_at'),
                'updated_at': ticket_data.get('updated_at'),
                'due_by': ticket_data.get('due_by'),
                'fr_due_by': ticket_data.get('fr_due_by'),
                'is_escalated': ticket_data.get('is_escalated')
            }
        }
        logger.info(f"DB insert_ticket Ìò∏Ï∂úÎê®: ticket_id={ticket_data.get('id')}, tenant_id={ticket_data.get('tenant_id')}")
        result = self.insert_integrated_object(integrated_data)
        logger.info(f"DB insert_ticket ÏôÑÎ£å: lastrowid={result}")
        return result
    
    def insert_conversation(self, conversation_data: Dict[str, Any]) -> int:
        """ÎåÄÌôî Îç∞Ïù¥ÌÑ∞ ÏÇΩÏûÖ - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©"""
        # ÎåÄÌôî Îç∞Ïù¥ÌÑ∞Î•º ÌÜµÌï© ÌòïÌÉúÎ°ú Î≥ÄÌôò
        integrated_data = {
            'original_id': str(conversation_data.get('id')),
            'tenant_id': conversation_data.get('tenant_id'),
            'platform': conversation_data.get('platform'),
            'object_type': 'conversation',
            'original_data': conversation_data,
            'integrated_content': conversation_data.get('body_text') or conversation_data.get('body'),
            'summary': f"Conversation {conversation_data.get('id')} for ticket {conversation_data.get('ticket_id')}",
            'metadata': {
                'ticket_original_id': str(conversation_data.get('ticket_id')),
                'user_id': conversation_data.get('user_id'),
                'incoming': conversation_data.get('incoming'),
                'private': conversation_data.get('private'),
                'source': conversation_data.get('source'),
                'attachments': conversation_data.get('attachments', []),
                'created_at': conversation_data.get('created_at'),
                'updated_at': conversation_data.get('updated_at')
            }
        }
        return self.insert_integrated_object(integrated_data)
    
    def insert_article(self, article_data: Dict[str, Any]) -> int:
        """ÏßÄÏãùÎ≤†Ïù¥Ïä§ Î¨∏ÏÑú ÏÇΩÏûÖ - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©"""
        # Î¨∏ÏÑú Îç∞Ïù¥ÌÑ∞Î•º ÌÜµÌï© ÌòïÌÉúÎ°ú Î≥ÄÌôò
        integrated_data = {
            'original_id': str(article_data.get('id')),
            'tenant_id': article_data.get('tenant_id'),
            'platform': article_data.get('platform'),
            'object_type': 'article',
            'original_data': article_data,
            'integrated_content': article_data.get('description_text') or article_data.get('description'),
            'summary': article_data.get('title'),
            'metadata': {
                'status': article_data.get('status'),
                'type': article_data.get('type'),
                'category_id': article_data.get('category_id'),
                'folder_id': article_data.get('folder_id'),
                'agent_id': article_data.get('agent_id'),
                'hierarchy': article_data.get('hierarchy', []),
                'thumbs_up': article_data.get('thumbs_up', 0),
                'thumbs_down': article_data.get('thumbs_down', 0),
                'hits': article_data.get('hits', 0),
                'tags': article_data.get('tags', []),
                'seo_data': article_data.get('seo_data', {}),
                'created_at': article_data.get('created_at'),
                'updated_at': article_data.get('updated_at')
            }
        }
        return self.insert_integrated_object(integrated_data)
    
    def insert_integrated_object(self, integrated_data: Dict[str, Any]) -> int:
        """ÌÜµÌï© Í∞ùÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏÇΩÏûÖ (platform-neutral 3-tuple Í∏∞Î∞ò)"""
        # DB Ïó∞Í≤∞ ÏÉÅÌÉú ÌôïÏù∏ Î∞è Ïû¨Ïó∞Í≤∞
        if not self.connection:
            logger.warning("DB Ïó∞Í≤∞Ïù¥ ÎÅäÏñ¥Ïßê. Ïû¨Ïó∞Í≤∞ ÏãúÎèÑ...")
            self.connect()
            # self.create_tables() # Ïù¥ÎØ∏ connect()ÏóêÏÑú Ï≤òÎ¶¨Îê®
            logger.info("DB Ïû¨Ïó∞Í≤∞ ÏôÑÎ£å")
        
        cursor = self.connection.cursor()
        
        # ÌïÑÏàò ÌïÑÎìú Í≤ÄÏ¶ù
        if not integrated_data.get('tenant_id'):
            raise ValueError("tenant_idÎäî ÌïÑÏàòÏûÖÎãàÎã§")
        if not integrated_data.get('platform'):
            raise ValueError("platformÏùÄ ÌïÑÏàòÏûÖÎãàÎã§")
        
        cursor.execute("""
            INSERT OR REPLACE INTO integrated_objects (
                original_id, tenant_id, platform, object_type,
                original_data, integrated_content, summary, metadata
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            str(integrated_data.get('original_id')),  # original_id (Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò)
            integrated_data.get('tenant_id'),
            integrated_data.get('platform'),
            integrated_data.get('object_type'),
            json.dumps(integrated_data.get('original_data', {})),
            integrated_data.get('integrated_content'),
            integrated_data.get('summary'),
            json.dumps(integrated_data.get('metadata', {}))
        ))
        
        self.connection.commit()
        return cursor.lastrowid
    
    def insert_attachment(self, attachment_data: Dict[str, Any]) -> int:
        """Ï≤®Î∂ÄÌååÏùº Îç∞Ïù¥ÌÑ∞ ÏÇΩÏûÖ - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©
        
        Args:
            attachment_data: Ï≤®Î∂ÄÌååÏùº Îç∞Ïù¥ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨
                - original_id: Ï≤®Î∂ÄÌååÏùº ÏõêÎ≥∏ ID
                - tenant_id: ÌÖåÎÑåÌä∏ ID
                - platform: ÌîåÎû´Ìèº
                - parent_type: Î∂ÄÎ™® ÌÉÄÏûÖ ('ticket', 'conversation', 'article')
                - parent_original_id: Î∂ÄÎ™® Í∞ùÏ≤¥ ÏõêÎ≥∏ ID
                - name: ÌååÏùºÎ™Ö
                - content_type: ÏΩòÌÖêÏ∏† ÌÉÄÏûÖ
                - size: ÌååÏùº ÌÅ¨Í∏∞
                - attachment_url: Ï≤®Î∂ÄÌååÏùº URL
                - created_at: ÏÉùÏÑ±ÏùºÏãú
                - updated_at: ÏàòÏ†ïÏùºÏãú
                - raw_data: ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞
                
        Returns:
            int: ÏÉùÏÑ±Îêú Î†àÏΩîÎìú ID
        """
        # Ï≤®Î∂ÄÌååÏùº Îç∞Ïù¥ÌÑ∞Î•º ÌÜµÌï© ÌòïÌÉúÎ°ú Î≥ÄÌôò
        integrated_data = {
            'original_id': str(attachment_data.get('original_id')),
            'tenant_id': attachment_data.get('tenant_id'),
            'platform': attachment_data.get('platform'),
            'object_type': 'attachment',
            'original_data': attachment_data,
            'integrated_content': f"File: {attachment_data.get('name')}",
            'summary': f"Attachment: {attachment_data.get('name')} ({attachment_data.get('content_type')})",
            'metadata': {
                'parent_type': attachment_data.get('parent_type'),
                'parent_original_id': attachment_data.get('parent_original_id'),
                'name': attachment_data.get('name'),
                'content_type': attachment_data.get('content_type'),
                'size': attachment_data.get('size'),
                'attachment_url': attachment_data.get('attachment_url'),
                'created_at': attachment_data.get('created_at'),
                'updated_at': attachment_data.get('updated_at')
            }
        }
        result = self.insert_integrated_object(integrated_data)
        logger.debug(f"Ï≤®Î∂ÄÌååÏùº Ï†ÄÏû• ÏôÑÎ£å: {attachment_data.get('name')} (ID: {attachment_data.get('original_id')})")
        return result

    def log_collection_job(self, job_data: Dict[str, Any]) -> int:
        """ÏàòÏßë ÏûëÏóÖ Î°úÍ∑∏ Ï†ÄÏû• - Î†àÍ±∞Ïãú Î©îÏÑúÎìú, ÌòÑÏû¨Îäî Î°úÍ∑∏Îßå Ï∂úÎ†•
        
        Args:
            job_data: ÏûëÏóÖ Îç∞Ïù¥ÌÑ∞ ÎîïÏÖîÎÑàÎ¶¨
                
        Returns:
            int: 0 (ÎçîÎØ∏ Í∞í)
        """
        logger.info(f"ÏàòÏßë ÏûëÏóÖ Î°úÍ∑∏: job_id={job_data.get('job_id')}, "
                   f"status={job_data.get('status')}, "
                   f"tickets={job_data.get('tickets_collected', 0)}, "
                   f"conversations={job_data.get('conversations_collected', 0)}, "
                   f"articles={job_data.get('articles_collected', 0)}, "
                   f"attachments={job_data.get('attachments_collected', 0)}")
        return 0

    def log_progress(self, job_id: str, step: int, total_steps: int, message: str = "", 
                    tenant_id: str = None, percentage: float = None) -> int:
        """ÏßÑÌñâÏÉÅÌô© Î°úÍ∑∏ Ï†ÄÏû•
        
        Args:
            job_id: ÏûëÏóÖ ID
            step: ÌòÑÏû¨ Îã®Í≥Ñ
            total_steps: Ï†ÑÏ≤¥ Îã®Í≥Ñ Ïàò
            message: Î©îÏãúÏßÄ
            tenant_id: ÌÖåÎÑåÌä∏ ID
            percentage: ÏßÑÌñâÎ•† (0-100)
            
        Returns:
            int: ÏÉùÏÑ±Îêú Î°úÍ∑∏ ID
        """
        if not self.connection:
            logger.warning("DB Ïó∞Í≤∞Ïù¥ ÎÅäÏñ¥Ïßê. Ïû¨Ïó∞Í≤∞ ÏãúÎèÑ...")
            self.connect()
            # self.create_tables() # Ïù¥ÎØ∏ connect()ÏóêÏÑú Ï≤òÎ¶¨Îê®
            logger.info("DB Ïû¨Ïó∞Í≤∞ ÏôÑÎ£å")
        
        cursor = self.connection.cursor()
        
        # percentage Í≥ÑÏÇ∞ (Ï†úÍ≥µÎêòÏßÄ ÏïäÏùÄ Í≤ΩÏö∞)
        if percentage is None:
            percentage = (step / total_steps) * 100 if total_steps > 0 else 0
        
        cursor.execute("""
            INSERT OR REPLACE INTO progress_logs (
                job_id, tenant_id, message, percentage, step, total_steps
            ) VALUES (?, ?, ?, ?, ?, ?)
        """, (
            job_id,
            tenant_id or getattr(self, 'tenant_id', None),
            message,
            percentage,
            step,
            total_steps
        ))
        
        self.connection.commit()
        logger.info(f"ÏßÑÌñâÏÉÅÌô© Î°úÍ∑∏ Ï†ÄÏû•: job_id={job_id}, step={step}/{total_steps}, message={message}")
        return cursor.lastrowid

    def get_tickets_by_company_and_platform(self, tenant_id: str, platform: str) -> List[Dict[str, Any]]:
        """ÌöåÏÇ¨ Î∞è ÌîåÎû´ÌèºÎ≥Ñ Ìã∞Ïºì Ï°∞Ìöå - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©
        
        Args:
            tenant_id: ÌÖåÎÑåÌä∏ ID
            platform: ÌîåÎû´ÌèºÎ™Ö
            
        Returns:
            List[Dict[str, Any]]: Ìã∞Ïºì Î™©Î°ù
        """
        if not self.connection:
            logger.warning("DB Ïó∞Í≤∞Ïù¥ ÎÅäÏñ¥Ïßê. Ïû¨Ïó∞Í≤∞ ÏãúÎèÑ...")
            self.connect()
            logger.info("DB Ïû¨Ïó∞Í≤∞ ÏôÑÎ£å")
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT * FROM integrated_objects 
            WHERE tenant_id = ? AND platform = ? AND object_type = 'ticket'
            ORDER BY json_extract(metadata, '$.created_at') DESC
        """, (tenant_id, platform))
        
        rows = cursor.fetchall()
        
        # Row Í∞ùÏ≤¥Î•º ÎîïÏÖîÎÑàÎ¶¨Î°ú Î≥ÄÌôò
        tickets = []
        for row in rows:
            ticket_obj = dict(row)
            
            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ÏôÄ ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ ÌååÏã±
            metadata = json.loads(ticket_obj.get('metadata', '{}'))
            original_data = json.loads(ticket_obj.get('original_data', '{}'))
            
            # Í∏∞Ï°¥ ticket ÌòïÌÉúÎ°ú Î≥ÄÌôò (ID ÌÉÄÏûÖ ÏïàÏ†Ñ Ï≤òÎ¶¨)
            original_id = ticket_obj.get('original_id')
            try:
                # Ïà´Ïûê IDÏù∏ Í≤ΩÏö∞ Ï†ïÏàòÎ°ú Î≥ÄÌôò, ÏïÑÎãàÎ©¥ Î¨∏ÏûêÏó¥ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
                parsed_id = int(original_id) if original_id.isdigit() else original_id
            except (ValueError, AttributeError):
                parsed_id = original_id
            
            ticket = {
                'id': parsed_id,
                'original_id': ticket_obj.get('original_id'),
                'tenant_id': ticket_obj.get('tenant_id'),
                'platform': ticket_obj.get('platform'),
                'subject': ticket_obj.get('summary'),
                'description': original_data.get('description'),
                'description_text': ticket_obj.get('integrated_content'),
                'status': metadata.get('status'),
                'priority': metadata.get('priority'),
                'type': metadata.get('type'),
                'source': metadata.get('source'),
                'requester_id': metadata.get('requester_id'),
                'responder_id': metadata.get('responder_id'),
                'group_id': metadata.get('group_id'),
                'tags': metadata.get('tags', []),
                'custom_fields': metadata.get('custom_fields', {}),
                'created_at': metadata.get('created_at'),
                'updated_at': metadata.get('updated_at'),
                'due_by': metadata.get('due_by'),
                'fr_due_by': metadata.get('fr_due_by'),
                'is_escalated': metadata.get('is_escalated'),
                'raw_data': original_data
            }
            tickets.append(ticket)
        
        return tickets

    def get_articles_by_company_and_platform(self, tenant_id: str, platform: str) -> List[Dict[str, Any]]:
        """ÌöåÏÇ¨ Î∞è ÌîåÎû´ÌèºÎ≥Ñ KB Î¨∏ÏÑú Ï°∞Ìöå - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©
        
        Args:
            tenant_id: ÌÖåÎÑåÌä∏ ID
            platform: ÌîåÎû´ÌèºÎ™Ö
            
        Returns:
            List[Dict[str, Any]]: KB Î¨∏ÏÑú Î™©Î°ù
        """
        if not self.connection:
            logger.warning("DB Ïó∞Í≤∞Ïù¥ ÎÅäÏñ¥Ïßê. Ïû¨Ïó∞Í≤∞ ÏãúÎèÑ...")
            self.connect()
            logger.info("DB Ïû¨Ïó∞Í≤∞ ÏôÑÎ£å")
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT * FROM integrated_objects 
            WHERE tenant_id = ? AND platform = ? AND object_type = 'article'
            ORDER BY json_extract(metadata, '$.created_at') DESC
        """, (tenant_id, platform))
        
        rows = cursor.fetchall()
        
        # Row Í∞ùÏ≤¥Î•º ÎîïÏÖîÎÑàÎ¶¨Î°ú Î≥ÄÌôò
        articles = []
        for row in rows:
            article_obj = dict(row)
            
            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ÏôÄ ÏõêÎ≥∏ Îç∞Ïù¥ÌÑ∞ ÌååÏã±
            metadata = json.loads(article_obj.get('metadata', '{}'))
            original_data = json.loads(article_obj.get('original_data', '{}'))
            
            # Í∏∞Ï°¥ article ÌòïÌÉúÎ°ú Î≥ÄÌôò (ID ÌÉÄÏûÖ ÏïàÏ†Ñ Ï≤òÎ¶¨)
            original_id = article_obj.get('original_id')
            try:
                # Ïà´Ïûê IDÏù∏ Í≤ΩÏö∞ Ï†ïÏàòÎ°ú Î≥ÄÌôò, ÏïÑÎãàÎ©¥ Î¨∏ÏûêÏó¥ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
                parsed_id = int(original_id) if original_id.isdigit() else original_id
            except (ValueError, AttributeError):
                parsed_id = original_id
            
            article = {
                'id': parsed_id,
                'original_id': article_obj.get('original_id'),
                'tenant_id': article_obj.get('tenant_id'),
                'platform': article_obj.get('platform'),
                'title': article_obj.get('summary'),
                'description': original_data.get('description'),
                'description_text': article_obj.get('integrated_content'),
                'status': metadata.get('status'),
                'type': metadata.get('type'),
                'category_id': metadata.get('category_id'),
                'folder_id': metadata.get('folder_id'),
                'agent_id': metadata.get('agent_id'),
                'hierarchy': metadata.get('hierarchy', []),
                'thumbs_up': metadata.get('thumbs_up', 0),
                'thumbs_down': metadata.get('thumbs_down', 0),
                'hits': metadata.get('hits', 0),
                'tags': metadata.get('tags', []),
                'seo_data': metadata.get('seo_data', {}),
                'created_at': metadata.get('created_at'),
                'updated_at': metadata.get('updated_at'),
                'raw_data': original_data
            }
            articles.append(article)
        
        return articles

    def get_attachments_by_ticket(self, ticket_original_id: str) -> List[Dict[str, Any]]:
        """Ìã∞ÏºìÏùò Ï≤®Î∂ÄÌååÏùº Ï°∞Ìöå - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©
        
        Args:
            ticket_original_id: Ìã∞Ïºì ÏõêÎ≥∏ ID
            
        Returns:
            List[Dict[str, Any]]: Ï≤®Î∂ÄÌååÏùº Îç∞Ïù¥ÌÑ∞ Î¶¨Ïä§Ìä∏
        """
        if not self.connection:
            self.connect()
            
        cursor = self.connection.cursor()
        
        # Ìã∞ÏºìÍ≥º Í¥ÄÎ†®Îêú Î™®Îì† Ï≤®Î∂ÄÌååÏùº Ï°∞Ìöå (Ìã∞Ïºì ÏßÅÏ†ë Ï≤®Î∂Ä + ÎåÄÌôî Ï≤®Î∂ÄÌååÏùº)
        # Î®ºÏ†Ä Ìï¥Îãπ Ìã∞ÏºìÏùò ÎåÄÌôîÎì§ÏùÑ Ï∞æÍ∏∞
        conversation_ids_query = """
            SELECT original_id FROM integrated_objects 
            WHERE tenant_id = ? AND platform = ? AND object_type = 'conversation'
            AND json_extract(metadata, '$.ticket_original_id') = ?
        """
        
        cursor.execute(conversation_ids_query, (self.tenant_id, self.platform, ticket_original_id))
        conversation_ids = [row[0] for row in cursor.fetchall()]
        
        # Ï≤®Î∂ÄÌååÏùº Ï°∞Ìöå - Ìã∞Ïºì ÏßÅÏ†ë Ï≤®Î∂Ä ÎòêÎäî ÎåÄÌôî Ï≤®Î∂Ä
        placeholders = ','.join(['?'] * len(conversation_ids)) if conversation_ids else "''"
        
        query = f"""
            SELECT * FROM integrated_objects 
            WHERE tenant_id = ? AND platform = ? AND object_type = 'attachment'
            AND (
                json_extract(metadata, '$.parent_type') = 'ticket' 
                AND json_extract(metadata, '$.parent_original_id') = ?
                OR (
                    json_extract(metadata, '$.parent_type') = 'conversation'
                    AND json_extract(metadata, '$.parent_original_id') IN ({placeholders})
                )
            )
            ORDER BY json_extract(metadata, '$.created_at')
        """
        
        params = [self.tenant_id, self.platform, ticket_original_id] + conversation_ids
        cursor.execute(query, params)
        
        rows = cursor.fetchall()
        attachments = []
        
        for row in rows:
            attachment_obj = dict(row)
            metadata = json.loads(attachment_obj.get('metadata', '{}'))
            
            # Í∏∞Ï°¥ ÌòïÌÉúÎ°ú Î≥ÄÌôò
            attachment = {
                'attachment_id': attachment_obj.get('original_id'),
                'name': metadata.get('name'),
                'content_type': metadata.get('content_type'),
                'size': metadata.get('size'),
                'download_url': metadata.get('attachment_url'),
                'parent_type': metadata.get('parent_type'),
                'conversation_id': metadata.get('parent_original_id') if metadata.get('parent_type') == 'conversation' else None,
                'created_at': metadata.get('created_at'),
                'raw_data': attachment_obj.get('original_data')
            }
            attachments.append(attachment)
        
        logger.debug(f"Ìã∞Ïºì {ticket_original_id}Ïùò Ï≤®Î∂ÄÌååÏùº Ï°∞Ìöå ÏôÑÎ£å: {len(attachments)}Í∞ú")
        return attachments

    def clear_all_data(self, tenant_id: str = None, platform: str = None):
        """Î™®Îì† Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú (force_rebuildÏö©) - integrated_objects ÌÖåÏù¥Î∏î ÏÇ¨Ïö©
        
        Args:
            tenant_id: ÌÖåÎÑåÌä∏ ID (ÏÑ†ÌÉùÏÇ¨Ìï≠, ÏßÄÏ†ïÏãú Ìï¥Îãπ ÌöåÏÇ¨ Îç∞Ïù¥ÌÑ∞Îßå ÏÇ≠Ï†ú)
            platform: ÌîåÎû´ÌèºÎ™Ö (ÏÑ†ÌÉùÏÇ¨Ìï≠, ÏßÄÏ†ïÏãú Ìï¥Îãπ ÌîåÎû´Ìèº Îç∞Ïù¥ÌÑ∞Îßå ÏÇ≠Ï†ú)
        """
        if not self.connection:
            logger.warning("DB Ïó∞Í≤∞Ïù¥ ÎÅäÏñ¥Ïßê. Ïû¨Ïó∞Í≤∞ ÏãúÎèÑ...")
            self.connect()
            logger.info("DB Ïû¨Ïó∞Í≤∞ ÏôÑÎ£å")
        
        cursor = self.connection.cursor()
        
        # Ï°∞Í±¥Î∂Ä ÏÇ≠Ï†ú - Ïù¥Ï†ú integrated_objectsÏôÄ progress_logsÎßå ÏÇ≠Ï†ú
        if tenant_id and platform:
            # ÌäπÏ†ï ÌöåÏÇ¨ Î∞è ÌîåÎû´Ìèº Îç∞Ïù¥ÌÑ∞Îßå ÏÇ≠Ï†ú
            cursor.execute("DELETE FROM integrated_objects WHERE tenant_id = ? AND platform = ?", 
                         (tenant_id, platform))
            logger.info(f"Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú ÏôÑÎ£å: tenant_id={tenant_id}, platform={platform}")
        elif tenant_id:
            # ÌäπÏ†ï ÌöåÏÇ¨ Îç∞Ïù¥ÌÑ∞Îßå ÏÇ≠Ï†ú  
            cursor.execute("DELETE FROM integrated_objects WHERE tenant_id = ?", (tenant_id,))
            cursor.execute("DELETE FROM progress_logs WHERE tenant_id = ?", (tenant_id,))
            logger.info(f"Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú ÏôÑÎ£å: tenant_id={tenant_id}")
        else:
            # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú - ÎèÑÎ©îÏù∏ Îç∞Ïù¥ÌÑ∞Îßå ÏÇ≠Ï†ú (SaaS ÌÖåÏù¥Î∏îÏùÄ Ïú†ÏßÄ)
            cursor.execute("DELETE FROM integrated_objects")
            cursor.execute("DELETE FROM progress_logs")
            logger.info("Ï†ÑÏ≤¥ ÎèÑÎ©îÏù∏ Îç∞Ïù¥ÌÑ∞ ÏÇ≠Ï†ú ÏôÑÎ£å")
        
        self.connection.commit()

    # =====================================================
    # üè¢ SaaS ÎùºÏù¥ÏÑ†Ïä§ Í¥ÄÎ¶¨ Î©îÏÑúÎìúÎì§
    # =====================================================
    
    def insert_company(self, company_data: Dict[str, Any]) -> int:
        """ÌöåÏÇ¨ Ï†ïÎ≥¥ Îì±Î°ù"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO companies (
                company_name, domain, contact_email, subscription_plan_id,
                purchased_seats, used_seats, billing_status, subscription_start,
                subscription_end, next_billing_date, monthly_cost,
                current_month_tickets, current_day_api_calls,
                last_reset_month, last_reset_day, freshdesk_domain
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            company_data.get('company_name'),
            company_data.get('domain'),
            company_data.get('contact_email'),
            company_data.get('subscription_plan_id'),
            company_data.get('purchased_seats', 0),
            company_data.get('used_seats', 0),
            company_data.get('billing_status', 'active'),
            company_data.get('subscription_start'),
            company_data.get('subscription_end'),
            company_data.get('next_billing_date'),
            company_data.get('monthly_cost', 0.0),
            company_data.get('current_month_tickets', 0),
            company_data.get('current_day_api_calls', 0),
            company_data.get('last_reset_month'),
            company_data.get('last_reset_day'),
            company_data.get('freshdesk_domain')
        ))
        
        self.connection.commit()
        tenant_id = cursor.lastrowid
        logger.info(f"ÌöåÏÇ¨ Ï†ïÎ≥¥ Ï†ÄÏû• ÏôÑÎ£å: ID={tenant_id}, domain={company_data.get('domain')}")
        return tenant_id
    
    def get_company_by_domain(self, domain: str) -> Optional[Dict[str, Any]]:
        """ÎèÑÎ©îÏù∏ÏúºÎ°ú ÌöåÏÇ¨ Ï†ïÎ≥¥ Ï°∞Ìöå"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        cursor.execute("SELECT * FROM companies WHERE domain = ?", (domain,))
        row = cursor.fetchone()
        
        return dict(row) if row else None
    
    def insert_agent(self, agent_data: Dict[str, Any]) -> int:
        """ÏÉÅÎã¥Ïõê Ï†ïÎ≥¥ Îì±Î°ù"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        
        cursor.execute("""
            INSERT OR REPLACE INTO agents (
                tenant_id, email, name, freshdesk_agent_id, freshdesk_role,
                license_status, seat_assigned, assigned_by, assigned_at,
                feature_overrides, last_login_at, last_activity_at,
                monthly_tickets_processed, monthly_ai_summaries_used, is_active
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            agent_data.get('tenant_id'),
            agent_data.get('email'),
            agent_data.get('name'),
            agent_data.get('freshdesk_agent_id'),
            agent_data.get('freshdesk_role'),
            agent_data.get('license_status', 'inactive'),
            agent_data.get('seat_assigned', False),
            agent_data.get('assigned_by'),
            agent_data.get('assigned_at'),
            agent_data.get('feature_overrides'),
            agent_data.get('last_login_at'),
            agent_data.get('last_activity_at'),
            agent_data.get('monthly_tickets_processed', 0),
            agent_data.get('monthly_ai_summaries_used', 0),
            agent_data.get('is_active', True)
        ))
        
        self.connection.commit()
        agent_id = cursor.lastrowid
        logger.info(f"ÏÉÅÎã¥Ïõê Ï†ïÎ≥¥ Ï†ÄÏû• ÏôÑÎ£å: ID={agent_id}, email={agent_data.get('email')}")
        return agent_id
    
    def get_agents_by_company(self, tenant_id: int) -> List[Dict[str, Any]]:
        """ÌöåÏÇ¨Î≥Ñ ÏÉÅÎã¥Ïõê Î™©Î°ù Ï°∞Ìöå"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        cursor.execute("""
            SELECT * FROM agents 
            WHERE tenant_id = ? AND is_active = 1
            ORDER BY created_at DESC
        """, (tenant_id,))
        
        rows = cursor.fetchall()
        agents = []
        for row in rows:
            agent = dict(row)
            # JSON ÌïÑÎìú ÌååÏã±
            if agent.get('feature_overrides'):
                try:
                    agent['feature_overrides'] = json.loads(agent['feature_overrides'])
                except json.JSONDecodeError:
                    agent['feature_overrides'] = {}
            agents.append(agent)
        
        return agents
    
    def log_usage(self, usage_data: Dict[str, Any]) -> int:
        """ÏÇ¨Ïö©Îüâ Î°úÍ∑∏ Í∏∞Î°ù"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        
        cursor.execute("""
            INSERT INTO usage_logs (
                tenant_id, agent_id, usage_type, usage_count,
                resource_id, metadata, usage_date
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            usage_data.get('tenant_id'),
            usage_data.get('agent_id'),
            usage_data.get('usage_type'),
            usage_data.get('usage_count', 1),
            usage_data.get('resource_id'),
            json.dumps(usage_data.get('metadata', {})),
            usage_data.get('usage_date', datetime.now().strftime('%Y-%m-%d'))
        ))
        
        self.connection.commit()
        usage_id = cursor.lastrowid
        logger.info(f"ÏÇ¨Ïö©Îüâ Î°úÍ∑∏ Í∏∞Î°ù: ID={usage_id}, type={usage_data.get('usage_type')}")
        return usage_id
    
    def get_usage_summary(self, tenant_id: int, usage_type: str = None, days: int = 30) -> List[Dict[str, Any]]:
        """ÏÇ¨Ïö©Îüâ ÏöîÏïΩ Ï°∞Ìöå"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        
        query = """
            SELECT usage_type, usage_date, SUM(usage_count) as total_usage
            FROM usage_logs 
            WHERE tenant_id = ? 
            AND usage_date >= date('now', '-{} days')
        """.format(days)
        
        params = [tenant_id]
        
        if usage_type:
            query += " AND usage_type = ?"
            params.append(usage_type)
        
        query += " GROUP BY usage_type, usage_date ORDER BY usage_date DESC"
        
        cursor.execute(query, params)
        rows = cursor.fetchall()
        
        return [dict(row) for row in rows]
    
    def update_seat_usage(self, tenant_id: int, used_seats: int) -> bool:
        """ÏãúÌä∏ ÏÇ¨Ïö©Îüâ ÏóÖÎç∞Ïù¥Ìä∏"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        
        cursor.execute("""
            UPDATE companies 
            SET used_seats = ?, updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
        """, (used_seats, tenant_id))
        
        self.connection.commit()
        
        if cursor.rowcount > 0:
            logger.info(f"ÌöåÏÇ¨ ÏãúÌä∏ ÏÇ¨Ïö©Îüâ ÏóÖÎç∞Ïù¥Ìä∏: tenant_id={tenant_id}, used_seats={used_seats}")
            return True
        else:
            logger.warning(f"ÌöåÏÇ¨ ÏãúÌä∏ ÏÇ¨Ïö©Îüâ ÏóÖÎç∞Ïù¥Ìä∏ Ïã§Ìå®: tenant_id={tenant_id}")
            return False
    
    def get_subscription_plan(self, plan_id: int) -> Optional[Dict[str, Any]]:
        """Íµ¨ÎèÖ ÌîåÎûú Ï†ïÎ≥¥ Ï°∞Ìöå"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        cursor.execute("SELECT * FROM subscription_plans WHERE id = ? AND is_active = 1", (plan_id,))
        row = cursor.fetchone()
        
        if row:
            plan = dict(row)
            # JSON ÌïÑÎìú ÌååÏã±
            if plan.get('features'):
                try:
                    plan['features'] = json.loads(plan['features'])
                except json.JSONDecodeError:
                    plan['features'] = {}
            return plan
        
        return None
    
    def insert_billing_record(self, billing_data: Dict[str, Any]) -> int:
        """Í≤∞Ï†ú Í∏∞Î°ù ÏÉùÏÑ±"""
        if not self.connection:
            self.connect()
        
        cursor = self.connection.cursor()
        
        cursor.execute("""
            INSERT INTO billing_history (
                tenant_id, billing_period_start, billing_period_end,
                base_amount, additional_seats_count, additional_seats_amount,
                total_amount, status, payment_method, transaction_id,
                plan_name, plan_features
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            billing_data.get('tenant_id'),
            billing_data.get('billing_period_start'),
            billing_data.get('billing_period_end'),
            billing_data.get('base_amount'),
            billing_data.get('additional_seats_count', 0),
            billing_data.get('additional_seats_amount', 0.0),
            billing_data.get('total_amount'),
            billing_data.get('status', 'pending'),
            billing_data.get('payment_method'),
            billing_data.get('transaction_id'),
            billing_data.get('plan_name'),
            json.dumps(billing_data.get('plan_features', {}))
        ))
        
        self.connection.commit()
        billing_id = cursor.lastrowid
        logger.info(f"Í≤∞Ï†ú Í∏∞Î°ù ÏÉùÏÑ±: ID={billing_id}, tenant_id={billing_data.get('tenant_id')}")
        return billing_id
    
    def count_integrated_objects(self) -> int:
        """ÌÜµÌï© Í∞ùÏ≤¥ Ï¥ù Í∞úÏàò Î∞òÌôò"""
        try:
            self.connect()
            cursor = self.connection.cursor()
            cursor.execute("SELECT COUNT(*) FROM integrated_objects")
            count = cursor.fetchone()[0]
            return count
        except Exception as e:
            logger.error(f"ÌÜµÌï© Í∞ùÏ≤¥ Í∞úÏàò Ï°∞Ìöå Ïò§Î•ò: {e}")
            return 0
        finally:
            self.disconnect()
    
    def count_integrated_objects_by_type(self, object_type: str) -> int:
        """ÌäπÏ†ï ÌÉÄÏûÖÏùò ÌÜµÌï© Í∞ùÏ≤¥ Í∞úÏàò Î∞òÌôò"""
        try:
            self.connect()
            cursor = self.connection.cursor()
            cursor.execute(
                "SELECT COUNT(*) FROM integrated_objects WHERE object_type = ?",
                (object_type,)
            )
            count = cursor.fetchone()[0]
            return count
        except Exception as e:
            logger.error(f"{object_type} ÌÉÄÏûÖ Í∞ùÏ≤¥ Í∞úÏàò Ï°∞Ìöå Ïò§Î•ò: {e}")
            return 0
        finally:
            self.disconnect()
    
    def get_integrated_objects_statistics(self) -> Dict[str, Any]:
        """ÌÜµÌï© Í∞ùÏ≤¥ ÌÜµÍ≥Ñ Ï†ïÎ≥¥ Î∞òÌôò"""
        try:
            self.connect()
            cursor = self.connection.cursor()
            
            # Ï†ÑÏ≤¥ Í∞úÏàò
            cursor.execute("SELECT COUNT(*) FROM integrated_objects")
            total_count = cursor.fetchone()[0]
            
            # ÌÉÄÏûÖÎ≥Ñ Í∞úÏàò
            cursor.execute("""
                SELECT object_type, COUNT(*) as count 
                FROM integrated_objects 
                GROUP BY object_type
            """)
            type_counts = dict(cursor.fetchall())
            
            # ÏµúÍ∑º ÏÉùÏÑ±Îêú Í∞ùÏ≤¥Îì§
            cursor.execute("""
                SELECT object_type, MAX(created_at) as latest_created
                FROM integrated_objects 
                GROUP BY object_type
            """)
            latest_by_type = dict(cursor.fetchall())
            
            return {
                'total_count': total_count,
                'type_counts': type_counts,
                'latest_by_type': latest_by_type,
                'tenant_id': self.tenant_id,
                'platform': self.platform
            }
            
        except Exception as e:
            logger.error(f"ÌÜµÌï© Í∞ùÏ≤¥ ÌÜµÍ≥Ñ Ï°∞Ìöå Ïò§Î•ò: {e}")
            return {
                'total_count': 0,
                'type_counts': {},
                'latest_by_type': {},
                'tenant_id': self.tenant_id,
                'platform': self.platform
            }
        finally:
            self.disconnect()

    # Ìò∏ÌôòÏÑ±ÏùÑ ÏúÑÌïú alias
DatabaseManager = SQLiteDatabase

def get_database(tenant_id: str = None, platform: str = "freshdesk") -> SQLiteDatabase:
    """
    Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ïù∏Ïä§ÌÑ¥Ïä§ Î∞òÌôò (Freshdesk Ï†ÑÏö© Î©ÄÌã∞ÌÖåÎÑåÌä∏)
    
    Args:
        tenant_id: ÌÖåÎÑåÌä∏ ID (ÌÖåÎÑåÌä∏ ID)
        platform: ÌîåÎû´Ìèº Ïù¥Î¶Ñ (ÌòÑÏû¨Îäî FreshdeskÎßå ÏßÄÏõê, Îã§Î•∏ Í∞íÏùÄ Î¨¥ÏãúÎê®)
    
    Returns:
        SQLiteDatabase Ïù∏Ïä§ÌÑ¥Ïä§ (Ìï≠ÏÉÅ Freshdesk Ï†ÑÏö©)
    """
    if not tenant_id:
        raise ValueError("Î©ÄÌã∞ÌÖåÎÑåÌä∏ ÌôòÍ≤ΩÏóêÏÑúÎäî tenant_id(tenant_id)Í∞Ä ÌïÑÏàòÏûÖÎãàÎã§")
    
    return SQLiteDatabase(tenant_id, platform)  # platformÏùÄ ÎÇ¥Î∂ÄÏ†ÅÏúºÎ°ú "freshdesk"Î°ú Í≥†Ï†ïÎê®


def validate_multitenant_setup() -> Dict[str, Any]:
    """Î©ÄÌã∞ÌÖåÎÑåÌä∏ ÏÑ§Ï†ï Í≤ÄÏ¶ù"""
    validation = {
        'database_type': os.getenv('DATABASE_TYPE', 'sqlite'),
        'isolation_method': 'file-based' if os.getenv('DATABASE_TYPE', 'sqlite') == 'sqlite' else 'schema-based',
        'environment_vars': {},
        'recommendations': [],
        'is_production_ready': False
    }
    
    # ÌôòÍ≤ΩÎ≥ÄÏàò ÌôïÏù∏
    required_vars = ['DATABASE_TYPE']
    if validation['database_type'] == 'postgresql':
        required_vars.extend(['POSTGRES_HOST', 'POSTGRES_DB', 'POSTGRES_USER', 'POSTGRES_PASSWORD'])
    
    for var in required_vars:
        validation['environment_vars'][var] = os.getenv(var, 'NOT_SET')
        if validation['environment_vars'][var] == 'NOT_SET':
            validation['recommendations'].append(f"ÌôòÍ≤ΩÎ≥ÄÏàò {var} ÏÑ§Ï†ï ÌïÑÏöî")
    
    # PostgreSQLÏùò Í≤ΩÏö∞ Ï∂îÍ∞Ä Í≤ÄÏ¶ù
    if validation['database_type'] == 'postgresql':
        try:
            import psycopg2
            validation['postgresql_driver'] = 'Available'
            validation['is_production_ready'] = len(validation['recommendations']) == 0
        except ImportError:
            validation['postgresql_driver'] = 'Not Available'
            validation['recommendations'].append("psycopg2 ÎìúÎùºÏù¥Î≤Ñ ÏÑ§Ïπò ÌïÑÏöî")
    else:
        validation['is_production_ready'] = True  # SQLiteÎäî Í∏∞Î≥∏Ï†ÅÏúºÎ°ú ÏÇ¨Ïö© Í∞ÄÎä•
    
    return validation
