# LLM 모델 레지스트리 - 모든 사용 가능한 모델을 중앙에서 관리
# 새로운 모델 추가나 기존 모델 중단 시 이 파일만 수정하면 됨

# 제공자별 모델 설정
providers:
  openai:
    api_key_env: "OPENAI_API_KEY"
    models:
      # Chat 모델
      gpt-3.5-turbo:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "fast"
        quality_tier: "good"
        context_window: 4096
        max_tokens: 4096
        deprecated: false
        
      gpt-4:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "high"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 8192
        max_tokens: 4096
        deprecated: false
        
      gpt-4-turbo:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "medium"
        speed_tier: "fast"
        quality_tier: "excellent"
        context_window: 128000
        max_tokens: 4096
        deprecated: false
        
      gpt-4o-mini:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "very_low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 128000
        max_tokens: 16384
        deprecated: false
        
      # Embedding 모델
      text-embedding-3-small:
        type: "embedding"
        capabilities: ["text_embedding"]
        cost_tier: "low"
        speed_tier: "fast"
        quality_tier: "good"
        dimensions: 1536
        deprecated: false
        
      text-embedding-3-large:
        type: "embedding"
        capabilities: ["text_embedding"]
        cost_tier: "medium"
        speed_tier: "medium"
        quality_tier: "excellent"
        dimensions: 3072
        deprecated: false
        
  anthropic:
    api_key_env: "ANTHROPIC_API_KEY"
    models:
      claude-3-haiku-20240307:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 200000
        max_tokens: 4096
        deprecated: false
        
      claude-3-sonnet-20240229:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "medium"
        speed_tier: "fast"
        quality_tier: "excellent"
        context_window: 200000
        max_tokens: 4096
        deprecated: false
        
      claude-3-opus-20240229:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning", "complex_analysis"]
        cost_tier: "high"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 200000
        max_tokens: 4096
        deprecated: false
        
      claude-3-5-haiku-20241022:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "excellent"
        context_window: 200000
        max_tokens: 8192
        deprecated: false
        
  gemini:
    api_key_env: "GEMINI_API_KEY"
    models:
      gemini-1.5-flash:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 1000000
        max_tokens: 8192
        deprecated: false
        
      gemini-1.5-flash-latest:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 1000000
        max_tokens: 8192
        deprecated: false
        
      gemini-1.5-pro:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning", "complex_analysis"]
        cost_tier: "medium"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 2000000
        max_tokens: 8192
        deprecated: false
        
      gemini-pro:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "medium"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 30720
        max_tokens: 2048
        deprecated: true
        replacement: "gemini-1.5-pro"
        
      # Embedding 모델
      models/embedding-001:
        type: "embedding"
        capabilities: ["text_embedding"]
        cost_tier: "low"
        speed_tier: "fast"
        quality_tier: "good"
        dimensions: 768
        deprecated: false

# Use case별 모델 우선순위 설정
use_cases:
  # 긴 문서 요약
  summarization:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-5-haiku-20241022"
        reason: "빠른 속도와 높은 품질의 요약 능력"
      - provider: "gemini"
        model: "gemini-1.5-flash"
        reason: "긴 컨텍스트 처리 능력"
      - provider: "openai"
        model: "gpt-4o-mini"
        reason: "비용 효율적인 요약"
    requirements:
      context_window: 50000
      max_tokens: 4096
      
  # 질문 답변
  question_answering:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-sonnet-20240229"
        reason: "정확한 답변 생성"
      - provider: "openai"
        model: "gpt-4-turbo"
        reason: "균형잡힌 성능"
      - provider: "gemini"
        model: "gemini-1.5-pro"
        reason: "복잡한 질문 처리"
    requirements:
      context_window: 20000
      max_tokens: 2048
      
  # 대화형 채팅
  chat:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-5-haiku-20241022"
        reason: "빠른 응답 속도"
      - provider: "openai"
        model: "gpt-3.5-turbo"
        reason: "안정적인 대화 품질"
      - provider: "gemini"
        model: "gemini-1.5-flash"
        reason: "비용 효율성"
    requirements:
      context_window: 10000
      max_tokens: 1024
      
  # 복잡한 분석
  analysis:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-opus-20240229"
        reason: "최고 수준의 분석 능력"
      - provider: "openai"
        model: "gpt-4"
        reason: "깊이 있는 분석"
      - provider: "gemini"
        model: "gemini-1.5-pro"
        reason: "대용량 데이터 분석"
    requirements:
      context_window: 100000
      max_tokens: 4096
      
  # 텍스트 임베딩
  embedding:
    priority_models:
      - provider: "openai"
        model: "text-embedding-3-small"
        reason: "범용적인 임베딩 품질"
      - provider: "openai"
        model: "text-embedding-3-large"
        reason: "고품질 임베딩"
      - provider: "gemini"
        model: "models/embedding-001"
        reason: "다국어 지원"
    requirements:
      dimensions: 1536

# 환경별 기본 설정
environments:
  development:
    default_provider: "gemini"
    default_chat_model: "gemini-1.5-flash"
    default_embedding_model: "text-embedding-3-small"
    cost_limit: "low"
    
  staging:
    default_provider: "anthropic"
    default_chat_model: "claude-3-5-haiku-20241022"
    default_embedding_model: "text-embedding-3-small"
    cost_limit: "medium"
    
  production:
    default_provider: "anthropic"
    default_chat_model: "claude-3-sonnet-20240229"
    default_embedding_model: "text-embedding-3-small"
    cost_limit: "high"

# 모델 deprecation 정책
deprecation_policy:
  # 사용 중단 예정 모델들
  deprecated_models:
    - model: "gemini-pro"
      deprecation_date: "2024-12-31"
      replacement: "gemini-1.5-pro"
      migration_guide: "기존 프롬프트는 그대로 사용 가능하지만 성능 향상을 위해 컨텍스트 윈도우 활용 권장"
      
  # 자동 마이그레이션 규칙
  auto_migration:
    enabled: true
    notification_period: 30  # 일 단위
    fallback_strategy: "use_replacement"
    
# 모델 성능 모니터링
monitoring:
  # 추적할 메트릭
  metrics:
    - "response_time"
    - "token_usage"
    - "cost_per_request"
    - "error_rate"
    - "user_satisfaction"
    
  # 성능 임계값
  performance_thresholds:
    max_response_time: 30  # 초
    max_error_rate: 0.05   # 5%
    max_cost_per_1k_tokens: 0.10  # $0.10
    
  # A/B 테스트 설정
  ab_testing:
    enabled: true
    test_percentage: 10  # 10%의 요청에 대해 A/B 테스트
    comparison_models:
      - baseline: "claude-3-5-haiku-20241022"
        candidate: "gpt-4o-mini"
        use_case: "summarization"