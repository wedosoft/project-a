# 중앙집중식 모델 레지스트리 설정
# 이 파일은 모든 환경에서 공통으로 사용되는 기본 설정입니다.
# 환경별 오버라이드는 environment_configs.yaml에서 정의합니다.

# 제공자별 모델 정의
providers:
  openai:
    api_key_env: "OPENAI_API_KEY"
    base_url: "https://api.openai.com/v1"
    models:
      gpt-3.5-turbo:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "fast"
        quality_tier: "good"
        context_window: 4096
        max_tokens: 4096
        deprecated: false
        
      gpt-4:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "high"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 8192
        max_tokens: 4096
        deprecated: false
        
      gpt-4-turbo:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "medium"
        speed_tier: "fast"
        quality_tier: "excellent"
        context_window: 128000
        max_tokens: 4096
        deprecated: false
        
      gpt-4o-mini:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "very_low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 128000
        max_tokens: 16384
        deprecated: false
        
      text-embedding-3-small:
        type: "embedding"
        capabilities: ["text_embedding"]
        cost_tier: "low"
        speed_tier: "fast"
        quality_tier: "good"
        dimensions: 1536
        deprecated: false
        
      text-embedding-3-large:
        type: "embedding"
        capabilities: ["text_embedding"]
        cost_tier: "medium"
        speed_tier: "medium"
        quality_tier: "excellent"
        dimensions: 3072
        deprecated: false

  anthropic:
    api_key_env: "ANTHROPIC_API_KEY"
    base_url: "https://api.anthropic.com"
    models:
      claude-3-haiku-20240307:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 200000
        max_tokens: 4096
        deprecated: false
        
      claude-3-sonnet-20240229:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "medium"
        speed_tier: "fast"
        quality_tier: "excellent"
        context_window: 200000
        max_tokens: 4096
        deprecated: false
        
      claude-3-opus-20240229:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning", "complex_analysis"]
        cost_tier: "high"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 200000
        max_tokens: 4096
        deprecated: false
        
      claude-3-5-haiku-20241022:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "excellent"
        context_window: 200000
        max_tokens: 8192
        deprecated: false

  gemini:
    api_key_env: "GEMINI_API_KEY"
    base_url: "https://generativelanguage.googleapis.com/v1"
    models:
      gemini-1.5-flash:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 1000000
        max_tokens: 8192
        deprecated: false
        
      gemini-1.5-flash-latest:
        type: "chat"
        capabilities: ["text_generation", "conversation"]
        cost_tier: "low"
        speed_tier: "very_fast"
        quality_tier: "good"
        context_window: 1000000
        max_tokens: 8192
        deprecated: false
        
      gemini-1.5-pro:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning", "complex_analysis"]
        cost_tier: "medium"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 2000000
        max_tokens: 8192
        deprecated: false
        
      gemini-pro:
        type: "chat"
        capabilities: ["text_generation", "conversation", "reasoning"]
        cost_tier: "medium"
        speed_tier: "medium"
        quality_tier: "excellent"
        context_window: 30720
        max_tokens: 2048
        deprecated: true
        replacement: "gemini-1.5-pro"
        deprecation_date: "2024-12-31"
        migration_guide: "기존 프롬프트는 그대로 사용 가능하지만 성능 향상을 위해 컨텍스트 윈도우 활용 권장"
        
      models/embedding-001:
        type: "embedding"
        capabilities: ["text_embedding"]
        cost_tier: "low"
        speed_tier: "fast"
        quality_tier: "good"
        dimensions: 768
        deprecated: false

# Use case별 모델 우선순위 (기본값)
use_cases:
  summarization:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-5-haiku-20241022"
        reason: "빠른 속도와 높은 품질의 요약 능력"
      - provider: "gemini"
        model: "gemini-1.5-flash"
        reason: "긴 컨텍스트 처리 능력"
      - provider: "openai"
        model: "gpt-4o-mini"
        reason: "비용 효율적인 요약"
    requirements:
      context_window: 50000
      max_tokens: 4096
      
  question_answering:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-sonnet-20240229"
        reason: "정확한 답변 생성"
      - provider: "openai"
        model: "gpt-4-turbo"
        reason: "균형잡힌 성능"
      - provider: "gemini"
        model: "gemini-1.5-pro"
        reason: "복잡한 질문 처리"
    requirements:
      context_window: 20000
      max_tokens: 2048
      
  chat:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-5-haiku-20241022"
        reason: "빠른 응답 속도"
      - provider: "openai"
        model: "gpt-3.5-turbo"
        reason: "안정적인 대화 품질"
      - provider: "gemini"
        model: "gemini-1.5-flash"
        reason: "비용 효율성"
    requirements:
      context_window: 10000
      max_tokens: 1024
      
  analysis:
    priority_models:
      - provider: "anthropic"
        model: "claude-3-opus-20240229"
        reason: "최고 수준의 분석 능력"
      - provider: "openai"
        model: "gpt-4"
        reason: "깊이 있는 분석"
      - provider: "gemini"
        model: "gemini-1.5-pro"
        reason: "대용량 데이터 분석"
    requirements:
      context_window: 100000
      max_tokens: 4096
      
  embedding:
    priority_models:
      - provider: "openai"
        model: "text-embedding-3-small"
        reason: "범용적인 임베딩 품질"
      - provider: "openai"
        model: "text-embedding-3-large"
        reason: "고품질 임베딩"
      - provider: "gemini"
        model: "models/embedding-001"
        reason: "다국어 지원"
    requirements:
      dimensions: 1536

# 모델 deprecation 정책
deprecation_policy:
  deprecated_models:
    - model: "gemini-pro"
      deprecation_date: "2024-12-31"
      replacement: "gemini-1.5-pro"
      migration_guide: "기존 프롬프트는 그대로 사용 가능하지만 성능 향상을 위해 컨텍스트 윈도우 활용 권장"
      
  auto_migration:
    enabled: true
    notification_period: 30
    fallback_strategy: "use_replacement"
    
# 모델 성능 모니터링
monitoring:
  metrics:
    - "response_time"
    - "token_usage"
    - "cost_per_request"
    - "error_rate"
    - "user_satisfaction"
    
  performance_thresholds:
    max_response_time: 30
    max_error_rate: 0.05
    max_cost_per_1k_tokens: 0.10
    
  ab_testing:
    enabled: true
    test_percentage: 10
    comparison_models:
      - baseline: "claude-3-5-haiku-20241022"
        candidate: "gpt-4o-mini"
        use_case: "summarization"