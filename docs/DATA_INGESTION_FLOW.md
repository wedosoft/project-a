# ë°ì´í„° ì¸ì œìŠ¤íŠ¸ ë° ì €ì¥ êµ¬ì¡°

**ë‚ ì§œ**: 2025-11-05
**í”„ë¡œì íŠ¸**: AI Contact Center OS

---

## ğŸ“Š ì´ì¤‘ ì €ì¥ ì•„í‚¤í…ì²˜

ì´ í”„ë¡œì íŠ¸ëŠ” **PostgreSQL + Qdrant ì´ì¤‘ ì €ì¥ êµ¬ì¡°**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Freshdesk í‹°ì¼“ & KB ë¬¸ì„œ                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL      â”‚    â”‚     Qdrant       â”‚
â”‚  (Supabase)       â”‚    â”‚  (Vector DB)     â”‚
â”‚                   â”‚    â”‚                  â”‚
â”‚  - BM25 ê²€ìƒ‰      â”‚    â”‚  - Dense ê²€ìƒ‰    â”‚
â”‚  - ìŠ¤íŒŒìŠ¤ ì¸ë±ìŠ¤  â”‚    â”‚  - ë²¡í„° ì„ë² ë”©   â”‚
â”‚  - í…ìŠ¤íŠ¸ ë§¤ì¹­    â”‚    â”‚  - ì˜ë¯¸ ê²€ìƒ‰     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Hybrid Search Service â”‚
        â”‚  (RRF Fusion)          â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1ï¸âƒ£ PostgreSQL (Supabase) ì €ì¥

### **ëª©ì **: BM25 ìŠ¤íŒŒìŠ¤ ê²€ìƒ‰

**í…Œì´ë¸” êµ¬ì¡°**: `search_documents`

```sql
CREATE TABLE search_documents (
    id TEXT PRIMARY KEY,
    collection_name TEXT NOT NULL,
    content TEXT NOT NULL,
    content_tsvector tsvector GENERATED ALWAYS AS (
        to_tsvector('simple', content)
    ) STORED,
    metadata JSONB,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**ì¸ë±ìŠ¤**:
- `idx_search_documents_tsvector` (GIN): Full-text search
- `idx_search_documents_trigram` (GIN): Similarity search
- `idx_search_documents_collection`: Collection filtering

**ê²€ìƒ‰ ë°©ì‹**: [sparse_search.py](backend/services/sparse_search.py:175-250)
```python
# BM25-like ranking with ts_rank_cd
SELECT
    id,
    content,
    metadata,
    ts_rank_cd(content_tsvector, to_tsquery('simple', query)) AS score
FROM search_documents
WHERE collection_name = 'support_tickets'
  AND content_tsvector @@ to_tsquery('simple', query)
ORDER BY score DESC
LIMIT 10
```

**ì €ì¥ ë°ì´í„°**:
```python
{
    "id": "ticket-123",
    "collection_name": "support_tickets",
    "content": "Database connection error: timeout after 30s...",
    "metadata": {
        "ticket_id": "123",
        "priority": "high",
        "status": "resolved",
        "created_at": "2025-11-01"
    }
}
```

---

## 2ï¸âƒ£ Qdrant ì €ì¥

### **ëª©ì **: Dense ë²¡í„° ì˜ë¯¸ ê²€ìƒ‰

**ì»¬ë ‰ì…˜ êµ¬ì¡°**:

#### **support_tickets ì»¬ë ‰ì…˜**

**ë©€í‹°ë²¡í„° ì„¤ê³„**:
```python
vectors_config = {
    "symptom_vec": VectorParams(size=1024, distance=COSINE),
    "cause_vec": VectorParams(size=1024, distance=COSINE),
    "resolution_vec": VectorParams(size=1024, distance=COSINE)
}
```

**ì„ë² ë”© ëª¨ë¸**: `BAAI/bge-m3` (1024 ì°¨ì›)

**ì €ì¥ ë°ì´í„°** ([vector_search.py](backend/services/vector_search.py:122-167)):
```python
{
    "id": "ticket-123",
    "vectors": {
        "symptom_vec": [0.123, 0.456, ...],  # 1024 dimensions
        "cause_vec": [0.789, 0.012, ...],    # 1024 dimensions
        "resolution_vec": [0.345, 0.678, ...] # 1024 dimensions
    },
    "payload": {
        "ticket_id": "123",
        "subject": "Database connection error",
        "content": "Full ticket content...",
        "priority": "high",
        "status": "resolved",
        "symptom": "Connection timeout",
        "cause": "Network configuration issue",
        "resolution": "Update firewall rules"
    }
}
```

#### **kb_procedures ì»¬ë ‰ì…˜**

**ë©€í‹°ë²¡í„° ì„¤ê³„**:
```python
vectors_config = {
    "intent_vec": VectorParams(size=1024, distance=COSINE),
    "procedure_vec": VectorParams(size=1024, distance=COSINE)
}
```

**ì €ì¥ ë°ì´í„°**:
```python
{
    "id": "kb-001",
    "vectors": {
        "intent_vec": [0.111, 0.222, ...],     # ì§ˆë¬¸/ì˜ë„ ì„ë² ë”©
        "procedure_vec": [0.333, 0.444, ...]   # ì ˆì°¨/ë‹µë³€ ì„ë² ë”©
    },
    "payload": {
        "kb_id": "001",
        "title": "How to setup email integration",
        "content": "Step 1: ...",
        "category": "configuration",
        "tags": ["email", "integration", "setup"]
    }
}
```

---

## ğŸ”„ ë°ì´í„° ì¸ì œìŠ¤íŠ¸ í”Œë¡œìš°

### **ì „ì²´ í”„ë¡œì„¸ìŠ¤**:

```
1. Freshdesk API ì¡°íšŒ
   â†“
2. LLM ì¶”ì¶œ (Symptom/Cause/Resolution)
   â†“
3. ì„ë² ë”© ìƒì„± (BGE-M3)
   â†“
4. ë³‘ë ¬ ì €ì¥
   â”œâ†’ PostgreSQL: BM25 ì¸ë±ì‹±
   â””â†’ Qdrant: ë²¡í„° ì €ì¥
```

### **ìƒì„¸ ì½”ë“œ í”Œë¡œìš°**:

#### **1ë‹¨ê³„: Freshdesk í‹°ì¼“ ì¡°íšŒ** ([freshdesk.py](backend/services/freshdesk.py))
```python
from backend.services.freshdesk import FreshdeskClient

freshdesk = FreshdeskClient()
tickets = await freshdesk.fetch_tickets(
    updated_since=datetime.now() - timedelta(days=30),
    per_page=30,
    max_tickets=500
)
```

#### **2ë‹¨ê³„: LLM ì¶”ì¶œ** ([extractor.py](backend/services/extractor.py))
```python
from backend.services.extractor import IssueBlockExtractor

extractor = IssueBlockExtractor(provider=LLMProvider.GEMINI)

for ticket in tickets:
    issue_block = await extractor.extract_from_ticket(ticket)
    # issue_block = {
    #     "symptom": "Connection timeout",
    #     "cause": "Network configuration",
    #     "resolution": "Update firewall"
    # }
```

#### **3ë‹¨ê³„: ì„ë² ë”© ìƒì„±** ([vector_search.py](backend/services/vector_search.py:101-120))
```python
from backend.services.vector_search import VectorSearchService

vector_service = VectorSearchService()

# ê° í•„ë“œë³„ ì„ë² ë”© ìƒì„±
symptom_embeddings = vector_service.generate_embeddings([issue_block["symptom"]])
cause_embeddings = vector_service.generate_embeddings([issue_block["cause"]])
resolution_embeddings = vector_service.generate_embeddings([issue_block["resolution"]])
```

#### **4ë‹¨ê³„: Qdrant ì €ì¥** ([vector_search.py](backend/services/vector_search.py:122-167))
```python
# Qdrantì— ë©€í‹°ë²¡í„° ì €ì¥
points = [{
    "id": ticket["id"],
    "vectors": {
        "symptom_vec": symptom_embeddings[0].tolist(),
        "cause_vec": cause_embeddings[0].tolist(),
        "resolution_vec": resolution_embeddings[0].tolist()
    },
    "payload": {
        "ticket_id": ticket["id"],
        "subject": ticket["subject"],
        "content": ticket["description_text"],
        "symptom": issue_block["symptom"],
        "cause": issue_block["cause"],
        "resolution": issue_block["resolution"],
        "priority": ticket["priority"],
        "status": ticket["status"]
    }
}]

await vector_service.upsert_vectors(
    collection_name="support_tickets",
    points=points
)
```

#### **5ë‹¨ê³„: PostgreSQL ì €ì¥** ([sparse_search.py](backend/services/sparse_search.py:126-174))
```python
from backend.services.sparse_search import SparseSearchService

sparse_service = SparseSearchService()

# PostgreSQL BM25 ì¸ë±ì‹±
documents = [{
    "id": ticket["id"],
    "content": f"{ticket['subject']}\n\n{ticket['description_text']}",
    "metadata": {
        "ticket_id": ticket["id"],
        "priority": ticket["priority"],
        "status": ticket["status"],
        "created_at": ticket["created_at"]
    }
}]

await sparse_service.index_documents(
    collection_name="support_tickets",
    documents=documents
)
```

---

## ğŸ” í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í”Œë¡œìš°

### **ê²€ìƒ‰ í”„ë¡œì„¸ìŠ¤** ([hybrid_search.py](backend/services/hybrid_search.py:65-131))

```python
from backend.services.hybrid_search import HybridSearchService

hybrid_service = HybridSearchService()

results = await hybrid_service.search(
    collection_name="support_tickets",
    query="Database connection timeout",
    top_k=5,
    use_reranking=True
)
```

### **ë‚´ë¶€ ë™ì‘**:

#### **1. Dense + Sparse ë³‘ë ¬ ê²€ìƒ‰**
```python
# ë³‘ë ¬ ì‹¤í–‰
dense_results, sparse_results = await asyncio.gather(
    vector_service.search(query, top_k=10),  # Qdrant
    sparse_service.bm25_search(query, top_k=10)  # PostgreSQL
)
```

#### **2. RRF Fusion** ([hybrid_search.py](backend/services/hybrid_search.py:172-238))
```python
# Reciprocal Rank Fusion ì•Œê³ ë¦¬ì¦˜
rrf_score(doc) = Î£(weight_i / (k + rank_i(doc)))

# Dense ê²°ê³¼ ìŠ¤ì½”ì–´ë§
for rank, result in enumerate(dense_results, 1):
    rrf_scores[doc_id] += dense_weight / (60 + rank)

# Sparse ê²°ê³¼ ìŠ¤ì½”ì–´ë§
for rank, result in enumerate(sparse_results, 1):
    rrf_scores[doc_id] += sparse_weight / (60 + rank)

# ê²°í•© ë° ì •ë ¬
fused_results = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)
```

#### **3. Cross-Encoder Reranking** ([reranker.py](backend/services/reranker.py))
```python
# Jina AI Reranker v2ë¡œ ìµœì¢… ì¬ë­í‚¹
from backend.services.reranker import RerankerService

reranker = RerankerService()
final_results = reranker.rerank_results(
    query=query,
    search_results=fused_results,
    top_k=5
)
```

---

## ğŸ“ˆ ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ

### **ê° ë°©ì‹ì˜ ì¥ë‹¨ì **:

| ë°©ì‹ | ì¥ì  | ë‹¨ì  | ì‚¬ìš© ì¼€ì´ìŠ¤ |
|------|------|------|------------|
| **Dense (Qdrant)** | ì˜ë¯¸ ì´í•´, ë‹¤êµ­ì–´ ì§€ì› | ê³„ì‚° ë¹„ìš© ë†’ìŒ | "ì—°ê²° ì˜¤ë¥˜" â†’ "timeout ë¬¸ì œ" ë§¤ì¹­ |
| **Sparse (PostgreSQL)** | ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­, ë¹ ë¦„ | ì˜ë¯¸ ì´í•´ ë¶ˆê°€ | "error code 500" â†’ ì •í™•í•œ ì—ëŸ¬ ì½”ë“œ ë§¤ì¹­ |
| **Hybrid (RRF)** | ì–‘ìª½ ì¥ì  ê²°í•© | ë³µì¡ë„ ì¦ê°€ | ëŒ€ë¶€ë¶„ì˜ ì‹¤ì œ ê²€ìƒ‰ ì‹œë‚˜ë¦¬ì˜¤ |

### **ê²€ìƒ‰ í’ˆì§ˆ ì§€í‘œ**:

- **Recall@10**: ê´€ë ¨ ë¬¸ì„œ 10ê°œ ì¤‘ ëª‡ ê°œë¥¼ ì°¾ëŠ”ê°€
- **nDCG@10**: ìˆœìœ„ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰ í’ˆì§ˆ
- **RRF ìŠ¤ì½”ì–´**: Dense + Sparse ê²°í•© ì ìˆ˜

---

## ğŸš€ ì‹¤ì œ ì¸ì œìŠ¤íŠ¸ ì‹¤í–‰

### **í˜„ì¬ ìƒíƒœ**: ë²¡í„° DB ë¹„ì–´ìˆìŒ âš ï¸

**í™•ì¸ ë°©ë²•**:
```python
from backend.services.vector_search import VectorSearchService

vector_service = VectorSearchService()
info = vector_service.get_collection_info("support_tickets")
print(f"Points count: {info['points_count']}")  # í˜„ì¬: 0
```

### **ë°ì´í„° ì¸ì œìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± í•„ìš”**:

í˜„ì¬ `scripts/test_integration.py`ëŠ” ë‹¨ìˆœ LLM ì¶”ì¶œ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰í•˜ë¯€ë¡œ, **ì „ì²´ ì¸ì œìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸**ë¥¼ ìƒˆë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤:

```python
# scripts/data_ingestion.py (ì‘ì„± í•„ìš”)

import asyncio
from backend.services.freshdesk import FreshdeskClient
from backend.services.extractor import IssueBlockExtractor, LLMProvider
from backend.services.vector_search import VectorSearchService
from backend.services.sparse_search import SparseSearchService

async def ingest_tickets():
    """
    Freshdesk í‹°ì¼“ì„ Qdrant + PostgreSQLì— ì €ì¥
    """
    # 1. Freshdesk í‹°ì¼“ ì¡°íšŒ
    freshdesk = FreshdeskClient()
    tickets = await freshdesk.fetch_tickets(max_tickets=500)

    # 2. LLM ì¶”ì¶œê¸° ì´ˆê¸°í™”
    extractor = IssueBlockExtractor(provider=LLMProvider.GEMINI)

    # 3. ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    vector_service = VectorSearchService()
    sparse_service = SparseSearchService()

    # 4. PostgreSQL ìŠ¤í‚¤ë§ˆ ì´ˆê¸°í™”
    await sparse_service.initialize_search_schema()

    # 5. Qdrant ì»¬ë ‰ì…˜ ìƒì„±
    vector_service.create_collection(
        collection_name="support_tickets",
        vector_names=["symptom_vec", "cause_vec", "resolution_vec"]
    )

    # 6. ê° í‹°ì¼“ ì²˜ë¦¬
    for ticket in tickets:
        # 6a. LLM ì¶”ì¶œ
        issue_block = await extractor.extract_from_ticket(ticket)

        # 6b. ì„ë² ë”© ìƒì„±
        symptom_emb = vector_service.generate_embeddings([issue_block["symptom"]])
        cause_emb = vector_service.generate_embeddings([issue_block["cause"]])
        resolution_emb = vector_service.generate_embeddings([issue_block["resolution"]])

        # 6c. Qdrant ì €ì¥
        await vector_service.upsert_vectors(
            collection_name="support_tickets",
            points=[{
                "id": ticket["id"],
                "vectors": {
                    "symptom_vec": symptom_emb[0].tolist(),
                    "cause_vec": cause_emb[0].tolist(),
                    "resolution_vec": resolution_emb[0].tolist()
                },
                "payload": {
                    "ticket_id": ticket["id"],
                    "subject": ticket["subject"],
                    "content": ticket["description_text"],
                    **issue_block
                }
            }]
        )

        # 6d. PostgreSQL ì €ì¥
        await sparse_service.index_documents(
            collection_name="support_tickets",
            documents=[{
                "id": ticket["id"],
                "content": f"{ticket['subject']}\n\n{ticket['description_text']}",
                "metadata": {"ticket_id": ticket["id"]}
            }]
        )

if __name__ == "__main__":
    asyncio.run(ingest_tickets())
```

---

## ğŸ“Š ì €ì¥ ìš©ëŸ‰ ì¶”ì •

### **500ê°œ í‹°ì¼“ ê¸°ì¤€**:

**PostgreSQL**:
- í…ìŠ¤íŠ¸ í¬ê¸°: ~500 KB (í‰ê·  1KB/í‹°ì¼“)
- ì¸ë±ìŠ¤ í¬ê¸°: ~2 MB (GIN ì¸ë±ìŠ¤)
- **ì´í•©**: ~2.5 MB

**Qdrant**:
- ë²¡í„° í¬ê¸°: ~6 MB (500ê±´ Ã— 3ë²¡í„° Ã— 1024ì°¨ì› Ã— 4ë°”ì´íŠ¸)
- Payload í¬ê¸°: ~1 MB
- **ì´í•©**: ~7 MB

**ì „ì²´**: ~10 MB (500ê°œ í‹°ì¼“ ê¸°ì¤€)

---

## ğŸ¯ ìš”ì•½

### âœ… **ì´ì¤‘ ì €ì¥ ì´ìœ **:

1. **PostgreSQL (BM25)**:
   - ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (ì—ëŸ¬ ì½”ë“œ, ì œí’ˆëª…)
   - ë¹ ë¥¸ í…ìŠ¤íŠ¸ ê²€ìƒ‰
   - í•œêµ­ì–´ ì „ë¬¸ ê²€ìƒ‰

2. **Qdrant (Dense)**:
   - ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (ìœ ì‚¬ ì¦ìƒ)
   - ë‹¤êµ­ì–´ ì§€ì›
   - ë©€í‹°ë²¡í„° (ì¦ìƒ/ì›ì¸/í•´ê²° ê°ê° ê²€ìƒ‰)

3. **í•˜ì´ë¸Œë¦¬ë“œ (RRF + Reranking)**:
   - ì–‘ìª½ ì¥ì  ê²°í•©
   - Cross-encoderë¡œ ìµœì¢… ì¬ë­í‚¹
   - ê²€ìƒ‰ í’ˆì§ˆ ìµœëŒ€í™”

### âš ï¸ **í˜„ì¬ ì‘ì—… í•„ìš”**:
1. ì „ì²´ ë°ì´í„° ì¸ì œìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
2. Freshdesk â†’ Qdrant + PostgreSQL íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
3. ê²€ìƒ‰ í’ˆì§ˆ ê²€ì¦ ë° íŠœë‹

---

**ì‘ì„±ì¼**: 2025-11-05
**ì‘ì„±ì**: AI Assistant
