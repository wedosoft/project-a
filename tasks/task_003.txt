# Task ID: 3
# Title: OpenAI 임베딩 모듈 구현
# Status: completed
# Dependencies: 1
# Priority: high
# Description: LLM Router 및 Orchestrator 구현을 통한 다중 LLM 제공자 지원 및 프롬프트 관리 시스템 개발
# Details:
다음 핵심 기능을 `core/llm_router.py`에 구현:

1. **다중 LLM 제공자 지원**:
   - Anthropic, OpenAI, Gemini 등 다양한 LLM 제공자 연동
   - 자동 폴백 메커니즘 구현 (특정 LLM 실패 시 다른 LLM으로 자동 전환)
   - 로드 밸런싱 기능 구현
   - LLM 성능 메트릭 수집 및 모니터링

2. **프롬프트 관리**:
   - 티켓 요약, 사용자 질문, 검색된 컨텍스트(유사 티켓, 관련 문서) 등 다양한 정보를 조합하여 최적의 프롬프트 동적 구성
   - 'LLM 호출 시 맥락 중심으로 프롬프트 구성' 원칙 준수

3. **LLM 호출 제어**:
   - 사용자의 명시적인 요청(예: 'AI로 답변 생성' 버튼 클릭)이 있을 때만 LLM 호출
   - 불필요한 API 호출 방지 로직 구현

4. **컨텍스트 최적화**:
   - 자연어 요청의 의도 파악
   - LLM이 고품질 응답을 생성할 수 있도록 컨텍스트 정보 최적화

5. **응답 처리**:
   - LLM 응답 검증 및 후처리
   - 프론트엔드가 사용하기 쉬운 JSON 형식으로 변환

6. **에러 핸들링**:
   - LLM API 호출 실패, 타임아웃 등의 에러 상황에 대한 강력한 에러 처리
   - 폴백 로직 구현

# Test Strategy:
1. 각 LLM 제공자 API 연동 테스트 (모킹 활용)
2. 프롬프트 구성 로직 단위 테스트
3. 폴백 및 로드 밸런싱 기능 테스트
4. 다양한 시나리오(예: 컨텍스트 부족, LLM 응답 오류)에 대한 통합 테스트
5. 에러 처리 및 재시도 로직 테스트
6. 응답 처리 및 JSON 변환 테스트

# Subtasks:
## 3.1. 다중 LLM 제공자 연동 구현 [pending]
### Dependencies: None
### Description: Anthropic, OpenAI, Gemini 등 다양한 LLM 제공자 API 연동 구현
### Details:


## 3.2. 자동 폴백 및 로드 밸런싱 구현 [pending]
### Dependencies: None
### Description: LLM 호출 실패 시 대체 제공자로 자동 전환하는 폴백 메커니즘과 부하 분산을 위한 로드 밸런싱 구현
### Details:


## 3.3. 프롬프트 관리 시스템 개발 [pending]
### Dependencies: None
### Description: 다양한 컨텍스트 정보를 조합하여 최적의 프롬프트를 동적으로 구성하는 시스템 개발
### Details:


## 3.4. LLM 호출 제어 로직 구현 [pending]
### Dependencies: None
### Description: 사용자의 명시적 요청에만 LLM을 호출하도록 제어하는 로직 구현
### Details:


## 3.5. 응답 처리 및 변환 기능 개발 [pending]
### Dependencies: None
### Description: LLM 응답을 검증하고 프론트엔드용 JSON 형식으로 변환하는 기능 개발
### Details:


## 3.6. 에러 핸들링 및 재시도 로직 구현 [pending]
### Dependencies: None
### Description: API 호출 실패, 타임아웃 등의 에러 상황에 대한 처리 및 재시도 로직 구현
### Details:


## 3.7. LLM 성능 메트릭 수집 시스템 구현 [pending]
### Dependencies: None
### Description: 각 LLM 제공자의 응답 시간, 성공률, 품질 등을 모니터링하는 메트릭 수집 시스템 구현
### Details:


